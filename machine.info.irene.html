

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>irene.info v0.0</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#" class="icon icon-home"> irene
          

          
            
            <img src="_static/tgcc-logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                2021-12-01.1214
              </div>
            
          

          

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
            
              <!-- Local TOC -->
              <div class="local-toc"><p class="caption"><span class="caption-text">Content</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Introduction">Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#the-computing-center">The computing center</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#access-to-computing-resources">Access to computing resources</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Supercomputer_architecture">Supercomputer architecture</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#configuration-of-machine">Configuration of Irene</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#interconnect">Interconnect</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#lustre">Lustre</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#quick-start-for-amd-rome">Quick start for AMD Rome</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#quick-start-for-arm-a64fx">Quick start for ARM A64FX</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/User_account">User account</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#user-account-creation">User account creation</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#passwords">Passwords</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#account-locking-and-account-deletion">Account locking and account deletion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Interactive_access">Interactive access</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#system-access">System access</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#login-nodes-usage">Login nodes usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#remote-desktop-system-service-nicedcv">Remote Desktop System service (NiceDCV)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Data_spaces">Data spaces</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#available-file-systems">Available file systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#quota">Quota</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#data-protection">Data protection</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#personal-spaces">Personal Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#shared-spaces">Shared Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#parallel-file-system-usage-monitoring">Parallel file system usage monitoring</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Data_transfer">Data transfers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#file-transfer">File transfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#synchronize-your-ccrt-account-with-your-prace-account">Synchronize your CCRT account with your PRACE account</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#ccfr-infrastructure">CCFR infrastructure</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#prace-infrastructure">PRACE infrastructure</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Environment_management">Environment management</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#what-is-module">What is module</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#module-actions">Module actions</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#initialization-and-scope">Initialization and scope</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#major-modulefiles">Major modulefiles</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#extend-your-environment-with-modulefiles">Extend your environment with modulefiles</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Software">Softwares</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#generalities-on-software">Generalities on software</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#specific-software">Specific software</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#product-life-cycle">Product Life cycle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Job_submission">Job submission</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#scheduling-policy">Scheduling policy</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#choosing-the-file-systems">Choosing the file systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#submission-scripts">Submission scripts</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#job-monitoring-and-control">Job monitoring and control</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#special-jobs">Special jobs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Project_accounting">Project accounting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#computing-hours-consumption-control-process">Computing hours consumption control process</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#ccc-myproject">ccc_myproject</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#ccc-compuse">ccc_compuse</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Compiling">Compilation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#language-standard">Language standard</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#available-compilers">Available compilers</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#available-numerical-libraries">Available numerical libraries</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#compiling-for-skylake">Compiling for Skylake</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#compiling-for-rome-milan">Compiling for Rome/Milan</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Parallel_programming">Parallel programming</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#mpi">MPI</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#openmp">OpenMP</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#using-gpus">Using GPUs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Runtime_tuning">Runtime tuning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#memory-allocation-tuning">Memory allocation tuning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Process_distribution_affinity_binding">Process distribution, affinity and binding</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#hardware-topology">Hardware topology</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#definitions">Definitions</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#process-distribution">Process distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#process-and-thread-affinity">Process and thread affinity</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#hyper-threading-usage">Hyper-Threading usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#turbo">Turbo</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/IO">Parallel IO</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#mpi-io">MPI-IO</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#recommended-data-usage-on-parallel-file-system">Recommended data usage on parallel file system</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#parallel-compression-and-decompression-with-pigz">Parallel compression and decompression with pigz</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Debugging">Debugging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#summary">Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#compiler-flags">Compiler flags</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#available-debuggers">Available debuggers</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#other-tools">Other tools</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Profiling">Profiling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#summary">Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#ipm">IPM</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#darshan">Darshan</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#arm-forge-map">Arm-forge MAP</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#gprof">Gprof</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#igprof">igprof</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#papi">PAPI</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#scalasca">Scalasca</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#vampir">Vampir</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#extra-p">Extra-P</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#hpctoolkit">HPCToolkit</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#intel-vtune">Intel Vtune</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#valgrind">Valgrind</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#intel-advisor">Intel Advisor</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#tau-tuning-and-analysis-utilities">TAU (Tuning and Analysis Utilities)</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#gprof2dot">Gprof2dot</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#perf">Perf</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#memonit">Memonit</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Post-processing">Post-processing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#gnuplot">Gnuplot</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#xmgrace">Xmgrace</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#tecplot">Tecplot</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#ensight">Ensight</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#visit">visit</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#paraview">paraview</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Virtualization">Virtualization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="irene.html#pcocc">PCOCC</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#pre-requisites-for-virtual-machines">Pre-requisites for virtual machines</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#launching-a-cluster-of-vms">Launching a cluster of VMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#bridge-templates">Bridge templates</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#customizing-the-vm">Customizing the VM</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#bridge-plugin">Bridge plugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#checkpoint-restart-with-bridge-plugin">Checkpoint / restart with Bridge plugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#launching-a-cluster-of-containers">Launching a cluster of containers</a></li>
<li class="toctree-l2"><a class="reference internal" href="irene.html#whole-set-of-commands">Whole set of commands</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="irene.html#document-toc/fulldoc/Glossary">Glossary of CCC commands</a></li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">irene</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#">Docs</a> &raquo;</li>
        
      <li>irene.info v0.0</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="welcome-to-irene-documentation">
<h1>Welcome to Irene documentation<a class="headerlink" href="#welcome-to-irene-documentation" title="Permalink to this headline">¶</a></h1>
<p>This user guide is provided by the TGCC computing center (<a class="reference external" href="https://www-tgcc.ccc.cea.fr/">https://www-tgcc.ccc.cea.fr/</a>).</p>
<div class="line-block">
<div class="line">This documentation can be found in different formats:</div>
<div class="line"><br /></div>
<div class="line">HTML:</div>
<div class="line"><a class="reference external" href="../../fr/html/irene.html">Documentation en français HTML</a></div>
<div class="line"><a class="reference external" href="../../fr/singlehtml/irene.html">Documentation en français HTML (Page unique)</a></div>
<div class="line"><a class="reference external" href="../../en/html/irene.html">English documentation HTML</a></div>
<div class="line"><a class="reference external" href="../../en/singlehtml/irene.html">English documentation HTML (One page)</a></div>
<div class="line"><br /></div>
<div class="line">PDF:</div>
<div class="line"><a class="reference external" href="../../fr/latex/irene.pdf">Documentation en français PDF</a></div>
<div class="line"><a class="reference external" href="../../en/latex/irene.pdf">English documentation PDF</a></div>
<div class="line"><br /></div>
</div>
<p>This documentation is available on clusters with the following commands:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ machine.info
$ man irene
</pre></div>
</div>
<p>Feel free to contact us at <a class="reference external" href="mailto:hotline&#46;tgcc&#37;&#52;&#48;cea&#46;fr">hotline<span>&#46;</span>tgcc<span>&#64;</span>cea<span>&#46;</span>fr</a> for any suggestion about this documentation.</p>
<div class="toctree-wrapper compound">
<span id="document-toc/fulldoc/Introduction"></span><div class="section" id="introduction">
<span id="id1"></span><h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-computing-center">
<h3>The computing center<a class="headerlink" href="#the-computing-center" title="Permalink to this headline">¶</a></h3>
<p>The <abbr title="Très Grand Centre de Calcul du CEA">TGCC</abbr> is a high performance computing infrastructure aiming at hosting state-of-the-art supercomputers in France.</p>
<p>It is designed to:</p>
<ul class="simple">
<li>Accommodate future high end computing systems.</li>
<li>Provide a communication and exhibition space for scientific events (conferences, seminars, training sessions, …).</li>
<li>Propose a flexible and modular facility for future evolution of HPC systems.</li>
</ul>
<p>The TGCC hosts two clusters:</p>
<ul class="simple">
<li>Joliot-Curie, a 21 PFlops supercomputer that is part of <abbr title="Grand Equipement National de Calcul Intensif">GENCI</abbr>. It represents the french contribution to the European <abbr title="Partnership for Advanced Computing in Europe">PRACE</abbr> infrastructure.</li>
<li>Topaze, a 4 PFlops supercomputer that is part of the <abbr title="Centre de Calcul Recherche et Technologie, used by the CEA and its industrial partners">CCRT</abbr>.</li>
</ul>
<p>The computing center architecture is data-centric. The computing nodes are connected to the private Lustre storage system for very fast I/O. And Global Lustre filesystems are shared between the different supercomputers. A hierarchical data storage system manages petabytes of data and is used for long term storage and archiving of results.</p>
<p>The computing center operates round the clock, except for scheduled maintenance periods when the teams update the hardware, firmware and software. The regular maintenance periods also allow a check of the general behavior and performance of the various supercomputers. Every year, a compulsory electrical maintenance requires a full shut down of the supercomputers for a longer period (3 days).</p>
<p>On-site support for the contractors, expert administration teams and an on-call duty system optimize the availability of the computing service. Guaranteeing access security and data confidentiality is a major preoccupation. A CEA IT security experts unit controls a security supervision system which monitors, detects and analyzes security alerts, enabling the security managers to react extremely rapidly.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The Hotline is the single point of contact for any question or support request:</p>
<ul class="simple">
<li>mail : <a class="reference external" href="mailto:hotline&#46;tgcc&#37;&#52;&#48;cea&#46;fr">hotline<span>&#46;</span>tgcc<span>&#64;</span>cea<span>&#46;</span>fr</a></li>
<li>tel : +33 1 77 57 42 42</li>
</ul>
<p class="last">Depending on its type, the demand will be transmitted to the appropriate team.</p>
</div>
<p>A users committee (COMUT) takes place every trimester to exchange between users and the TGCC staff. The representatives of each community can provide their feedback on the general usage of the computing center. Any big change or update is announced during the COMUT.</p>
<p>Training sessions are organized by TGCC staff on a regular basis.</p>
</div>
<div class="section" id="access-to-computing-resources">
<h3>Access to computing resources<a class="headerlink" href="#access-to-computing-resources" title="Permalink to this headline">¶</a></h3>
<p>Computing hours on the computing center are granted in a community-dependent fashion:</p>
<ul>
<li><p class="first">CCRT Partners automatically get a share of the computing resources.</p>
</li>
<li><p class="first">French research teams can ask for resources through GENCI thanks to DARI calls: <a class="reference external" href="http://www.edari.fr">http://www.edari.fr</a></p>
</li>
<li><p class="first">Scientists and researchers from academia and industry can ask for resources through PRACE. PRACE accesses are of 2 kinds:</p>
<ul class="simple">
<li>Preparatory Access is intended for short-term access to resources, for code-enabling and porting, required to prepare proposals for Project Access and to demonstrate the scalability of codes. Applications for Preparatory Access are accepted at any time, with a cut-off date every 3 months.</li>
<li>Project Access is intended for individual researchers and research groups including multinational research groups. It can be used for 1-year production runs, as well as for 2-year or 3-year (Multi-Year Access) production runs.</li>
</ul>
<blockquote>
<div><p>Project Access is subject to the PRACE Peer Review Process, which includes technical and scientific review. Technical experts and leading scientists evaluate the proposals submitted in response to the bi-annual calls. Applications for Preparatory Access undergo technical review only.
For more information on how to apply for access to PRACE resources, go to <a class="reference external" href="http://www.prace-ri.eu/how-to-apply">http://www.prace-ri.eu/how-to-apply</a></p>
</div></blockquote>
</li>
</ul>
<p>Ongoing PRACE projects are monitored as much as possible. Therefore, we regularly ask for your feedback. Feel free to tell us about any issue you are facing.</p>
<p>Project or partner accounts are granted an amount of computing hours or a computing share. They must use the awarded hours on a regular basis. To ensure that: over-consumption lowers priority so jobs might need more time to access resources, and reaching an under-consumption limit may result in hours being removed from a project.</p>
</div>
</div>
<span id="document-toc/fulldoc/Supercomputer_architecture"></span><div class="section" id="supercomputer-architecture">
<span id="id1"></span><h2>Supercomputer architecture<a class="headerlink" href="#supercomputer-architecture" title="Permalink to this headline">¶</a></h2>
<div class="section" id="configuration-of-machine">
<h3>Configuration of Irene<a class="headerlink" href="#configuration-of-machine" title="Permalink to this headline">¶</a></h3>
<p>The compute nodes are gathered in partitions according to their hardware characteristics (CPU architecture, amount of RAM, presence of GPU, etc). A partition is a set of identical nodes that can be targeted to host one or several jobs. Choosing the right partition for a job depends on code prerequisites in term of hardware resources. For example, executing a code designed to be GPU accelerated requires a partition with GPU nodes.</p>
<p>The Irene supercomputer offers three different kind of nodes: regular compute nodes, KNL nodes, large memory nodes and GPU nodes.</p>
<ul>
<li><dl class="first docutils">
<dt>Skylake nodes for regular computation</dt><dd><ul class="simple">
<li>Partition name: skylake</li>
<li>CPU : 2x24-cores Intel <a class="reference external" href="mailto:Skylake&#37;&#52;&#48;2&#46;7GHz">Skylake<span>&#64;</span>2<span>&#46;</span>7GHz</a> (AVX512)</li>
<li>Cores/Node: 48</li>
<li>Nodes: 1 656</li>
<li>Total cores: 79 488</li>
<li>RAM/Node: 180GB</li>
<li>RAM/Core: 3.75GB</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>KNL nodes for regular computation</dt><dd><ul class="simple">
<li>Partition name: knl</li>
<li>CPUs: 1x68-cores Intel <a class="reference external" href="mailto:KNL&#37;&#52;&#48;1&#46;4GHz">KNL<span>&#64;</span>1<span>&#46;</span>4GHz</a></li>
<li>Cores/Node: 64 (With 4 additional cores reserved for the operating system. They are referenced by the scheduler but not taken into account for hours consumption.)</li>
<li>Nodes: 828</li>
<li>Total cores : 52 992</li>
<li>RAM/Node: 96GB</li>
<li>RAM/Core: 1.4GB</li>
<li>Cluster mode is set to quadrant</li>
<li>MCDRAM (Multi-Channel Dynamic Random Access Memory) is set as a last-level cache (cache mode)</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>AMD Rome nodes for regular computation</dt><dd><ul class="simple">
<li>Partition name : Rome</li>
<li>CPUs: 2x64 AMD <a class="reference external" href="mailto:Rome&#37;&#52;&#48;2&#46;6Ghz">Rome<span>&#64;</span>2<span>&#46;</span>6Ghz</a> (AVX2)</li>
<li>Core/Node: 128</li>
<li>Nodes: 2292</li>
<li>Total core: 293 376</li>
<li>RAM/Node: 256GB</li>
<li>RAM/core : 2GB</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Hybrid nodes for GPU computing and graphical usage</dt><dd><ul class="simple">
<li>Partition name: hybrid</li>
<li>CPUs: 2x24-cores Intel <a class="reference external" href="mailto:Skylake&#37;&#52;&#48;2&#46;7GHz">Skylake<span>&#64;</span>2<span>&#46;</span>7GHz</a> (AVX512)</li>
<li>GPUs: 1x Nvidia Pascal P100</li>
<li>Cores/Node: 48</li>
<li>Nodes: 20</li>
<li>Total cores: 960 (+ 20 GPU)</li>
<li>RAM/Node: 192GB</li>
<li>RAM/Core: 4GB</li>
<li>I/O: 1 HDD 250 GB + 1 SSD 800 GB/NVMe</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Fat nodes with a lot of shared memory for computation lasting a reasonable amount of time and using no more than one node</dt><dd><ul class="simple">
<li>Partition name: xlarge</li>
<li>CPUs: 4x28-cores Intel <a class="reference external" href="mailto:Skylake&#37;&#52;&#48;2&#46;1GHz">Skylake<span>&#64;</span>2<span>&#46;</span>1GHz</a></li>
<li>GPUs: 1x Nvidia Pascal P100</li>
<li>Cores/Node: 112</li>
<li>Nodes: 5</li>
<li>Total cores: 560</li>
<li>RAM/Node: 3TB</li>
<li>RAM/Core: 27GB</li>
<li>IO: 2 HDD de 1 TB + 1 SSD 1600 GB/NVMe</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>V100 nodes for GPU computing and AI</dt><dd><ul class="simple">
<li>Partition name: V100</li>
<li>CPUs: 2x20-cores Intel <a class="reference external" href="mailto:Cascadelake&#37;&#52;&#48;2&#46;1GHz">Cascadelake<span>&#64;</span>2<span>&#46;</span>1GHz</a> (AVX512)</li>
<li>GPUs: 4x Nvidia Tesla V100</li>
<li>Cores/Node: 40</li>
<li>Nodes: 32</li>
<li>Total cores: 1280 (+ 128 GPU)</li>
<li>RAM/Node: 180 GB</li>
<li>RAM/Core: 4.5 GB</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>ARM A64FX for regular computation</dt><dd><ul class="simple">
<li>Partition name : A64FX</li>
<li>CPUs : 1x48 A64FX Armv8.2-A SVE &#64;1.8Ghz</li>
<li>Core/Node : 48</li>
<li>Nodes : 80</li>
<li>Total core : 3840</li>
<li>RAM/Node : 32GB</li>
<li>RAM/core : 666MB</li>
</ul>
</dd>
</dl>
</li>
</ul>
<p><strong class="command">ccc_mpinfo</strong> displays the available partitions/queues that can be used on a job.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mpinfo
                  --------------CPUS------------  -------------NODES------------
PARTITION    STATUS   TOTAL   DOWN    USED    FREE    TOTAL   DOWN    USED    FREE     MpC   CpN SpN CpS TpC
---------    ------   ------  ------  ------  ------  ------  ------  ------  ------   ----- --- --- --- ---
milan        up       107776       0  104373    3403     842       0     821      21    1867  128   2  64   1
a100         up         6144     128    3840    2176      48       1      30      17    3867  128   2  64   1
xlarge       up          256       0       0     256       2       0       0       2   31250  128   2  64   1
</pre></div>
</div>
<ul class="simple">
<li><strong>MpC</strong> : amount of memory per core</li>
<li><strong>CpN</strong> : number of cores per node</li>
<li><strong>SpN</strong> : number of sockets per node</li>
<li><strong>Cps</strong> : number of cores per socket</li>
<li><strong>TpC</strong> : number of threads per core (for hyperthreading)</li>
</ul>
</div>
<div class="section" id="interconnect">
<h3>Interconnect<a class="headerlink" href="#interconnect" title="Permalink to this headline">¶</a></h3>
<p>The compute nodes are connected through a EDR InfiniBand network in a pruned FAT tree topology. This high throughput (100GB/s) and low latency network is used for I/O and communications among nodes of the supercomputer.</p>
</div>
<div class="section" id="lustre">
<h3>Lustre<a class="headerlink" href="#lustre" title="Permalink to this headline">¶</a></h3>
<p>Lustre is a type of parallel distributed file system, commonly used for large-scale cluster computing. It actually relies on a set of multiple I/O servers and the Lustre software presents them as a single unified filesystem.</p>
<p>The major Lustre components are the <abbr title="MetaData Server">MDS</abbr> and <abbr title="Object Storage Servers">OSSs</abbr>. The MDS stores metadata such as file names, directories, access permissions, and file layout. It is not actually involved in any I/O operations. The actual data is stored on the OSSs. Note that one single file can be stored on several OSSs which is one of the benefits of Lustre when working with large files.</p>
<div class="figure align-default" id="id5">
<img alt="Lustre.png" src="_images/Lustre.png" />
<p class="caption"><span class="caption-text">Lustre.png</span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
<p>More information on how Lustre works and best practices are described in <a class="reference internal" href="irene.html#recommended-data-usage-on-parallel-file-system"><span class="std std-ref">Lustre best practice</span></a>.</p>
</div>
<div class="section" id="quick-start-for-amd-rome">
<h3>Quick start for AMD Rome<a class="headerlink" href="#quick-start-for-amd-rome" title="Permalink to this headline">¶</a></h3>
<div class="section" id="compilation">
<h4>Compilation<a class="headerlink" href="#compilation" title="Permalink to this headline">¶</a></h4>
<p>By default intel compiler (icc/ifort) adds a test when building on intel processors. In order to avoid an error when building for execution on a Rome architecture, one should use the <code class="xref std std-option docutils literal notranslate"><span class="pre">-mavx2</span></code> flags for compilation. If the user wants to compile an optimized version that works on any processor of Irene (ie : skl, knl and rome), he will need to use the following flags <code class="xref std std-option docutils literal notranslate"><span class="pre">-mavx2</span> <span class="pre">-ax</span> <span class="pre">CORE-AVX512,MIC-AVX512</span></code>.</p>
</div>
<div class="section" id="blis-numerical-library">
<h4>BLIS numerical library<a class="headerlink" href="#blis-numerical-library" title="Permalink to this headline">¶</a></h4>
<p>BLIS is a portable open-source software framework for instantiating high-performance BLAS-like dense linear algebra libraries. The framework was designed to isolate essential kernels of computation that, when optimized, immediately enable optimized implementations of most of its commonly used and computationally intensive operations. Select kernels have been optimized for the AMD EPYC processor family by AMD and others.</p>
<p>To compile your code with this library, you need to load the blis module and to add the environment variable <span class="target" id="index-0"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCC_LDFLAGS</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ module load blis
</pre></div>
</div>
<ul class="simple">
<li>if you use the fortran language, use the following compilation commands:</li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ifort prog.f90 <span class="si">${</span><span class="nv">CCC_LDFLAGS</span><span class="si">}</span>
$ mpifort prog.f90 <span class="si">${</span><span class="nv">CCC_LDFLAGS</span><span class="si">}</span>
</pre></div>
</div>
<ul class="simple">
<li>if you use the c language, use the following compilation commands:</li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ icc prog.c <span class="si">${</span><span class="nv">CCC_LDFLAGS</span><span class="si">}</span>
$ mpicc prog.c <span class="si">${</span><span class="nv">CCC_LDFLAGS</span><span class="si">}</span>
</pre></div>
</div>
<p>BLIS also includes a BLAS compatibility layer which gives application developers access to BLIS implementations via traditional BLAS API calls, that can be used in FORTRAN as well as in C code. BLIS also provides a CBLAS API, which is a C-style interface for BLAS, that can be called from C code.</p>
</div>
<div class="section" id="processor-performance">
<h4>Processor performance<a class="headerlink" href="#processor-performance" title="Permalink to this headline">¶</a></h4>
<p>A Rome core has a lower max floating point performance than a skylake when taking vectorization into account (67 Gflop/s per core on skylake vs 41.6 Gflop/s per core on Rome).
For the non vectorial part, the performance per core is analogous on skylake and rome.</p>
</div>
<div class="section" id="memory-architecture">
<h4>Memory architecture<a class="headerlink" href="#memory-architecture" title="Permalink to this headline">¶</a></h4>
<p>The memory bandwith of a Rome node is around 320 GB/s max which imply 2.5GB/s per core ( for comparaison pupose a skylake has a 4GB/s bandwith)</p>
<p>The Rome processor has three levels of NUMA effects :</p>
<ul class="simple">
<li>by ccx : it consists of a group of 4 cores which directly share the L3 cache (and as such have a better access to a data already in cache)</li>
<li>by memory controller : the 8 memory channels of the socket are split in 4 dual channel controllers, each dedicated to a group of 4 ccx ( 16 core in total) which will have a better access to the memory attached to its controller</li>
<li>by socket : the 64 cores of a socket have a faster access to the memory attached to it than the one on the other socket.</li>
</ul>
<p>The consequences for hybrid MPI/OpenMP code is that a probable good configuration is one of the following :</p>
<ul class="simple">
<li>4 OpenMP by process if your code shared a lot of access between threads in L3 cache</li>
<li>16 OpenMP by process if your code is bound by memory latency</li>
<li>64 or 128 OpenMP by process if your code already use a first touch allocation</li>
</ul>
</div>
<div class="section" id="network">
<h4>Network<a class="headerlink" href="#network" title="Permalink to this headline">¶</a></h4>
<p>The network is a 100Gb/s shared between 128 cores. The bandwith per core is around 2.6 times lower than skylake which means that communication heavy full MPI codes may suffer a slowdown when compared to skylake.</p>
</div>
</div>
<div class="section" id="quick-start-for-arm-a64fx">
<h3>Quick start for ARM A64FX<a class="headerlink" href="#quick-start-for-arm-a64fx" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id2">
<h4>Memory architecture<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<p>The memory bandwith of an A64FX node is around 1024Gb/s max which imply ~21Gb/s per core (instead of 4GB/s per core for a skylake partition node).</p>
<p>Its processor has 4 memory controlers each attributed to a group of cores. Each group, called Core Memory Group (CMG), contains 12 contiguous cores that share a single L2 cache (8Mb). Within a CMG, access to data shared between threads is faster than between threads of different CMGs.</p>
<p>Hence one of the most efficient MPI / OpenMP distribution is usually 4 MPI processes with 12 OpenMP threads per node.</p>
</div>
<div class="section" id="id3">
<h4>Network<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h4>
<p>Similarly to the Skylake and Rome partitions, the network bandwidth per node is 100Gb/s. Therefore, the A64FX partition has a network bandwidth per core of ~2Gb/s which is identical to the Skylake partition. In comparison with the Rome partition which has a network bandwidth per core of ~0.8Gb/s.</p>
</div>
<div class="section" id="ssl2-numerical-library">
<h4>SSL2 numerical library<a class="headerlink" href="#ssl2-numerical-library" title="Permalink to this headline">¶</a></h4>
<p>Fujitsu provides a dedicated numerical library, called Fujitsu Scientific Subroutine Library II (SSL2), optimized for A64FX. This library provides linear algebra functions like the Open Blas ones (see below for the associated compilation option).</p>
</div>
<div class="section" id="id4">
<h4>Compilation<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h4>
<p>Fujitsu provide dedicated compilers for A64FX architecture:</p>
<ul class="simple">
<li><strong>fcc</strong> for C</li>
<li><strong>FCC</strong> for C ++</li>
<li><strong>frt</strong> for Fortran</li>
</ul>
<p>The compilation optimization option recommended by the manufacturor, in order to achieve performances, is: <code class="xref std std-option docutils literal notranslate"><span class="pre">-Kfast</span></code>.</p>
<p>Activation of the OpenMP parallelization is done with the option: <code class="xref std std-option docutils literal notranslate"><span class="pre">-Kopenmp</span></code>.
We can condense the two previous options into a single instruction: <code class="xref std std-option docutils literal notranslate"><span class="pre">-Kfast,openmp</span></code>.
Furthermore, the call to the SSL2 numerical library is made with the option: <code class="xref std std-option docutils literal notranslate"><span class="pre">-SSL2</span></code>.</p>
</div>
<div class="section" id="documentation">
<h4>Documentation<a class="headerlink" href="#documentation" title="Permalink to this headline">¶</a></h4>
<p>More information about Fujitsu compilers and error messages can be found in the Fujitsu documentation located at this path.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>/ccc/products/cdc_docs/fujitsu_compiler/
</pre></div>
</div>
</div>
</div>
</div>
<span id="document-toc/fulldoc/User_account"></span><div class="section" id="user-account">
<span id="id1"></span><h2>User account<a class="headerlink" href="#user-account" title="Permalink to this headline">¶</a></h2>
<p>The Irene supercomputer is accessible to scientific users and to CCRT partners.</p>
<p>Academic use is granted through French and European calls for projects:</p>
<ul class="simple">
<li>PRACE calls for proposals: <a class="reference external" href="http://www.prace-ri.eu/hpc-access">http://www.prace-ri.eu/hpc-access</a></li>
<li>DARI calls for proposals: <a class="reference external" href="http://www.edari.fr">http://www.edari.fr</a></li>
</ul>
<div class="section" id="user-account-creation">
<h3>User account creation<a class="headerlink" href="#user-account-creation" title="Permalink to this headline">¶</a></h3>
<p>Each user willing to access the supercomputer needs its own account. For obvious security reasons, you cannot have one account shared by several users.</p>
<p>To create an account, the project leader should fill in and send the form available on the TGCC website to the TGCC Hotline providing the following information:</p>
<ul class="simple">
<li>The users information (name, adress, phone number, email, etc)<ul>
<li>For internships, or CDD’s, the end of validity of the account is required</li>
</ul>
</li>
<li>The project information<ul>
<li>Project name and reference number for PRACE or GENCI projects</li>
<li>Partner name for CCRT accounts</li>
</ul>
</li>
<li>The official technical contact person</li>
<li>The safety officer</li>
<li>Security information</li>
</ul>
<p>The first 6 characters of your password
The connecting IP address or access mode (for CCRT: external CEA, VPN, IP network)</p>
<p>It is recommended to use the interface provided at <a class="reference external" href="https://www-dcc.extra.cea.fr/Tgcc/">https://www-dcc.extra.cea.fr/Tgcc/</a>. It allows you to edit the account creation form interactively. It should then be signed and transmitted to the indicated address.</p>
</div>
<div class="section" id="passwords">
<h3>Passwords<a class="headerlink" href="#passwords" title="Permalink to this headline">¶</a></h3>
<p>A default password is set when your account is created. You will be automatically asked to change it the first time you connect.</p>
<p>Once connected, the password change is done with the <strong class="command">passwd</strong> command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ passwd
Changing password <span class="k">for</span> user &lt;login&gt;.
Current Password: &lt;<span class="nb">type</span> here current password&gt;
New password: &lt;enter new password&gt;
Retype new password: &lt;retype same new password&gt;
passwd: all authentication tokens updated successfully.
</pre></div>
</div>
<p>A password must comply with the following rules:</p>
<ul class="simple">
<li>be at least 12 characters long and use at least 3 distinct characters classes</li>
<li>be renewed after 12 months</li>
<li>previously used password cannot be reused</li>
<li>if you modify your password, you will need to wait 5 days before modifying it again</li>
</ul>
<p>You can check the expiration date of your password with the command <strong class="command">ccc_password_expiration</strong>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_password_expiration
Password <span class="k">for</span> &lt;login&gt;: &lt;<span class="nb">type</span> here current password&gt;
Your password will expire in <span class="m">192</span> days on Fri Mar <span class="m">14</span> <span class="m">11</span>:04:16 <span class="m">2014</span>
</pre></div>
</div>
<p>If you loose your password, contact TGCC Hotline and ask for a password reset.</p>
</div>
<div class="section" id="account-locking-and-account-deletion">
<h3>Account locking and account deletion<a class="headerlink" href="#account-locking-and-account-deletion" title="Permalink to this headline">¶</a></h3>
<p>Accounts may be locked and deleted once it is not used anymore. Here are the rules regarding account locking:</p>
<ul class="simple">
<li>Accounts related to a project (PRACE or GENCI) are locked 30 days after the end of the project.</li>
<li>Any account that is inactive for 6 months will be locked. Activity refers to any connexion to the frontend or a job submission.</li>
<li>If an end date was provided when the account was created, the account will be locket on that date.</li>
<li>We may decide to lock an account temporarily if we consider its usage of the resources is inappropriate. For example, an account that uses too much memory on the login nodes or does not respect some limits on the file systems may be locked. In any case you will receive several warning emails before we actually lock the account.</li>
</ul>
<p>One year after being locked, accounts are <strong>deleted</strong> along with their data.</p>
<p>If your account is locked and you want to unlock it, please send an email to <a class="reference external" href="mailto:hotline&#46;tgcc&#37;&#52;&#48;cea&#46;fr">hotline<span>&#46;</span>tgcc<span>&#64;</span>cea<span>&#46;</span>fr</a> with an half-password of 6 characters.</p>
</div>
</div>
<span id="document-toc/fulldoc/Interactive_access"></span><div class="section" id="interactive-access">
<span id="id1"></span><h2>Interactive access<a class="headerlink" href="#interactive-access" title="Permalink to this headline">¶</a></h2>
<div class="section" id="system-access">
<h3>System access<a class="headerlink" href="#system-access" title="Permalink to this headline">¶</a></h3>
<p>Any user or CCRT partner that has been allocated computing hours or a computing share can access the supercomputer through the Internet (or through its partner network) but there are some prerequisites:</p>
<ul class="simple">
<li>your account has to be created,</li>
<li>If you are not connecting from a CCRT partner network, you need to specify the external IP address from which you will access the machine. Any attempt to connect to the machine from another IP address will fail.</li>
</ul>
<p>Hereafter more information on how to connect to the supercomputer.</p>
<p>The supercomputer can be reached with the Secure SHell (SSH) protocol.</p>
<p>SSH connection to the supercomputer can be established:</p>
<ul class="simple">
<li>on Unix-like OSes (for instance Linux or Mac OS X) with the <strong class="command">ssh</strong> command within a terminal,</li>
<li>on Windows, with <strong class="program">PuTTY</strong> (we advise you to use version &gt;= 0.59 for compatibility).The SSH client will open a terminal on a login node of the supercomputer.</li>
</ul>
<p>The SSH client will open a terminal on a login node of the supercomputer.</p>
<p>Access point depend of the type of node you want to access :</p>
<div class="section" id="skylake-fat-and-hybrid-nodes">
<h4>Skylake, Fat and Hybrid nodes<a class="headerlink" href="#skylake-fat-and-hybrid-nodes" title="Permalink to this headline">¶</a></h4>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">when using this access you wont be able to see any reference to rome or v100 nodes including jobs running on it.
To see Rome and V100 use connection method described in the next section.</p>
</div>
<p>If you own a PRACE user account (authentication with a password):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ssh &lt;login&gt;@irene-eu.ccc.cea.fr
password:
</pre></div>
</div>
<p>If you own a national academic (FR) user account (authentication with a password):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ssh &lt;login&gt;@irene-fr.ccc.cea.fr
password:
</pre></div>
</div>
<p>If you own a CCRT user account (authentication with a password or a SSH key-pair if you connect from a CCRT partner network):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ssh &lt;login&gt;@irene-ccrt.ccc.cea.fr
password:
</pre></div>
</div>
<p>To log out, you can use the Ctrl-d keyboard sequence, or type the <strong class="command">exit</strong> command.</p>
</div>
<div class="section" id="rome-and-v100">
<h4>Rome and V100<a class="headerlink" href="#rome-and-v100" title="Permalink to this headline">¶</a></h4>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">when using this access you wont be able to see any reference to skylake, knl, xlarge or hybrid nodes including jobs running on it.
To see skylake, knl, xlarge and hybrid use connection method described in the previous section.
If you own a PRACE user account (authentication with a password):</p>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ssh &lt;login&gt;@irene-amd-eu.ccc.cea.fr
password:
</pre></div>
</div>
<p>If you own a national academic (FR) user account (authentication with a password):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ssh &lt;login&gt;@irene-amd-fr.ccc.cea.fr
password:
</pre></div>
</div>
<p>If you own a CCRT user account (authentication with a password or a SSH key-pair if you connect from a CCRT partner network):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ssh &lt;login&gt;@irene-amd-ccrt.ccc.cea.fr
password:
</pre></div>
</div>
<p>To log out, you can use the Ctrl-d keyboard sequence, or type the exit command.
Please note that:</p>
<ul class="simple">
<li>Idle connections will be automatically closed after 6 hours of inactivity.</li>
<li>You can only access the supercomputer from your local machine. By default, your local machine is not reachable from the supercomputer to increase the safety of your local environment.</li>
</ul>
<p>Limitation on the memory consumption on the login nodes: A user has a maximum of 8G RAM memory on a login node and all users have a limitation of 120G cumulated memory. If a program is executed on the login node and writes on /dev/shm it will also consume from the quota of 8G. Beyond this threshold a protection system will kill all the running processes including the connection processes, thus closing all user opened shells on the cluster.</p>
</div>
<div class="section" id="ssh-fingerprint">
<h4>SSH fingerprint<a class="headerlink" href="#ssh-fingerprint" title="Permalink to this headline">¶</a></h4>
<p>If a strict host key checking setting is enabled in your local OpenSSH configuration, you will have to register our system SSH fingerprint before your first connection:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ssh-keyscan irene.ccc.cea.fr &gt;&gt;~/.ssh/known_hosts
</pre></div>
</div>
<p>You can verify the SSH fingerprint registered for the system in your local OpenSSH configuration with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ssh-keygen -l -F irene.ccc.cea.fr
</pre></div>
</div>
<p>If we advertise a SSH fingerprint change, you can revoke previously registered fingerprint in your local OpenSSH configuration with either commands:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ssh-keygen -R irene.ccc.cea.fr
$ sed -i &#39;/irene.ccc.cea.fr/d&#39; ~/.ssh/known_hosts
</pre></div>
</div>
<p>To make you sure that the system you access is authentic, the SSH fingerprint presented to you should be:</p>
<ul class="simple">
<li>ECDSA key for irene.ccc.cea.fr, irene-fr.ccc.cea.fr, irene-ccrt.ccc.cea.fr, irene-ccrt.ccc.cea.fr or irene-eu.ccc.cea.fr:</li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>e7:2c:bb:c8:c3:ab:c3:9f:52:d5:50:a2:de:9a:2b:a7 <span class="o">(</span>MD5<span class="o">)</span>
knJaymnaa0dOL9GosYKfqntMs/zahoRSisiYLQz6WxY <span class="o">(</span>SHA256<span class="o">)</span>
</pre></div>
</div>
<ul class="simple">
<li>RSA key for irene.ccc.cea.fr or irene-fr.ccc.cea.fr:</li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">80</span>:5b:bf:1b:26:1b:b5:55:b3:fe:b6:ae:2b:05:09:f8 <span class="o">(</span>MD5<span class="o">)</span>
ZXohIopQqdipjXgZzladjpw8bg5Lxa1ilU1qSqqSRHQ <span class="o">(</span>SHA256<span class="o">)</span>
</pre></div>
</div>
<ul class="simple">
<li>RSA key for irene-ccrt.ccc.cea.fr:</li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>d5:33:c8:06:a6:54:7f:6a:ce:f8:0e:6d:36:f7:e4:e3 <span class="o">(</span>MD5<span class="o">)</span>
D5Cnp4HXnqg4nPPAwraKIpL/wXudnzS6a8XZW7FzA4c <span class="o">(</span>SHA256<span class="o">)</span>
</pre></div>
</div>
<ul class="simple">
<li>RSA key for irene-eu.ccc.cea.fr:</li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>3e:c4:0d:3b:c1:ad:df:b6:db:50:82:5d:7b:3f:bd:48 <span class="o">(</span>MD5<span class="o">)</span>
7WbUFzLzhX9zM2WLMq+RsuxU2Sji0dzORxR5O6TePB4 <span class="o">(</span>SHA256<span class="o">)</span>
</pre></div>
</div>
</div>
<div class="section" id="x11-connections">
<h4>X11 connections<a class="headerlink" href="#x11-connections" title="Permalink to this headline">¶</a></h4>
<p>If you need a graphical environment, you must forward the graphical protocol (X11) on your SSH connection. SSH provides the options <code class="xref std std-option docutils literal notranslate"><span class="pre">-X</span></code> and <code class="xref std std-option docutils literal notranslate"><span class="pre">-Y</span></code> to enable X11 protocol forwarding. For instance:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ssh -X &lt;login&gt;@irene.ccc.cea.fr
</pre></div>
</div>
<p>After 10 hours, you will need to renew your security privileges if you want to keep using graphical resources, by using the <strong class="command">kinit -R</strong> command.</p>
<p>Note that X11 forwarding should be enabled with caution. Connecting with X11 forwarding opens a channel from the server back to your graphical desktop environment. It means that if system is compromised, someone may access your local environment and spy on your activities.</p>
<p>Since this is a security issue, by default, X11 forwarding enabled with <code class="xref std std-option docutils literal notranslate"><span class="pre">-X</span></code> option is subjected to some restrictions by the system. This may cause some graphical software to fail. If this is the case, try connecting with <code class="xref std std-option docutils literal notranslate"><span class="pre">-Y</span></code>.</p>
<p>By using <code class="xref std std-option docutils literal notranslate"><span class="pre">-Y</span></code> instead of <code class="xref std std-option docutils literal notranslate"><span class="pre">-X</span></code>, the server is considered as “trusted”. The restrictions are then disabled so this mode should be used with particular caution.</p>
<p>Please refer to SSH man-pages for details.</p>
</div>
<div class="section" id="registering-an-external-host-to-connect-to-the-computing-center">
<h4>Registering an external host to connect to the computing center<a class="headerlink" href="#registering-an-external-host-to-connect-to-the-computing-center" title="Permalink to this headline">¶</a></h4>
<p>If you are not connecting from a CCRT partner network, you need to register the external host from which you will access the computing center. To declare an external host, you need to provide the following details to the TGCC Hotline:</p>
<ul class="simple">
<li>the <strong>IP address</strong> of the external host you will connect from; this IP address should be declared in a public DNS and should point to a public FQDN</li>
<li>the <strong>Fully Qualified Domain Name</strong> (FQDN) associated to the IP address; the external host you declare must have a public FQDN associated to its IP address</li>
<li>the <strong>contact information of your Security Officer</strong>; This person should guarantee that the configuration of the external host you register complies with the latest computer security practices and norms</li>
</ul>
<p>The above information have to be transmitted to register an external host to connect to the computing center. Your Security Officer and your Project Leader have to validate by mail to the TGCC Hotline your request.</p>
</div>
<div class="section" id="ssh-public-key-management">
<h4>SSH public key management<a class="headerlink" href="#ssh-public-key-management" title="Permalink to this headline">¶</a></h4>
<p><strong>For users connecting through a CCRT partners network</strong>, the security policy was enforced to use public-key cryptography. Key pairs will now have a validity period of one year and each user will be allowed a maximum number of five public keys.</p>
<p>Key pairs are still managed through the <code class="file docutils literal notranslate"><span class="pre">.ssh/authorized_keys</span></code> file. However, any change must now be followed by a synchronization request by email to the TGCC Hotline for immediate recognition. This synchronization will allow the new keys to be validated and registered in the authentication database used for the SSH access points.</p>
<div class="section" id="add-an-ssh-public-key">
<h5>Add an SSH public key<a class="headerlink" href="#add-an-ssh-public-key" title="Permalink to this headline">¶</a></h5>
<p>Any user connecting from a CCRT partners network and willing to connect to the supercomputer with an SSH public key should:</p>
<ul class="simple">
<li>add the specified SSH public key to the <code class="file docutils literal notranslate"><span class="pre">~/.ssh/authorized_keys</span></code> file on his CCRT account</li>
<li>request a synchronization of the <code class="file docutils literal notranslate"><span class="pre">.authorized_keys</span></code> file by sending an email to <a class="reference external" href="mailto:hotline&#46;tgcc&#37;&#52;&#48;cea&#46;fr">hotline<span>&#46;</span>tgcc<span>&#64;</span>cea<span>&#46;</span>fr</a></li>
</ul>
<p>Here is an example of the different steps to follow. All these steps are executed on the user’s local workstation.</p>
<ul class="simple">
<li>generate a key pair for connection to irene</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ssh-keygen -b 4096 -f ~/.ssh/id_rsa_ccrt
Generating public/private rsa key pair.
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in ~/.ssh/id_rsa_ccrt.
Your public key has been saved in ~/.ssh/id_rsa_ccrt.pub.
The key fingerprint is:
55:f9:8b:42:99:ec:a8:6c:1d:48:35:73:de:2f:e5:f9 login@myhost
The key&#39;s randomart image is:
+--[ RSA 4096]----+
|            ..   |
|        + ...    |
|       . *.+ .   |
|      .  .* . o  |
|     . .S+   = o |
|      . o o o =  |
|     . o . . . . |
|      + .       E|
|     .           |
+-----------------+
</pre></div>
</div>
<ul class="simple">
<li>associate the key pair to the irene connection in your <code class="file docutils literal notranslate"><span class="pre">~/.ssh/config</span></code> on your local workstation</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ vim .ssh/config
$ grep -A7 irene .ssh/config
Host irene*
    User login
    IdentityFile ~/.ssh/id_rsa_ccrt
    IdentitiesOnly yes
    PubKeyAuthentication yes
    PasswordAuthentication yes
    GSSAPIAuthentication no
</pre></div>
</div>
<ul class="simple">
<li>add the public key to the <code class="file docutils literal notranslate"><span class="pre">authorized_keys</span></code> file in the user’s home directory</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cat ~/.ssh/id_rsa_ccrt.pub | ssh login@irene.ccc.cea.fr &quot;cat - &gt; ~/.ssh/authorized_keys&quot;
login@irene.ccc.cea.fr&#39;s password:
</pre></div>
</div>
<ul class="simple">
<li>request the synchronization of the allowed public keys list for the user’s login. Here is a template of the mail to send to <a class="reference external" href="mailto:hotline&#46;tgcc&#37;&#52;&#48;cea&#46;fr">hotline<span>&#46;</span>tgcc<span>&#64;</span>cea<span>&#46;</span>fr</a></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Subject : Public Keys synchronization for user &#39;login&#39;

&gt; Dear TGCC Hotline,
&gt;
&gt; I have just modified my ~/.ssh/authorized_keys file. Please, synchronize its content to your authentication infrastructure.
&gt;
&gt; Thanks in advance.
&gt; Regards,
</pre></div>
</div>
</div>
<div class="section" id="remove-an-ssh-public-key">
<h5>Remove an SSH public key<a class="headerlink" href="#remove-an-ssh-public-key" title="Permalink to this headline">¶</a></h5>
<p>Any user willing to remove an SSH public key from the list of authorized public keys should:</p>
<ul class="simple">
<li>remove the specified SSH public key from the <code class="file docutils literal notranslate"><span class="pre">~/.ssh/authorized_keys</span></code> file on his CCRT account</li>
<li>request a synchronization of the <code class="file docutils literal notranslate"><span class="pre">.authorized_keys</span></code> file by sending an email to <a class="reference external" href="mailto:hotline&#46;tgcc&#37;&#52;&#48;cea&#46;fr">hotline<span>&#46;</span>tgcc<span>&#64;</span>cea<span>&#46;</span>fr</a></li>
</ul>
<p>Here is a template of the mail to send to <a class="reference external" href="mailto:hotline&#46;tgcc&#37;&#52;&#48;cea&#46;fr">hotline<span>&#46;</span>tgcc<span>&#64;</span>cea<span>&#46;</span>fr</a></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Subject : Public Keys synchronization for user &#39;login&#39;

Dear TGCC Hotline,
&gt;
&gt; I have just modified my ~/.ssh/authorized_keys file. Please, synchronize its content to your authentication infrastructure.
&gt;
&gt; Thanks in advance.
&gt; Regards,
</pre></div>
</div>
</div>
<div class="section" id="list-available-ssh-public-keys">
<h5>List available SSH public keys<a class="headerlink" href="#list-available-ssh-public-keys" title="Permalink to this headline">¶</a></h5>
<p>Listing all the available public keys associated to your account can be done from a login node by executing one of the following commands:</p>
<ul class="simple">
<li>list all valid public keys allowing to connect the supercomputer :</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ssh-ldap-pubkey -u login -V valid list
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAgEAulQnUFly4... login@mynhost expire=2016-03-31
</pre></div>
</div>
<ul class="simple">
<li>list all expired public keys that do not allow to connect to the supercomputer:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ssh-ldap-pubkey -u login -V expired list
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAxoqrkZdj4... login@myphost expire=2015-01-26
</pre></div>
</div>
<ul class="simple">
<li>list all valid public keys that are due to expire within 30 days</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ssh-ldap-pubkey -u login -V expire -e 30 list
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAgEAulQnUFly... login@myhost expire=2015-04-25
</pre></div>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Once a public key is removed by a user, it is saved in TGCC infrastructure for the record but does not allow to connect anymore.</p>
</div>
</div>
<div class="section" id="restore-the-ssh-authorized-keys-file">
<h5>Restore the .ssh/authorized_keys file<a class="headerlink" href="#restore-the-ssh-authorized-keys-file" title="Permalink to this headline">¶</a></h5>
<p>If your .ssh/authorized_keys is lost/corrupted, it can be restored thanks to the LDAP data with the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ssh-ldap-pubkey list -u login &gt; ~/.ssh/authorized_keys
</pre></div>
</div>
<p>Once it has been restored, the authorized_keys file can be used again to add or remove public keys before any synchronisation request to the Hotline.</p>
</div>
</div>
<div class="section" id="login-node-load-balancing">
<h4>Login node load-balancing<a class="headerlink" href="#login-node-load-balancing" title="Permalink to this headline">¶</a></h4>
<p>When connecting to the supercomputer with its regular DNS name (irene.ccc.cea.fr), a user is automatically directed to one of the reachable login nodes based on the host he is coming from. So the subsequent connections from the same host will be directed to the same login node. If you want to connect to a specific login node, a specific DNS name has to be used:</p>
<ul class="simple">
<li>If you own a CCRT user account, these DNS names are:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">irene</span><span class="o">-</span><span class="n">log1</span><span class="o">.</span><span class="n">ccc</span><span class="o">.</span><span class="n">cea</span><span class="o">.</span><span class="n">fr</span>
<span class="n">irene</span><span class="o">-</span><span class="n">log2</span><span class="o">.</span><span class="n">ccc</span><span class="o">.</span><span class="n">cea</span><span class="o">.</span><span class="n">fr</span>
<span class="n">irene</span><span class="o">-</span><span class="n">log3</span><span class="o">.</span><span class="n">ccc</span><span class="o">.</span><span class="n">cea</span><span class="o">.</span><span class="n">fr</span>
</pre></div>
</div>
</div>
<div class="section" id="ssh-session-multiplexing">
<h4>SSH session multiplexing<a class="headerlink" href="#ssh-session-multiplexing" title="Permalink to this headline">¶</a></h4>
<p>SSH session multiplexing allows an existing connection to the computing center to be reused without re-authentication to the computing center. Anyone accessing the machine where the connection to the computing center is initiated can then reuse a multiplexed connection and access the computing center. This feature is available only when connecting from a CCRT partner network.</p>
</div>
</div>
<div class="section" id="login-nodes-usage">
<h3>Login nodes usage<a class="headerlink" href="#login-nodes-usage" title="Permalink to this headline">¶</a></h3>
<p>When you connect to the supercomputer, you are directed to one of the login nodes of the machine. Many users are simultaneously connected to these login nodes. Since their resources are shared it is important to respect some standards of good practice.</p>
<div class="section" id="usage-limit-on-login-nodes">
<h4>Usage limit on login nodes<a class="headerlink" href="#usage-limit-on-login-nodes" title="Permalink to this headline">¶</a></h4>
<p>Login nodes should only be used to interact with the batch manager and to run lightweight tasks. As a rule of thumb, any process or group of processes which would use more CPU power and/or memory than what is available on a basic personal computer should not be executed on a login node. For more demanding interactive tasks, you should allocate dedicated resources on a compute node.</p>
<p>To ensure a satisfying experience for all users, offending tasks are automatically throttled or killed.</p>
</div>
<div class="section" id="interactive-submission">
<h4>Interactive submission<a class="headerlink" href="#interactive-submission" title="Permalink to this headline">¶</a></h4>
<p>There are 2 possible ways of accessing computing resources without using a submission script. <strong class="command">ccc_mprun -K</strong> allows to create the allocation and the job environment while you are still on the login node. It is useful for MPI tests. <strong class="command">ccc_mprun -s</strong> opens a shell on a compute node. It is useful for sequential or multi-threaded work that would be too costly for the login node.</p>
<div class="section" id="allocate-resources-interactively-k">
<h5>Allocate resources interactively (-K)<a class="headerlink" href="#allocate-resources-interactively-k" title="Permalink to this headline">¶</a></h5>
<p>It is possible to work interactively on allocated compute nodes thanks to the option <code class="xref std std-option docutils literal notranslate"><span class="pre">-K</span></code> of <strong class="command">ccc_mprun</strong>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -p partition -n 8 -T 3600 -K
</pre></div>
</div>
<p>This command will create an allocation and start a job.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ echo $SLURM_JOBID
901732
</pre></div>
</div>
<p>Within this reservation, you can run job steps with <strong class="command">ccc_mprun</strong>. Since the compute nodes are already allocated, you will not have to wait.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun hostname
node1569
node1569
node1569
node1569
node1569
node1569
node1569
node1569
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">At this point, you are still connected on the login node. You cannot run your code directly or with mpirun. you have to use <strong class="command">ccc_mprun</strong>!</p>
</div>
<p>Such an allocation is useful when developing an MPI program, in order to be able to test a <strong class="command">ccc_mprun</strong> quickly and several times in a short period.</p>
</div>
<div class="section" id="working-on-a-compute-node-s">
<h5>Working on a compute node (-s)<a class="headerlink" href="#working-on-a-compute-node-s" title="Permalink to this headline">¶</a></h5>
<p>To directly work on the allocated compute nodes, you need to open a shell inside a SLURM allocation. This is possible thanks to the <code class="xref std std-option docutils literal notranslate"><span class="pre">-s</span></code> option:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -p partition -c 16 -s
[node1569 ~]$ hostname
  node1569
</pre></div>
</div>
<p>In this case, the 16 cores of the node node1569 are allocated to you and you are able to run freely on all those cores without disrupting other jobs. It is just like any allocation, the computing hours will be accounted on your project.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>You cannot use multiple nodes in this mode. You are limited to the number of cores in one node.</li>
<li>When you do not need it any longer, do not forget to stop the interactive session with ctrl+d or exit 0.</li>
<li>The computing hours spent in the interactive session will be withdrawn from your project quota.</li>
<li>You can wait for the allocation for a shorter time using the “test” QOS.</li>
</ul>
</div>
<p>This is typically used for costly and punctual tasks such as compiling a large code on 16 cores, post-processing or aggregating output data etc.</p>
<p>At any point, you can use the <strong class="command">hostname</strong> command to check whether you are on a compute node or on a login nodes.</p>
</div>
</div>
<div class="section" id="crontab">
<h4>Crontab<a class="headerlink" href="#crontab" title="Permalink to this headline">¶</a></h4>
<p>Crontab mechanism is available on login nodes in order to execute desired tasks in the background at designated times. A specific version of cron called <strong class="command">crontab</strong> is provided and can be invoked with the regular <strong class="command">crontab</strong> command name. <strong class="command">crontab</strong> adds the ability to manage the crontab content associated to your user account whatever the login node your are connected to, still having this crontab be executed once (only one login node schedules and executes the commands you specify in your crontab).</p>
<p>The command <strong class="command">crontab -e</strong> edits the file which contains the instructions to be launched, and <strong class="command">crontab -r</strong> removes the current crontab. The instructions follow the following format:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mm</span> <span class="n">hh</span> <span class="n">dd</span> <span class="n">MMM</span> <span class="n">DDD</span> <span class="n">task</span> <span class="o">&gt;</span> <span class="n">logfile</span>
</pre></div>
</div>
<p>where mm, hh, dd, MMM represent the minutes, the hours, the day of the month MMM, and DDD the days of every week on which the task ‘task’ is executed. ‘Logfile’ is the log file in which is redirected the standard output. The periodicity of the task must be appropriate to the need, and must not be lower than 5 minutes in order to not over solicit the system. Below are some examples of valid instruction lines:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">0</span> <span class="mi">0</span> <span class="o">*</span> <span class="o">*</span> <span class="mi">1</span> <span class="n">ccc_msub</span> <span class="o">/</span><span class="n">path1</span><span class="o">/</span><span class="n">regression</span><span class="o">.</span><span class="n">sh</span> <span class="o">&gt;&gt;</span> <span class="o">/</span><span class="n">path2</span><span class="o">/</span><span class="n">joblist</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>will submit every Monday at 0:00 the script of submission <code class="file docutils literal notranslate"><span class="pre">regression.sh</span></code>, and writes the JobID in the file <code class="file docutils literal notranslate"><span class="pre">joblist.sh</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">*/</span><span class="mi">10</span> <span class="mi">8</span><span class="o">-</span><span class="mi">18</span> <span class="o">*</span> <span class="o">*</span> <span class="n">mon</span><span class="p">,</span><span class="n">tue</span><span class="p">,</span><span class="n">wed</span><span class="p">,</span><span class="n">thu</span><span class="p">,</span><span class="n">fri</span> <span class="n">clear</span> <span class="o">&gt;</span> <span class="o">/</span><span class="n">dev</span><span class="o">/</span><span class="n">null</span> <span class="mi">2</span><span class="o">&gt;&amp;</span><span class="mi">1</span>
</pre></div>
</div>
<p>clears the shell every ten minutes between 8 a.m. and 6 p.m. during the week, without saving the output.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">0</span> <span class="mi">10</span> <span class="mi">20</span> <span class="mi">12</span> <span class="o">*</span> <span class="n">mkdir</span> <span class="o">/</span><span class="n">path3</span><span class="o">/</span><span class="n">annual_report</span>
</pre></div>
</div>
<p>will create every 20th of December at 10 a.m. the folder ‘annual_report’ in <code class="file docutils literal notranslate"><span class="pre">/path3</span></code>.</p>
</div>
</div>
<div class="section" id="remote-desktop-system-service-nicedcv">
<h3>Remote Desktop System service (NiceDCV)<a class="headerlink" href="#remote-desktop-system-service-nicedcv" title="Permalink to this headline">¶</a></h3>
<p>The Remote Desktop System service on the TGCC supercomputer is based on NiceDCV solution. NiceDCV provides a web site where you can launch the booked graphical session : <a class="reference external" href="https://visu-ccrt.ccc.cea.fr">https://visu-ccrt.ccc.cea.fr</a></p>
<div class="section" id="book-a-session">
<h4>Book a session<a class="headerlink" href="#book-a-session" title="Permalink to this headline">¶</a></h4>
<p>There are two types of sessions : a “virtual” session and a “console” session.</p>
<ul class="simple">
<li>The virtual session is using the GNOME Display Manager (GDM) unlike the console session. The virtual session is by default launched on only one GPU and not on all the GPUs of the node. Therefore, it is possible to launch in parallel as many virtual sessions as the number of available GPUs on the node. Moreover, many users can launch a virtual session on the same node given that they are on the same container.</li>
</ul>
<p>The following command allows to book a virtual session :</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_visu virtual -p partition
</pre></div>
</div>
<ul class="simple">
<li>The console session allows node exclusivity, i.e. all GPUs on the node can be used inside the session. The visualization performance could be faster than on the virtual session (almost 2 times faster).</li>
</ul>
<p>The following command allows to book for a console session :</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_visu console -p partition
</pre></div>
</div>
</div>
<div class="section" id="session-access">
<h4>Session access<a class="headerlink" href="#session-access" title="Permalink to this headline">¶</a></h4>
<p>Once the reservation is booked from the above commands, a URL is given in the standard output. To access the graphical session, launch this URL on your browser. A page opens in which you are asked to give your Irene credentials. Then, to acess the allocated session, you have two options:</p>
<ul class="simple">
<li>The first client (on the left): opens the session inside the brower. You need to give again your Irene credentials.</li>
<li>The second client (on the right): allows to download it. However, you need root access on your machine to be able to install it.</li>
</ul>
<p>Moreover, while the allocation with command <strong class="command">ccc_visu</strong> didn’t expire or hadn’t been cancelled, the session will not be impacted if the client is closed.</p>
</div>
</div>
</div>
<span id="document-toc/fulldoc/Data_spaces"></span><div class="section" id="data-spaces">
<span id="id1"></span><h2>Data spaces<a class="headerlink" href="#data-spaces" title="Permalink to this headline">¶</a></h2>
<p>All user data are stored on file systems reachable from the supercomputer login and compute nodes. Each file system has a purpose: your HOME directory contains user configuration, your SCRATCH directory is intended for temporary computational data sets, etc. To prevent over-usage of the file system capacities, limitations/quotas are set on data space allocated to users or groups. Except for your HOME directory, which is hosted by a NFS file system, user data spaces are stored on Lustre file systems. This section provides data usage guidelines that must be followed, since an inappropriate usage of the file systems might badly affect the overall production of the computing center.</p>
<div class="section" id="available-file-systems">
<h3>Available file systems<a class="headerlink" href="#available-file-systems" title="Permalink to this headline">¶</a></h3>
<p>This section introduces the available file systems with their purpose, their quota policy and their recommended usage.</p>
<p><strong>HOME</strong></p>
<p>The HOME is a slow, small file system with backup that can be used from any machine.</p>
<p>Characteristics:</p>
<ul class="simple">
<li>Type: NFS</li>
<li>Data transfer rate: low</li>
<li>Quota: 3GB/user</li>
<li>Usage: Sources, job submission scripts…</li>
<li>Comments: Data are saved</li>
<li>Access: from all resources of the center</li>
<li>Variable: <span class="target" id="index-0"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">HOME</span></code> or <span class="target" id="index-1"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCFRHOME</span></code></li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>HOME is the only file system without limitation on the number of files (quota on inodes)</li>
<li>The retention time for HOME directories backup is 6 months</li>
<li>The backup files are under the <code class="file docutils literal notranslate"><span class="pre">~/.snapshot</span></code> directory</li>
</ul>
</div>
<p><strong>SCRATCH</strong></p>
<p>The SCRATCH is a very fast, big and automatically purged file system.</p>
<p>Characteristics:</p>
<ul class="simple">
<li>Type: Lustre</li>
<li>Data transfer rate: 300 GB/s</li>
<li>Quota: The quota is defined by group. The command <strong class="command">ccc_quota</strong> provides information about the quota of the groups you belong to</li>
<li>Usage: Data, Code output…</li>
<li>Comments: This filesystem is subject to purge</li>
<li>Access: Local to the supercomputer</li>
<li>Variable: <span class="target" id="index-2"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCCSCRATCHDIR</span></code> or <span class="target" id="index-3"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCFRSCRATCH</span></code></li>
</ul>
<p>The purge policy is as follows:</p>
<ul class="simple">
<li>Files not accessed for 60 days are <strong>automatically</strong> purged</li>
<li>Symbolic links are not purged</li>
<li>Directories that have been empty for more than 30 days are removed</li>
</ul>
<p><strong>WORK</strong></p>
<p>WORK is a fast, medium and permanent file system (but without backup):</p>
<p>Characteristics:</p>
<ul class="simple">
<li>Type: Lustre via routers</li>
<li>Data transfer rate: high (20 GB/s)</li>
<li>Quota: 5 TB and 500 000 files/user</li>
<li>Usage: Commonly used file (Source code, Binary…)</li>
<li>Comments: Neither purged nor saved (tar your important data to STORE)</li>
<li>Access: from all resources of the center</li>
<li>Variable: <span class="target" id="index-4"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCCWORKDIR</span></code> or <span class="target" id="index-5"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCFRWORK</span></code></li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>WORK is smaller than SCRATCH, it’s only managed through quota.</li>
<li>This space is not purged but <strong>not saved</strong> (regularly backup your important data as tar files in STORE)</li>
</ul>
</div>
<p><strong>STORE</strong></p>
<p>STORE is a huge storage file system</p>
<p>Characteristics:</p>
<ul class="simple">
<li>Type: Lustre + HSM</li>
<li>Data transfer rate: high (30 GB/s)</li>
<li>Quota: 500 000 files/user, expected file size range 10GB-1TB</li>
<li>Usage: To store of large files (direct computation allowed in that case) or packed data (tar files…)</li>
<li>Comments: Migration to hsm relies on file modification time: avoid using <strong class="command">cp</strong> options like <code class="xref std std-option docutils literal notranslate"><span class="pre">-p</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-a</span></code> …</li>
<li>Access: from all resources of the center</li>
<li>Variable: <span class="target" id="index-6"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCCSTOREDIR</span></code> or <span class="target" id="index-7"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCFRSTORE</span></code></li>
<li>Additional info: Use <strong class="command">ccc_hsm status &lt;file&gt;</strong> to know whether a file is on disk or tape level, and <strong class="command">ccc_hsm get &lt;file&gt;</strong> to preload file from tape before a computation</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>STORE has no limit on the disk usage (quota on space)</li>
<li>STORE usage is monitored by a scoring system</li>
<li>An <abbr title="Hierarchical Storage Management">HSM</abbr> is a data storage system which automatically moves data between high-speed and low-speed storage media. In our case, the high speed device is a Lustre file system and the low speed device consists of magnetic tape drives. Data copied to the HSM filesystem will be moved to magnetic tapes (usually depending on the modification date of the files). Once the data is stored on tape, accessing it will be slower.</li>
</ul>
</div>
<p><strong>TMP</strong></p>
<p>TMP is a local, fast file system but of limited size.</p>
<p>Characteristics:</p>
<ul class="simple">
<li>Type: zram (RAM)</li>
<li>Data transfer rate: very high (&gt;1Go/s) and very low latency</li>
<li>Size: 16 Go</li>
<li>Usage: Temporary files during a job</li>
<li>Comments: Purge after each job</li>
<li>Access: Local within each node</li>
<li>Variable: <span class="target" id="index-8"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCCTMPDIR</span></code> or <span class="target" id="index-9"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCFRTMP</span></code></li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>TMP allow fast write and read for local needs.</li>
<li>TMP is local to the node. Only jobs/processes within the same node have access to the same files.</li>
<li>Write files in TMP will reduce the amount of available RAM.</li>
</ul>
</div>
<p><strong>SHM</strong></p>
<p>SHM is a very fast, local file system but of limited size.</p>
<p>Characteristics:</p>
<ul class="simple">
<li>Type: tmpfs (RAM, block size 4Ko)</li>
<li>Data transfer rate: very high (&gt;1Go/s) and very low latency</li>
<li>Size: 50% of RAM (ie: 94 Go on skylake)</li>
<li>Usage: Temporary files during compute; can be used as a large cache</li>
<li>Comments: Purge after each job</li>
<li>Access: Local within each node</li>
<li>Variable: <span class="target" id="index-10"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCCSHMDIR</span></code></li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>SHM allow very fast file access.</li>
<li>SHM is local to the node. Only jobs/processes within the same node have access to the same files.</li>
<li>Write files in SHM will reduce the amount of available RAM.</li>
</ul>
</div>
<div class="section" id="specifity-for-n4hc-users">
<h4>Specifity for N4HC users<a class="headerlink" href="#specifity-for-n4hc-users" title="Permalink to this headline">¶</a></h4>
<p><strong>WORK</strong></p>
<p>Characteristics:</p>
<ul class="simple">
<li>Type: Lustre via routers, SSD storage (FLASH)</li>
<li>Data transfer rate: high (110 GB/s)</li>
<li>Quota: 5 TB and 500 000 files/user</li>
<li>Usage: Commonly used file (Source code, Binary,…)</li>
<li>Comments: Neither purged nor saved (tar your important data to STORE), random access efficiency</li>
<li>Access: from all resources of the center</li>
<li>Variable: $CCCWORKDIR or $CCFRWORK</li>
</ul>
</div>
</div>
<div class="section" id="quota">
<span id="id2"></span><h3>Quota<a class="headerlink" href="#quota" title="Permalink to this headline">¶</a></h3>
<p>Because file systems are shared between many users, restrictions are enforced on disk usage. The disk quotas and your current usage (space and number of files or directories) are shown by the command <strong class="command">ccc_quota</strong>. This command also displays a score rating your usage on Lustre + HSM file systems (“Account scoring”).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_quota
Disk quotas for user &lt;login&gt; (uid &lt;uid&gt;):

             ============ SPACE =============  ============ INODE =============
 Filesystem     usage    soft    hard   grace   entries    soft    hard   grace
 ----------  -------- ------- ------- -------  -------- ------- ------- -------
       HOME     2.06G      5G      5G       -   115.79k       -       -       -
      STORE   674.28G       -       -       -        25       -       -       -
       WORK    79.44G       -       -       -    334.3k       -       -       -
    SCRATCH   845.93G       -       -       -     1.06M       -       -       -

Disk quotas for data space &lt;group&gt; (gid &lt;gid&gt;):

             ============ SPACE =============  ============ INODE =============
 Filesystem     usage    soft    hard   grace   entries    soft    hard   grace
 ----------  -------- ------- ------- -------  -------- ------- ------- -------
       HOME         -       -       -       -         -       -       -       -
      STORE     2.56T       -       -       -    35.87k    100k  100.1k       -
       WORK     6.95T    110T  110.1T       -     3.97M      7M   7.05M       -
    SCRATCH   728.02G    100T  100.1T       -     1.34M      2M   2.05M       -

STORE filesystem scoring for group &lt;group&gt; (gid &lt;gid&gt;):

 ================= SPACE ================  ============== INODE ===============
    usage  files&lt;32M  files&lt;1G  avg_fsize   entries     dir  symlink  non_files
 -------- ---------- --------- ----------  -------- ------- -------- ----------
   16.97T     92.09%    92.33%       626M    35.87k    6235     1204     20.74%
          ---------- --------- ----------                            ----------
                 0/7 +     0/3 +      2/4                            +      3/6
          ====================================  TOTAL SCORE: 5/20 =============
</pre></div>
</div>
<div class="section" id="disk-quotas">
<h4>Disk quotas<a class="headerlink" href="#disk-quotas" title="Permalink to this headline">¶</a></h4>
<p>Three parameters govern the disk quotas:</p>
<ul class="simple">
<li><em>soft limit</em>: when your usage reaches this limit you will be warned.</li>
<li><em>hard limit</em>: when your usage reaches this limit you will be unable to write new files.</li>
<li><em>grace period</em>: the period during which you can exceed the <em>soft limit</em>.</li>
</ul>
<p>Within the computing center, the quotas have been defined as follows:</p>
<ul class="simple">
<li>the <em>grace period</em> is 1 week. It means that once you have reached the soft limit, a countdown starts for a week. By the end of the countdown, if you have not brought your quota under the soft limit, you will not be able to create new files anymore. Once you get back under the soft limit, the countdown is reset.</li>
<li><em>soft limit</em> and <em>hard limit</em> are almost always the same, which means that checking your current usage to be below this limit is enough.</li>
<li>those limits have been set <em>on both the number of files (inode) and the data usage (space)</em> for <em>WORK</em> and <em>SCRATCH</em>.</li>
<li>those limits have been set <em>only on the data usage (space)</em> for <em>HOME</em>.</li>
<li>those limits have been set <em>only on the number of files (inode)</em> for <em>Lustre + HSM file systems (CCCSTOREDIR)</em>.</li>
<li>Lustre + HSM file systems (CCCSTOREDIR) have a scoring system instead of space limitations.</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The section <em>Disk quotas</em> displayed by <strong class="command">ccc_quota</strong> is updated in real-time.</p>
</div>
</div>
<div class="section" id="account-scoring">
<h4>Account scoring<a class="headerlink" href="#account-scoring" title="Permalink to this headline">¶</a></h4>
<p>On Lustre + HSM file systems (CCCSTOREDIR), a score reflects how close you are from the recommended usage.</p>
<p>4 criteria are defined and are each granted a certain amount of points. Here are those criteria:</p>
<ul class="simple">
<li>inodes should be regular files (not directories nor symbolic links) for 6 points,</li>
<li>files should be bigger than 32MB for 7 points,</li>
<li>files should be bigger than 1GB for 3 points,</li>
<li>the average file size should be high enough for 4 points.
More specifically, with 64MB, 128MB, 1GB and 8GB as limits, you get one point per limit exceeded by your average file size.
For example, an average file size of 2GB will give you a partial score of 3/4.</li>
</ul>
<p>The command <strong class="command">ccc_quota</strong> shows how well you match the criteria in the <em>Account Scoring</em> section:</p>
<ul class="simple">
<li>current usage (space and inodes)</li>
<li>percentages of files not matching the criteria</li>
<li>global score and the partial scores.</li>
</ul>
<p>Here is an example of scoring:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">STORE</span> <span class="n">filesystem</span> <span class="n">scoring</span> <span class="k">for</span> <span class="n">group</span> <span class="o">&lt;</span><span class="n">group</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">gid</span> <span class="o">&lt;</span><span class="n">gid</span><span class="o">&gt;</span><span class="p">):</span>

 <span class="o">=================</span> <span class="n">SPACE</span> <span class="o">================</span>  <span class="o">==============</span> <span class="n">INODE</span> <span class="o">===============</span>
    <span class="n">usage</span>  <span class="n">files</span><span class="o">&lt;</span><span class="mi">32</span><span class="n">M</span>  <span class="n">files</span><span class="o">&lt;</span><span class="mi">1</span><span class="n">G</span>  <span class="n">avg_fsize</span>   <span class="n">entries</span>     <span class="nb">dir</span>  <span class="n">symlink</span>  <span class="n">non_files</span>
 <span class="o">--------</span> <span class="o">----------</span> <span class="o">---------</span> <span class="o">----------</span>  <span class="o">--------</span> <span class="o">-------</span> <span class="o">--------</span> <span class="o">----------</span>
   <span class="mf">16.97</span><span class="n">T</span>     <span class="mf">92.09</span><span class="o">%</span>    <span class="mf">92.33</span><span class="o">%</span>       <span class="mi">626</span><span class="n">M</span>    <span class="mf">35.87</span><span class="n">k</span>    <span class="mi">6235</span>     <span class="mi">1204</span>     <span class="mf">20.74</span><span class="o">%</span>
          <span class="o">----------</span> <span class="o">---------</span> <span class="o">----------</span>                            <span class="o">----------</span>
                 <span class="mi">0</span><span class="o">/</span><span class="mi">7</span> <span class="o">+</span>     <span class="mi">0</span><span class="o">/</span><span class="mi">3</span> <span class="o">+</span>      <span class="mi">2</span><span class="o">/</span><span class="mi">4</span>                            <span class="o">+</span>      <span class="mi">3</span><span class="o">/</span><span class="mi">6</span>
          <span class="o">====================================</span>  <span class="n">TOTAL</span> <span class="n">SCORE</span><span class="p">:</span> <span class="mi">5</span><span class="o">/</span><span class="mi">20</span> <span class="o">=============</span>
</pre></div>
</div>
<ul class="simple">
<li>For instance, for the criteria “non_files”, the score is of 3 out of 6</li>
<li>The related number is 20.74%: this is the proportion of your inodes that are directories of links.</li>
<li>These 20.74% represent three points lost out of 6</li>
<li>The partial score of the criteria is computed and is then 3/6</li>
<li>Finally all partial scores are summed and constitute a global score</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ex</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="o">+</span><span class="mi">0</span><span class="o">+</span><span class="mi">2</span><span class="o">+</span><span class="mi">3</span><span class="p">)</span><span class="o">=</span><span class="mi">5</span> <span class="n">points</span> <span class="n">over</span> <span class="p">(</span><span class="mi">7</span><span class="o">+</span><span class="mi">3</span><span class="o">+</span><span class="mi">4</span><span class="o">+</span><span class="mi">6</span><span class="p">)</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">that</span> <span class="ow">is</span> <span class="n">to</span> <span class="n">say</span> <span class="mi">5</span><span class="o">/</span><span class="mi">20</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The section <em>Account Scoring</em> displayed by <strong class="command">ccc_quota</strong> is updated daily (around 13:00 CET/CEST).</p>
</div>
</div>
</div>
<div class="section" id="data-protection">
<h3>Data protection<a class="headerlink" href="#data-protection" title="Permalink to this headline">¶</a></h3>
<div class="section" id="containers">
<h4>Containers<a class="headerlink" href="#containers" title="Permalink to this headline">¶</a></h4>
<p>On each filesystem, a container structure protects your personal directory. Containers gather a community of similar users. They act as locks that stop any user from outside, thus defining a trusting perimeter:</p>
<ul class="simple">
<li>Users from the same container can collaborate and exchange data</li>
<li>Users from different containers cannot collaborate or exchange data</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Containers are based on paths like: <code class="file docutils literal notranslate"><span class="pre">/ccc/&lt;filesystem&gt;/&lt;container&gt;/&lt;group&gt;/&lt;login&gt;</span></code>.</p>
</div>
</div>
<div class="section" id="umask">
<h4>Umask<a class="headerlink" href="#umask" title="Permalink to this headline">¶</a></h4>
<p>The command <strong class="command">umask</strong> sets the file permissions masks for newly created files.</p>
<p>The default value for umask is <strong>0027</strong> or <strong>u=rwx,g=rx,o=</strong>.</p>
</div>
</div>
<div class="section" id="personal-spaces">
<h3>Personal Spaces<a class="headerlink" href="#personal-spaces" title="Permalink to this headline">¶</a></h3>
<p>Every user of the computing center has a personal space in their primary work group, on each available filesystems: NFS home, local and global Lustre filesystems.</p>
<p>The command <strong class="command">ccc_home</strong> displays the personal directories for your login.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_home -a
$HOME:              /ccc/home/contxxx/group/login
$CCCSCRATCHDIR:     /ccc/scratch/contxxx/group/login
$CCCWORKDIR:        /ccc/work/contxxx/group/login
$CCCSTOREDIR:       /ccc/store/contxxx/group/login
</pre></div>
</div>
<p>By default, members of the same work group have read access to each other’s personal spaces.</p>
</div>
<div class="section" id="shared-spaces">
<h3>Shared Spaces<a class="headerlink" href="#shared-spaces" title="Permalink to this headline">¶</a></h3>
<p>A shared space is a powerful tool to share environment, installations and results between users or a community. It mainly consists of data storage with additional tools to enhance or manage it. Shared spaces may be used within a community to share:</p>
<ul class="simple">
<li>Data: input files, configuration files, results, logs</li>
<li>Products or compute codes</li>
</ul>
<div class="section" id="accessibility-and-procedures">
<h4>Accessibility and procedures<a class="headerlink" href="#accessibility-and-procedures" title="Permalink to this headline">¶</a></h4>
<p>A shared space shall be administratively managed by a unique member of the community. Other members are divided into two groups:</p>
<ul class="simple">
<li><em>Staff</em> members have read-write permission. This means they can write, setup and maintain the shared space.</li>
<li>The other members of the community are basic <em>users</em>. They have read-only permission.</li>
</ul>
<p>An <em>open shared space</em> is a shared space for which every user is considered <em>staff</em> and has write permission.</p>
<p>Every request or question must be directed to the hotline (<a class="reference external" href="mailto:hotline&#46;tgcc&#37;&#52;&#48;cea&#46;fr">hotline<span>&#46;</span>tgcc<span>&#64;</span>cea<span>&#46;</span>fr</a>). Please note that the following operations may only be performed by the hotline:</p>
<ul class="simple">
<li>Add a new user: The request has to be made by the shared space manager</li>
<li>Remove a user: The request has to be made by the said user or the manager</li>
<li>Change ownership of files: This needs approval from either the previous and new owner of the files or from the manager.</li>
</ul>
<p>The <a class="reference external" href="https://www-tgcc.ccc.cea.fr/docs/TGCC-shared-space-form-v4.pdf">shared space creation form</a> can be found on the tgcc web site.</p>
</div>
<div class="section" id="implementation">
<h4>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h4>
<div class="section" id="file-systems">
<h5>File systems<a class="headerlink" href="#file-systems" title="Permalink to this headline">¶</a></h5>
<p>Regarding file systems, a shared space is like the already existing personal space: it is spread over 4 different file systems (HOME, CCCSCRATCH, CCCWORK and CCCSTORE). For a shared space called <em>SHSPACE</em>, the names to access the 4 different storage spaces will be:</p>
<ul class="simple">
<li><span class="target" id="index-11"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$&lt;SHSPACE&gt;_HOME</span></code> or <span class="target" id="index-12"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$&lt;SHSPACE&gt;_CCFRHOME</span></code></li>
<li><span class="target" id="index-13"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$&lt;SHSPACE&gt;_CCCSCRATCHDIR</span></code> or <span class="target" id="index-14"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$&lt;SHSPACE&gt;_CCFRSCRATCH</span></code></li>
<li><span class="target" id="index-15"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$&lt;SHSPACE&gt;_CCCWORKDIR</span></code> or <span class="target" id="index-16"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$&lt;SHSPACE&gt;_CCFRWORK</span></code></li>
<li><span class="target" id="index-17"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$&lt;SHSPACE&gt;_CCCSTOREDIR</span></code> or <span class="target" id="index-18"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$&lt;SHSPACE&gt;_CCFRSTORE</span></code></li>
</ul>
<p>Those environment variables also exist for your personal space: they are named <span class="target" id="index-19"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">OWN_HOME</span></code>, <span class="target" id="index-20"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">OWN_SCRATCHDIR</span></code>, etc. and are defined in your default environment.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You may be a member of several shared spaces.</p>
</div>
<div class="figure align-default" id="id3">
<img alt="700 px | Shared storage space" src="_images/Shared_space_FileSystems.png" />
<p class="caption"><span class="caption-text">Shared storage space</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="limitations-and-quota">
<h5>Limitations and quota<a class="headerlink" href="#limitations-and-quota" title="Permalink to this headline">¶</a></h5>
<p>Several limitations rule a shared space:</p>
<ul class="simple">
<li>It cannot be shared between users of different containers</li>
<li>It is not a user account and it does not come with computing hours</li>
</ul>
<p>Please note that shared file systems have no specific quota. The inodes stored on any file system will impact the quota of their owner.</p>
<div class="figure align-default" id="id4">
<img alt="400 px | Shared space quota" src="_images/Shared_space_Quota.png" />
<p class="caption"><span class="caption-text">Shared space quota</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
<p>For France Genomique users, the quota limitation is different. Each France Genomique shared space has its own quota on each filesystem. Thus the users individual quota is not affected.</p>
</div>
<div class="section" id="unix-groups">
<h5>Unix groups<a class="headerlink" href="#unix-groups" title="Permalink to this headline">¶</a></h5>
<p>As for the personal space, read and write permissions are managed through unix groups. If we consider again a shared space called &lt;shspace&gt;, two unix groups are created:</p>
<ul class="simple">
<li><strong>shspace</strong> for all non staff users</li>
<li><strong>shspace_w</strong> for staff members</li>
</ul>
<p>If shspace is an open space, only the shspace unix group is created.</p>
<p>This allows staff members to manage the users rights on several directories. For instance, they will be able to make sets of tools, input files or software available as read-only to users. Besides, they may define specific directories where simple users can write their result files to share them with the community.</p>
</div>
</div>
<div class="section" id="tools">
<h4>Tools<a class="headerlink" href="#tools" title="Permalink to this headline">¶</a></h4>
<p>The computing center provides several tools to ease usage and management of shared spaces.</p>
<ul class="simple">
<li>The <strong>datadir/&lt;shspace&gt;</strong> and <strong>dfldatadir/&lt;shspace&gt;</strong> modules offer set environment variables that simplify access to the shared storage spaces.</li>
<li>The <strong>extenv/&lt;shspace&gt;</strong> module helps using shared products or computing codes.</li>
<li>The scripts <strong>ccc_shspace_chmod</strong> and <strong>ccc_shspace_modck</strong>, along with the module <strong>collwork</strong>, allow to test and set the unix permissions of files and directories in the shared space.</li>
</ul>
<div class="section" id="module-datadir-dfldatadir">
<h5>module datadir/dfldatadir<a class="headerlink" href="#module-datadir-dfldatadir" title="Permalink to this headline">¶</a></h5>
<p>The modules datadir and dfldatadir set environment variables that point to the various storage spaces. Versions of those modules exists for your personal space (own, usually loaded by default), and for each shared space you are member of.</p>
<ul class="simple">
<li>The datadir module sets an environment variable for each data directory available. Several versions of datadir may be loaded simultaneously in your environment.</li>
</ul>
<p>The example below shows the default module datadir/own and the impact of loading datadir/shspace:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module list
Currently Loaded Modulefiles:
1) ccc 2) datadir/own 3) dfldatadir/own

$ echo $OWN_CCCWORKDIR
/ccc/work/contxxx/grp1/user1

$ module load datadir/shspace
load module datadir/shspace (Data Directory)

$ echo $SHSPACE_CCCWORKDIR
/ccc/work/contxxx/shspace/shspace
</pre></div>
</div>
<ul class="simple">
<li>The dfldatadir module sets the default environment variables for the various storage spaces (<span class="target" id="index-21"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCCSCRATCHDIR</span></code>, <span class="target" id="index-22"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCCWORKDIR</span></code>, <span class="target" id="index-23"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCCSTOREDIR</span></code> and their CCFR equivalent).</li>
</ul>
<p>Only one version of dfldatadir can be loaded at a time.</p>
<p>This example shows how to use dfldatadir:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module list
Currently Loaded Modulefiles:
1) ccc 2) datadir/own 3) dfldatadir/own

$ echo $CCCWORKDIR
/ccc/work/contxxx/grp1/user1
</pre></div>
</div>
<p>By default, <span class="target" id="index-24"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$CCCWORKDIR</span></code> (and its CCFR’s equivalent <span class="target" id="index-25"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$CCFRWORK</span></code>) points to your own work directory.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module switch dfldatadir/own dfldatadir/shspace
unload module dfldatadir/own (Default Data Directory)
unload module datadir/own (Data Directory)
load module dfldatadir/shspace (Default Data Directory)
</pre></div>
</div>
<p>Once dfldatadir/shspace is loaded instead of dfldatadir/own, <span class="target" id="index-26"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$CCCWORKDIR</span></code> (and <span class="target" id="index-27"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$CCFRWORK</span></code>) points to the work directory shared by shspace.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ echo $CCCWORKDIR
/ccc/work/contxxx/shspace/shspace
</pre></div>
</div>
<p>Generic variables are set by the dfldatadir module, which point to the datadir/shspace variables without mentioning a specific shspace name. This can be useful in order to create generic scripts adapted to different projects.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ echo $ALL_CCCWORKDIR
/ccc/work/contxxx/shspace/shspace
</pre></div>
</div>
</div>
<div class="section" id="environment-extension">
<h5>Environment extension<a class="headerlink" href="#environment-extension" title="Permalink to this headline">¶</a></h5>
<p>The <strong>extenv</strong> module extends the current user environment. It defines a common environment for all users of a shared space.</p>
<p>Loading the extenv module will:</p>
<ul class="simple">
<li>Set environment variables defining the path to shared products and module files (<span class="target" id="index-28"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SHSPACE_PRODUCTSHOME</span></code>, <span class="target" id="index-29"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SHSPACE_MODULEFILES</span></code>, <span class="target" id="index-30"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SHSPACE_MODULESHOME</span></code>)</li>
<li>Execute an initialization script</li>
<li>Add shared modules to the available modules</li>
</ul>
<p>The environment extension mechanisms uses specific paths. Products installed in the &lt;shspace&gt; shared space should be installed in <span class="target" id="index-31"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$SHSPACE_PRODUCTSHOME</span></code> and the corresponding module files should be in <span class="target" id="index-32"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$SHSPACE_MODULEFILES</span></code>.</p>
<div class="section" id="initialization-file">
<h6>Initialization file<a class="headerlink" href="#initialization-file" title="Permalink to this headline">¶</a></h6>
<p>If a file named <em>init</em> is found in the path defined by <span class="target" id="index-33"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$SHSPACE_MODULESHOME</span></code>, then it is executed each time the extenv/&lt;shspace&gt; module is loaded. This may be helpful to define other common environment variables or to add prerequisites on modules to be used by the community.</p>
<p>For instance the following example defines two environment variables: one is the directory containing input files (<span class="target" id="index-34"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SHSPACE_INPUTDIR</span></code>), and the other is the result directory (<span class="target" id="index-35"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SHSPACE_RESULTDIR</span></code>). It also adds <code class="file docutils literal notranslate"><span class="pre">$SHSPACE_PRODUCTSHOME/tools/bin</span></code> to the <span class="target" id="index-36"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">PATH</span></code> so that the tools installed in <code class="file docutils literal notranslate"><span class="pre">$SHSPACE_PRODUCTSHOME/tools/bin</span></code> are easily available.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cat $SHSPACE_MODULESHOME/init
setenv SHSPACE_INPUTDIR &quot;$env(SHSPACE_CCCWORKDIR)/in&quot;
setenv SHSPACE_RESULTDIR &quot;$env(SHSPACE_CCCSCRATCHDIR)/res&quot;
append-path PATH &quot;$env(SHSPACE_PRODUCTSHOME)/tools/bin&quot;
</pre></div>
</div>
</div>
<div class="section" id="modules">
<h6>Modules<a class="headerlink" href="#modules" title="Permalink to this headline">¶</a></h6>
<p>After the module extenv/&lt;shspace&gt; is loaded, all the module files located in <span class="target" id="index-37"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$SHSPACE_MODULEFILES</span></code> become visible to the module command. For each product, there should be one module file per version.</p>
<p>For example, if you create specific modules in the shared environment in the following paths:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ find $SHSPACE_MODULEFILES
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/code1
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/tool2
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/libprod
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/libprod/1.0
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/libprod/2.0
</pre></div>
</div>
<p>Then, those modules will be visible and accessible once the extenv/&lt;shspace&gt; module is loaded.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load extenv/shspace
load module extenv/shspace (Extra Environment)
$ module avail
---------------- /opt/Modules/default/modulefiles/applications -----------------
abinit/x.y.z        gaussian/x.y.z        openfoam/x.y.z
[...]
-------------------- /opt/Modules/default/modulefiles/tools --------------------
advisor/x.y.z       ipython/x.y.z         r/x.y.z
[...]
-------- /ccc/contxxx/home/shspace/shspace/products/modules/modulefiles --------
code1        libprod/1.0        libprod/2.0        tool2

$ module load tool2
$ module list
Currently Loaded Modulefiles:
1) ccc          3) dfldatadir/own   5) extenv/shspace
2) datadir/own  4) datadir/shspace  6) tool2
</pre></div>
</div>
<p>Let us consider the example of a product installed in the shared space. The program is called <em>prog</em>. Its version is <em>version</em>. It depends on the product <em>dep</em>. The product should be installed in the directory <code class="file docutils literal notranslate"><span class="pre">$SHSPACE_PRODUCTSHOME/prog-version</span></code>. The syntax of its module file <code class="file docutils literal notranslate"><span class="pre">$SHSPACE_MODULEFILES/prog/version</span></code> would be:</p>
<div class="highlight-tcl notranslate"><div class="highlight"><pre><span></span><span class="c">#%Module1.0</span>
<span class="c"># Software description</span>
<span class="k">set</span> version     <span class="s2">&quot;version&quot;</span>
<span class="k">set</span> whatis      <span class="s2">&quot;PROG&quot;</span>
<span class="k">set</span> software    <span class="s2">&quot;prog&quot;</span>
<span class="k">set</span> description <span class="s2">&quot;&lt;description&gt;&quot;</span>

<span class="c"># Conflict</span>
<span class="nv">conflict</span>        <span class="s2">&quot;$software&quot;</span>

<span class="c"># Prereq</span>
<span class="nv">prereq</span> dep

<span class="c"># load head common functions and behavior</span>
<span class="nb">source</span> <span class="nv">$env</span><span class="k">(</span><span class="nv">MODULEFILES</span><span class="k">)</span><span class="o">/</span>.headcommon
<span class="c"># Loads software&#39;s environment</span>

<span class="c"># application-specific variables</span>
<span class="k">set</span> prefix       <span class="s2">&quot;$env(SHSPACE_PRODUCTSHOME)/$software-$version&quot;</span>
<span class="k">set</span> libdir       <span class="s2">&quot;$prefix/lib&quot;</span>
<span class="k">set</span> incdir       <span class="s2">&quot;$prefix/include&quot;</span>
<span class="k">set</span> docdir       <span class="s2">&quot;$prefix/doc&quot;</span>

<span class="c"># compilerwrappers-specific variables</span>
<span class="k">set</span> ldflags      <span class="s2">&quot;&lt;ldflags&gt;&quot;</span>

<span class="nb">append</span><span class="o">-</span>path PATH <span class="s2">&quot;$bindir&quot;</span>
<span class="nb">append</span><span class="o">-</span>path LD_LIBRARY_PATH <span class="s2">&quot;$libdir&quot;</span>

<span class="nv">setenv</span> VARNAME <span class="s2">&quot;VALUE&quot;</span>

<span class="c"># load common functions and behavior</span>
<span class="nb">source</span> <span class="nv">$env</span><span class="k">(</span><span class="nv">MODULEFILES</span><span class="k">)</span><span class="o">/</span>.common
</pre></div>
</div>
<ul class="simple">
<li>Setting the local variables <span class="target" id="index-38"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">prefix</span></code>, <span class="target" id="index-39"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">libdir</span></code>, <span class="target" id="index-40"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">incdir</span></code> and <span class="target" id="index-41"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">docdir</span></code> will create the environment variables <span class="target" id="index-42"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">PROG_ROOT</span></code>, <span class="target" id="index-43"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">PROG_LIBDIR</span></code>, <span class="target" id="index-44"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">PROG_INCDIR</span></code> and <span class="target" id="index-45"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">PROG_DOCDIR</span></code> when the module is loaded. You can also define any environment variable needed by the software as the example does for <span class="target" id="index-46"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">VARNAME</span></code>.</li>
<li>Inter module dependencies are now handled automatically with the <em>prereq</em> keyword. That way, any time the module is loaded, its dependencies are loaded if necessary.</li>
</ul>
<p>We recommend the use of the previous example as a template for all your module files. If you use the recommended path for all installations (<code class="file docutils literal notranslate"><span class="pre">$SHSPACE_PRODUCTSHOME/&lt;software&gt;-&lt;version&gt;</span></code>), you can keep that template as it is. Just specify the right software and version and the potential VARNAME environment variables you want to define for the software.</p>
<p>Using that template will ensure that your module behaves the same way as the default modules and that all the available module commands will work for you.</p>
</div>
</div>
<div class="section" id="module-collection">
<h5>Module collection<a class="headerlink" href="#module-collection" title="Permalink to this headline">¶</a></h5>
<p>The collection mechanism allows to define a set of modules to be loaded either automatically when starting a session, through the <em>default</em> collection or manually with <strong class="command">module restore [collection_name]</strong>.</p>
<p>Along with datadir, dfldatadir and extenv, the aim of this collections is to replace all users configurations that may have been done up to now in the shell configuration files. (<code class="file docutils literal notranslate"><span class="pre">.bashrc</span></code>, <code class="file docutils literal notranslate"><span class="pre">.bash_profile</span></code>, etc)</p>
<p>Here are the useful commands to manage collections:</p>
<ul class="simple">
<li>To create a collection containing the modules currently loaded in your environment:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">save</span> <span class="p">[</span><span class="n">collection_name</span><span class="p">]</span>
</pre></div>
</div>
<p>If <em>[collection_name]</em> is not specified, it will impact the default collection.</p>
<ul class="simple">
<li>To list available collections:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">savelist</span>
</pre></div>
</div>
<ul class="simple">
<li>To load a saved collection:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">restore</span> <span class="p">[</span><span class="n">collection_name</span><span class="p">]</span>
</pre></div>
</div>
<p>If <em>[collection_name]</em> is not specified, the default collection will be loaded.</p>
<p>Those collections are stored in the users home, just like shell configuration scripts.</p>
<p>Let us say you have a product Tool2 installed in your shared extended environment. Here is how you would add it to your default collection:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module list
Currently Loaded Modulefiles:
1) ccc 2) datadir/own 3) dfldatadir/own
</pre></div>
</div>
<p>Load all necessary modules to access your shared product correctly.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load datadir/shspace
load module datadir/shspace (Data Directory)
$ module load extenv/shspace
load module extenv/shspace (Extra Environment)
$ module load tool2
load module tool2 (TOOL2)
$ module list
Currently Loaded Modulefiles:
1) ccc         3) dfldatadir/own  5) extenv/shspace
2) datadir/own 4) datadir/shspace 6) tool2
</pre></div>
</div>
<p>Use module save to make the current environment the default one.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module save
</pre></div>
</div>
<p>After that, every time you will connect to your account, those will be the modules loaded by default.</p>
<p>We highly recommend the use of collections instead of adding calls to <strong class="command">module load</strong> in shell configuration files. A call to <strong class="command">module load</strong> takes non negligible time whether the module was already loaded or not. And when they are specified in <code class="file docutils literal notranslate"><span class="pre">~/.bashrc</span></code>, they run for each bash script or shell execution. On the contrary, a collection is only loaded if the environment has not yet been initialized. Therefore, using collections will fasten connections and script executions.</p>
<p>Note: To ensure the correct setting of your user environment, make sure</p>
<ul class="simple">
<li>That the file <code class="file docutils literal notranslate"><span class="pre">~/.bashrc</span></code> contains:</li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="o">[</span> -f /etc/bashrc <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
. /etc/bashrc
<span class="k">fi</span>
</pre></div>
</div>
<ul class="simple">
<li>That the file <code class="file docutils literal notranslate"><span class="pre">~/.bash_profile</span></code> contains:</li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="o">[</span> -f ~/.bashrc <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
. ~/.bashrc
<span class="k">fi</span>
</pre></div>
</div>
</div>
<div class="section" id="managing-permissions">
<h5>Managing permissions<a class="headerlink" href="#managing-permissions" title="Permalink to this headline">¶</a></h5>
<p>By default, only staff members have write permission on the shared space. But sometimes write permission is needed for every user of the community on some specific subset of the shared space. A typical usage is the collection of usage and execution logs from all users for further analysis by the staff members. It could also allow all users of the community to produce results with the available tools and share them on the shared space.</p>
<p>To make a directory writeable, a staff member has to create it and set the correct permission for all users. Here is an example to create a subdirectory <code class="file docutils literal notranslate"><span class="pre">logs</span></code> in the shared workdir:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load datadir/shspace
load module datadir/shspace (Data Directory)
$ cd $SHSPACE_CCCWORKDIR
$ mkdir logs
</pre></div>
</div>
<p>By default, only the staff group (shspace_w) has write permission on the new directory. The staff member has to change its permission to allow all users to write in this specific directory.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ chmod 2777 logs
</pre></div>
</div>
<p>Here are the permissions of each directory in the path to logs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ find $SHSPACE_CCCWORKDIR/.. -ls
4 drwxr-x--- 3 root    shspace   4096 Jul 1  2013  /ccc/work/contxxx/shspace
4 drwxrwsr-x 3 shspace shspace_w 4096 Sep 22 18:40 /ccc/work/contxxx/shspace/shspace
4 drwxrwsrwx 2 user1   shspace_w 4096 Sep 22 18:40 /ccc/work/contxxx/shspace/shspace/logs
</pre></div>
</div>
<p>The same example may apply for <span class="target" id="index-47"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$SHSPACE_CCCSCRATCHDIR</span></code> and <span class="target" id="index-48"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$SHSPACE_CCCSTOREDIR</span></code>.</p>
<p>To allow the whole community to work collaboratively on a set of data, all users need read and write access. From a Unix point of view, that means the owner group needs to have “rw” access to the files and “rwx” access to the directories. It is also necessary to be member of the owner group of the files and directories. To make sure the correct rights are used, users working on shared files should set their umask to 0002, and the collaborative directories should belong to the collaborative group (shspace_w) with their setgid bit set.</p>
<p>Even with correct group and rights on a directory, users other than the owner of a file cannot change its rights or ownership (with chmod or chown) nor the modification date of directories (<code class="xref std std-option docutils literal notranslate"><span class="pre">--omit-dir-times</span></code> option of <strong class="command">rsync</strong>)</p>
<p>Hereafter we list the tools that help manipulating and checking unix rights in shared spaces.</p>
<div class="section" id="collwork">
<h6>collwork<a class="headerlink" href="#collwork" title="Permalink to this headline">¶</a></h6>
<p>Your default umask is 0027, which is good to work on personal data. Loading the <em>collwork</em> module sets umask to the right value to work with collaborative data (0002). Once the collwork module is unloaded, the umask comes back to its default value.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ umask
0027
$ module load collwork
load module collwork/1.0 (Collaborative Work Environment Setup)
$ umask
0002
$ module unload collwork
unload module collwork/1.0 (Collaborative Work Environment Setup)
$ umask
0027
</pre></div>
</div>
</div>
<div class="section" id="ccc-shspace-chmod">
<h6>ccc_shspace_chmod<a class="headerlink" href="#ccc-shspace-chmod" title="Permalink to this headline">¶</a></h6>
<p>The <strong class="command">ccc_shspace_chmod</strong> script that sets the correct unix rights on collaborative directories, depending on the parameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_shspace_chmod staffread|userread|userwrite dir [dir ...]
</pre></div>
</div>
<ul class="simple">
<li>Choosing <strong>userwrite</strong> allows shared space members to read and write in dir and its contents:<ul>
<li>for a shared space:<ul>
<li>the ownership of all directories and files is set to the group shspace_w</li>
<li>all directories are set to 2777 mode (drwxrwsrwx)</li>
</ul>
</li>
<li>for an open shared space:<ul>
<li>the ownership of all directories and files is set to the group shspace</li>
<li>all directories are set to 2775 mode (drwxrwsr-x)</li>
</ul>
</li>
</ul>
</li>
<li>Choosing <strong>staffread</strong> allows allow shared space staff only to read and write in dir:<ul>
<li>the ownership of all directories and files is set to the group shspace_w</li>
<li>all directories are set to 2770 mode (drwxrws—)</li>
</ul>
</li>
<li>Choosing <strong>userread</strong> allows shared space members to only read dir and its content:<ul>
<li>the ownership of all directories and files is set to the group shspace_w</li>
<li>all directories are set to in 2775 mode (drwxrwsr-x)</li>
</ul>
</li>
</ul>
<p>The <strong class="command">ccc_shspace_chmod</strong> command can be used either by a staff member when creating a set of collaborative working directories, or by any user writing data in the collaborative directory to set the right permission on created files.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you cannot set the correct permissions on collaborative data, please send a request to <a class="reference external" href="mailto:hotline&#46;tgcc&#37;&#52;&#48;cea&#46;fr">hotline<span>&#46;</span>tgcc<span>&#64;</span>cea<span>&#46;</span>fr</a></p>
</div>
</div>
<div class="section" id="ccc-shspace-modck">
<h6>ccc_shspace_modck<a class="headerlink" href="#ccc-shspace-modck" title="Permalink to this headline">¶</a></h6>
<p>The <strong class="command">ccc_shspace_modck</strong> script checks the permissions of a set of directories and files in a collaborative space. It lists the directories with inconsistent permissions and gives advice on how to set them right.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_shspace_modck dir [dir ...]
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="parallel-file-system-usage-monitoring">
<h3>Parallel file system usage monitoring<a class="headerlink" href="#parallel-file-system-usage-monitoring" title="Permalink to this headline">¶</a></h3>
<p>Some general best practice rules should be met when using the available file systems. They are specified in <a class="reference internal" href="irene.html#recommended-data-usage-on-parallel-file-system"><span class="std std-ref">Recommended data usage on parallel file system</span></a>.</p>
<p>Inappropriate usage of parallel file systems is monitored, as it may badly affect overall performances. Several inappropriate practices are tracked down.</p>
<div class="section" id="too-many-small-files-on-cccstoredir">
<h4>Too many small files on CCCSTOREDIR<a class="headerlink" href="#too-many-small-files-on-cccstoredir" title="Permalink to this headline">¶</a></h4>
<p>File size has to be constrained. The following is considered inappropriate:</p>
<ul class="simple">
<li>Average size of files below 50MB (see the column “avg_fsize(MB)” from <strong>ccc_quota</strong>)</li>
<li>Percentage of files lower than 32MB higher than 80% (see the column “files&lt;32M” from <strong>ccc_quota</strong>)</li>
</ul>
<p>Once a week if rules are not followed, actions are triggered until situation is back to normal:</p>
<ul class="simple">
<li>Week 1: The user is informed by mail.</li>
<li>Week 2: The user is informed by mail.</li>
<li>Week 3: The user is informed by mail and his submissions are locked.</li>
<li>Week 4: The user is informed by mail.</li>
<li>Week 5: The user is informed by mail, his account is locked and his files can be removed.</li>
</ul>
</div>
<div class="section" id="too-many-files-in-a-directory-on-scratch-work-and-store">
<h4>Too many files in a directory on SCRATCH, WORK and STORE<a class="headerlink" href="#too-many-files-in-a-directory-on-scratch-work-and-store" title="Permalink to this headline">¶</a></h4>
<p>Directories with more than 50000 entries (files or directories) at the root level is inappropriate.</p>
<p>Once a week if this rule is not followed, actions are triggered until situation is back to normal:</p>
<ul class="simple">
<li>Week 1: The user is informed by mail.</li>
<li>Week 2: The user is informed by mail.</li>
<li>Week 3: The user is informed by mail and his submissions are locked.</li>
<li>Week 4: The user is informed by mail.</li>
<li>Week 5: The user is informed by mail, his account is locked and his files can be removed.</li>
</ul>
</div>
</div>
</div>
<span id="document-toc/fulldoc/Data_transfer"></span><div class="section" id="data-transfers">
<span id="id1"></span><h2>Data transfers<a class="headerlink" href="#data-transfers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="file-transfer">
<h3>File transfer<a class="headerlink" href="#file-transfer" title="Permalink to this headline">¶</a></h3>
<p>The center provides several means of transferring data to and from its various resources.</p>
<ul class="simple">
<li>On Unix-like OSes (for instance Linux or Mac OS X) use the <strong class="command">scp</strong> or <strong class="command">rsync</strong> commands.</li>
<li>On Windows, several clients exist. For example <strong class="program">PSCP</strong> or <strong class="program">WinSCP</strong></li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><abbr title="SSH File Transfer Protocol">SFTP</abbr>, which is used for example by <strong class="program">WinSCP</strong>, is disabled for security reasons on PRACE and FR login nodes.</p>
</div>
<p>Call the transfer routines from your local machine (<em>local_host</em>). Here are the different ways to copy data from or to the supercomputer login node (<em>remote_host</em>). The remote host depends on the type of project. It is the one used for SSH connections (see <a class="reference internal" href="irene.html#interactive-access"><span class="std std-ref">Interactive access</span></a> for more details). Hereafter, <code class="file docutils literal notranslate"><span class="pre">remote_dir</span></code> represents a valid directory on the remote host.</p>
<div class="section" id="scp">
<h4>scp<a class="headerlink" href="#scp" title="Permalink to this headline">¶</a></h4>
<p><strong class="command">scp</strong> copies files between hosts on a network. It uses ssh for data transfer, with the same authentication and the same security as <strong class="command">ssh</strong>.</p>
<p>To transfer data from local machine to remote machine:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scp [options] &lt;local_files&gt; &lt;login&gt;@&lt;remote_host&gt;:&lt;remote_dir&gt;
</pre></div>
</div>
<p>To transfer data from remote machine to local machine:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scp [options] &lt;login&gt;@&lt;remote_host&gt;:&lt;remote_dir&gt;/&lt;files&gt; &lt;local_dir&gt;
</pre></div>
</div>
<p>Basic options are <code class="xref std std-option docutils literal notranslate"><span class="pre">-v</span></code> for verbose mode and <code class="xref std std-option docutils literal notranslate"><span class="pre">-r</span></code> to copy directories. For more information, type <strong class="command">man scp</strong> from the command line.</p>
</div>
<div class="section" id="rsync">
<h4>rsync<a class="headerlink" href="#rsync" title="Permalink to this headline">¶</a></h4>
<p><strong class="command">rsync</strong> synchronizes two sets of files across a network. It sends only the differences between the source files and the destination files.</p>
<p>To transfer data from local machine to remote machine:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ rsync -e ssh -avz &lt;local_files&gt; &lt;login&gt;@&lt;remote_host&gt;:&lt;remote_dir&gt;
</pre></div>
</div>
<p>To transfer data from remote machine to local machine:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ rsync -e ssh -avz &lt;login&gt;@&lt;remote_host&gt;:&lt;remote_dir&gt;/&lt;files&gt; &lt;local_dir&gt;
</pre></div>
</div>
<p>For more information, type <strong class="command">man rsync</strong> from the command line.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Transferring data from or to the supercomputer may be more efficient when using archives instead of many small files.</p>
</div>
</div>
<div class="section" id="sftp">
<h4>sftp<a class="headerlink" href="#sftp" title="Permalink to this headline">¶</a></h4>
<p><strong class="command">sftp</strong> connects on a remote host, then can transfer files on both directions. It uses ssh for data transfer, with the same authentication and the same security as ssh.</p>
<p>To connect on a remote host:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ sftp [options] &lt;login&gt;@&lt;remote_host&gt;
</pre></div>
</div>
<p>An usual option is <code class="xref std std-option docutils literal notranslate"><span class="pre">-r</span></code> to copy directories. For more information, type man sftp from the command line.</p>
<p>Once logged in, to transfer data from the remote host to the local host:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ sftp&gt; get [options] &lt;remote_path&gt; &lt;local_path&gt;
</pre></div>
</div>
<p>And to transfer data from the local host to the remote host:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ sftp&gt; put [options] &lt;local_path&gt; &lt;remote_path&gt;
</pre></div>
</div>
<p>If you haven’t used the <code class="xref std std-option docutils literal notranslate"><span class="pre">-r</span></code> option with the <strong class="command">sftp</strong> command, you can use it directly with <strong class="command">get</strong> and <strong class="command">put</strong>. For more information, type <strong class="command">help</strong> from the <strong class="command">sftp</strong> prompt, or <strong class="command">man sftp</strong> from the command line.</p>
</div>
<div class="section" id="parallel-sftp">
<h4>parallel sftp<a class="headerlink" href="#parallel-sftp" title="Permalink to this headline">¶</a></h4>
<p>To speed up file transfer, you can use <strong class="command">psftp</strong>, a tool developed by CEA. <strong class="command">psftp</strong> uses parallel <strong class="command">sftp</strong> to make file transfers. You can install it locally by following the dedicated website: <a class="reference external" href="https://github.com/cea-hpc/openssh-portable">https://github.com/cea-hpc/openssh-portable</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>psftp is not tested on Windows and MacOS.</li>
<li>psftp is only useful when your transfer overuses a CPU on one of the hosts (local or remote computer). On a modern processor, it happens when the transfer bandwidth reaches ± 1Gbps (please double check if the network link between both nodes can use more than 1Gbps of bandwitdh).</li>
</ul>
</div>
<p><strong class="command">psftp</strong> is installed on login nodes of CEA clusters. Its usage is identical as <strong class="command">sftp</strong>, except the option <code class="xref std std-option docutils literal notranslate"><span class="pre">-n</span></code> which let you choose the number of ssh connections used for the parallel transfer.</p>
<p>For example, to make a parallel transfer with 5 ssh connections:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ psftp -n 5 &lt;login&gt;@&lt;remote_host&gt;
</pre></div>
</div>
<p>If one <strong class="command">sftp</strong> transfer is limited at 1Gbps, this transfer will use at most 5Gbps.</p>
</div>
</div>
<div class="section" id="synchronize-your-ccrt-account-with-your-prace-account">
<h3>Synchronize your CCRT account with your PRACE account<a class="headerlink" href="#synchronize-your-ccrt-account-with-your-prace-account" title="Permalink to this headline">¶</a></h3>
<p>If you own both a PRACE account and a CCRT account on the computing center, you may need to transfer data from one account to the other. You can transfer files between PRACE login nodes and CCRT login nodes with the scp or rsync commands like you would do with your local computer. The commands must run on a CCRT login node.</p>
<p>Connect to the CCRT login node as usual.</p>
<p>Transfer data from your PRACE account to your CCRT account:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scp &lt;prace_login&gt;@&lt;prace_host&gt;:&lt;remote_dir&gt;/&lt;files&gt; &lt;local_dir&gt;
$ rsync -e ssh -avz &lt;prace_login&gt;@&lt;prace_host&gt;:&lt;remote_dir&gt;/&lt;files&gt; &lt;local_dir&gt;
</pre></div>
</div>
<p>To push some data from your CCRT account to your PRACE account:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scp &lt;local_files&gt; &lt;prace_login&gt;@&lt;prace_host&gt;:&lt;remote_dir&gt;
$ rsync -e ssh -avz &lt;local_files&gt; &lt;prace_login&gt;@&lt;prace_host&gt;:&lt;remote_dir&gt;
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">To move or copy large amount of data, ask the TGCC Hotline for support to benefit from the best internal transfer rate.</p>
</div>
</div>
<div class="section" id="ccfr-infrastructure">
<h3>CCFR infrastructure<a class="headerlink" href="#ccfr-infrastructure" title="Permalink to this headline">¶</a></h3>
<p>Several French computing centers are interconnected through a dedicated network. A list of available CCFR machines is given by the command <strong class="command">ccfr_ssh -v</strong>. The ccfr module needs to be loaded first.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">CCFR services require an authorized X.509 grid certificate.
To register your grid certificate in CEA authorization database, please provide the Distinguished Name of your X.509 grid certificate to the Hotline</p>
</div>
<div class="section" id="remote-access">
<h4>Remote access<a class="headerlink" href="#remote-access" title="Permalink to this headline">¶</a></h4>
<p>The <strong class="command">ccfr_ssh</strong> command wrapper helps connect interactively to a CCFR machine:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load ccfr
$ ccfr_ssh &lt;remote_host&gt;
</pre></div>
</div>
</div>
<div class="section" id="data-transfer">
<h4>Data transfer<a class="headerlink" href="#data-transfer" title="Permalink to this headline">¶</a></h4>
<p>The main point of the network is fast data transfer between machines. The <strong class="command">ccfr_cp</strong> command wrapper uses rsync through ssh protocol.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load ccfr
$ ccfr_cp &lt;local_files&gt; &lt;remote_machine&gt;:&lt;remote_dir&gt;
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h4>Remote access<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<p><strong>GSI-SSH</strong> provides a secure way to login to a remote machine.</p>
<p>If you have a X.509 grid certificate registered in the authorization database of the remote site you want to connect to, and also in the local site you are currently connected to, you can connect with GSI-SSH. The exact hostname and port to use to access a specific site are given by the <strong class="command">prace_service</strong> command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ prace_service -i -s &lt;site&gt;
</pre></div>
</div>
<p>Then just connect to the remote machine with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ gsissh &lt;remote_host&gt; -p &lt;port&gt;
</pre></div>
</div>
</div>
<div class="section" id="id3">
<h4>Data transfer<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h4>
<p><strong>GridFTP</strong> is a protocol for high-performance, secure and reliable data transfer. It is the recommended way to transfer large data from one PRACE machine to another. It is much more effective than basic scp or rsync transfer.</p>
<p>The command line tool recommended to transfer files is <strong class="command">globus-url-copy</strong>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">globus</span><span class="o">-</span><span class="n">url</span><span class="o">-</span><span class="n">copy</span> <span class="p">[</span><span class="n">options</span><span class="p">]</span> <span class="n">sourceURL</span> <span class="n">destinationURL</span>
</pre></div>
</div>
<p>Use <strong class="command">prace_service -i -f &lt;site&gt;</strong> to get the URL identifying the remote machine. Local files can be referred to by the file protocol.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ globus-url-copy file://&lt;local_path&gt; gsiftp://&lt;remote_host&gt;:&lt;port&gt;&lt;remote_path&gt;
</pre></div>
</div>
</div>
</div>
<div class="section" id="prace-infrastructure">
<h3>PRACE infrastructure<a class="headerlink" href="#prace-infrastructure" title="Permalink to this headline">¶</a></h3>
<p>All the computing sites that are part of the PRACE infrastructure provide a set of tools to efficiently manage multiple projects on several computing centers. The prace_service command displays a list of available machines.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ prace_service -list
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">PRACE services like GSI-SSH and GridFTP require an authorized X.509 grid certificate.
To register your grid certificate in CEA authorization database, please provide the Distinguished Name of your X.509 grid certificate to the Hotline.
Thorough documentation of the PRACE services and their use is provided on the PRACE-RI website (<a class="reference external" href="http://www.prace-ri.eu/user-documentation/">http://www.prace-ri.eu/user-documentation/</a>). We provide you guidelines to perform most useful tasks.</p>
</div>
</div>
</div>
<span id="document-toc/fulldoc/Environment_management"></span><div class="section" id="environment-management">
<span id="id1"></span><h2>Environment management<a class="headerlink" href="#environment-management" title="Permalink to this headline">¶</a></h2>
<p>Traditional Unix way to manage environment usually involves editing your <code class="file docutils literal notranslate"><span class="pre">~/.bashrc</span></code> and/or sourcing software-specific files. This methodology can be error-prone due to inconsistent definitions and hardly let users dynamically enable or change the software they want to use. To dynamically manage your environment and pick up the needed software among the large software catalog provided, the <strong class="command">module</strong> command is provided from the <a class="reference external" href="http://sourceforge.net/projects/modules/">Environment Modules project</a>.</p>
<div class="section" id="what-is-module">
<h3>What is module<a class="headerlink" href="#what-is-module" title="Permalink to this headline">¶</a></h3>
<p><strong class="command">module</strong> is a user interface providing dynamic modification of your environment via modulefiles. <strong class="command">module</strong> allows to change easily the shell environment by initializing, modifying or unsetting environment variables.</p>
<p>Each modulefile contains the information needed to configure the shell for an application. Once the module is initialized, the environment can be modified on a per-module basis using the module command which interprets modulefiles. Typically modulefiles instruct the module command to alter or set shell environment variables such as <span class="target" id="index-0"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">PATH</span></code>, <span class="target" id="index-1"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">MANPATH</span></code>, etc. The modulefiles are added to and removed from the current environment by the user.</p>
<p>On the computing center, it is typically used to:</p>
<ul class="simple">
<li>define your user environment (<span class="target" id="index-2"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$HOME</span></code>, <span class="target" id="index-3"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$CCCSCRATCHDIR</span></code>, etc.);</li>
<li>easily get access to third-party softwares in different versions (ex: Intel compilers, GCC, MPI librairies, etc.);</li>
<li>handle the potential conflicts an requirements between software.</li>
</ul>
<p>Modulefiles are basically provided by the computing center staff to get access to the installed software and to the system properties. In addition you may have your own modulefiles to supplement the already provided modulefiles.</p>
</div>
<div class="section" id="module-actions">
<h3>Module actions<a class="headerlink" href="#module-actions" title="Permalink to this headline">¶</a></h3>
<p>Major kind of actions of the module command are described below. To get a full reference of the available module actions, you can either</p>
<ul class="simple">
<li>display the command usage message (<strong class="command">module -h</strong>)</li>
<li>look at the man page (<strong class="command">man module</strong>)</li>
<li>or even try the command auto-completion</li>
</ul>
<div class="section" id="listing-searching-modulefiles">
<h4>Listing / Searching modulefiles<a class="headerlink" href="#listing-searching-modulefiles" title="Permalink to this headline">¶</a></h4>
<p>Knowing current environment state:</p>
<ul class="simple">
<li><strong class="command">module list</strong> shows the current state of your environment, which means to display all the modules currently loaded</li>
</ul>
<p>Querying modulefiles catalog:</p>
<ul class="simple">
<li><strong class="command">module avail</strong> displays all available modules (modules suffixed by <code class="docutils literal notranslate"><span class="pre">&#64;</span></code> are aliases)</li>
<li><strong class="command">module avail --default</strong> reduces the regular <em>avail</em> output by only displaying the available default versions</li>
<li><strong class="command">module avail --latest</strong> in the same way displays only the available latest versions</li>
<li><strong class="command">module avail mpi</strong> shows the available <em>mpi</em> modulefiles</li>
</ul>
<p>Printing modulefile information:</p>
<ul class="simple">
<li><strong class="command">module help netcdf</strong> shows software description for default <em>netcdf</em> modulefile</li>
<li><strong class="command">module help hdf5/x.y.z</strong> shows software description for a specific <em>hdf5</em> modulefile</li>
<li><strong class="command">module show mkl</strong> displays software description plus environment definition for the default <em>mkl</em></li>
<li><strong class="command">module show python/x.y.z</strong> displays as above description and environment definition but for a specific version</li>
</ul>
<p>Searching for modulefiles:</p>
<ul class="simple">
<li><strong class="command">module whatis papi</strong> prints for each version of <em>papi</em> product a one-liner description and its associated keywords</li>
<li><strong class="command">module show products/keywords</strong> prints <em>products/keywords</em> modulefile description which lists all keywords in-use by available modulefiles</li>
<li><strong class="command">module search profiler</strong> searches for all products whose name, one-liner description or keywords match the <em>profiler</em> search string</li>
</ul>
</div>
<div class="section" id="loading-unloading-modulefiles">
<h4>Loading / Unloading modulefiles<a class="headerlink" href="#loading-unloading-modulefiles" title="Permalink to this headline">¶</a></h4>
<p>Adding modulefile(s) to the list of currently loaded modules:</p>
<ul class="simple">
<li><strong class="command">module load fftw3</strong> loads the default version of <em>fftw3</em> product or its latest version if no default version is explicitly set</li>
<li><strong class="command">module load visit/x.y.z</strong> loads specific version <em>x.y.z</em> of <em>visit</em></li>
<li><strong class="command">module load intel hdf5 netcdf</strong> loads multiple modulefiles in one command</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">On interactive shells, module auto-completion is enabled and can help you to find the name of modulefiles you want to load, unload or switch</p>
</div>
<p>Removing modulefile(s) from your current environment:</p>
<ul class="simple">
<li><strong class="command">module unload visit</strong> unloads loaded version of <em>visit</em> modulefile</li>
<li><strong class="command">module unload netcdf hdf5</strong> unloads multiple products in one command</li>
<li><strong class="command">module purge</strong> unloads all loaded modulefiles</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">All these load, unload, switch commands returns 0 on success or 1 elsewhere</p>
</div>
<p>Switching from one version of a modulefile to another:</p>
<ul class="simple">
<li><strong class="command">module switch intel intel/x.y.z</strong> unloads currently loaded <em>intel</em> modulefile then loads version <em>x.y.z</em></li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The <strong class="command">module</strong> command will automatically satisfy modulefile prerequisites. When loading a modulefile, all the modulefiles it declares as prerequisite are loaded prior to its own load. When unloading a modulefile, all the modulefiles it declares as prerequisite that have been automatically loaded as dependency are automatically unloaded after the initial modulefile unload.</p>
</div>
</div>
<div class="section" id="saving-and-restoring-modulefile-collections">
<h4>Saving and restoring modulefile collections<a class="headerlink" href="#saving-and-restoring-modulefile-collections" title="Permalink to this headline">¶</a></h4>
<p>A modulefile collection corresponds to saved state of your module environment you can restore whenever you want. A collection is composed of an ordered set of modulefiles which are the currently loaded modulefiles at the time of saving this collection. When a collection is restored, currently loaded modulefiles are unloaded to then load the set of modulefiles defined in the collection in the same loading order.</p>
<p>You can own any number of collections you want, which gives you the ability to easily switch between a production environment and a development environment or between a visualization environment and a debugging one, for instance.</p>
<p>Saving modulefile collections</p>
<ul class="simple">
<li><strong class="command">module save development</strong> saves the current list of loaded modules in the collection named <em>development</em></li>
<li><strong class="command">module save</strong> saves the current list of loaded modules in the <em>default</em> collection</li>
</ul>
<p>Listing saved modulefile collections</p>
<ul class="simple">
<li><strong class="command">module savelist</strong> lists all previously saved modulefile collections</li>
</ul>
<p>Restoring saved modulefile collections:</p>
<ul class="simple">
<li><strong class="command">module restore development</strong> restores the collection named <em>development</em>, by unloading currently loaded modulefiles then loading the modulefiles defined in the collection to restore the same ordered list of loaded modulefiles</li>
<li><strong class="command">module restore</strong> restores the <em>default</em> modulefile collection</li>
</ul>
</div>
</div>
<div class="section" id="initialization-and-scope">
<span id="id2"></span><h3>Initialization and scope<a class="headerlink" href="#initialization-and-scope" title="Permalink to this headline">¶</a></h3>
<p>Depending on shell mode, the <strong class="command">module</strong> environment is initialized and propagated in different ways. In all cases, the <strong class="command">module</strong> command is defined and a minimal environment is set. This minimal environment is composed of the default paths to the modulefiles provided by the computing center staff and the mandatory modulefiles <a class="reference internal" href="#ccc"><span class="std std-ref">ccc</span></a> and <a class="reference internal" href="#dfldatadir"><span class="std std-ref">dfldatadir</span></a> loaded. Then on interactive shell:</p>
<ol class="arabic simple">
<li>all <strong class="command">module</strong> output messages are set to be redirected to stdout</li>
<li><strong class="command">module</strong> command auto-completion is enabled</li>
<li>your module collection named <em>default</em> is restored if it exists</li>
</ol>
<p>On non-interactive shell following initialization is done after minimal environment setup:</p>
<ol class="arabic simple">
<li>all <strong class="command">module</strong> output messages are let on stderr</li>
<li>module message at load or unload is disabled</li>
<li>your module collection named <em>non-interactive</em> is restored if it exists</li>
</ol>
<div class="section" id="interactive-or-non-interactive">
<h4>Interactive or non-interactive ?<a class="headerlink" href="#interactive-or-non-interactive" title="Permalink to this headline">¶</a></h4>
<p>Interactive shell initialization is obtained when:</p>
<ul class="simple">
<li>you connect to the supercomputer or to a given node within the supercomputer to get a login shell</li>
<li>you run an interactive job</li>
</ul>
<p>Non-interactive shell initialization is obtained elsewhere, which means when:</p>
<ul class="simple">
<li>a batch job starts</li>
<li>you remotely execute a command (with SSH) on the supercomputer or on a node within the supercomputer</li>
</ul>
</div>
<div class="section" id="scope-of-your-environment">
<h4>Scope of your environment<a class="headerlink" href="#scope-of-your-environment" title="Permalink to this headline">¶</a></h4>
<p>Your environment is initialized or re-initialized in the conditions previously described, which means each time you connect to the supercomputer or from one node to another within the supercomputer your environment is reset to its default. It is also the case when the batch scheduler starts one of your batch job: by default the environment at the time of the job submission is not restored so the environment of this batch job is initialized as a non-interactive environment.</p>
<p>Once initialized, each load or unload of modulefile modifies the environment of the current shell, its subsequent sub-shells and jobs. So each sub-shell and script launched will inherit the environment from its parent shell. However to guaranty the <strong class="command">module</strong> function to still be defined in sub-shells and script launched, please ensure that <code class="file docutils literal notranslate"><span class="pre">/etc/bashrc</span></code> configuration is loaded in your <code class="file docutils literal notranslate"><span class="pre">~/.bashrc</span></code> local configuration file, for instance with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Source global definitions</span>
<span class="k">if</span> <span class="o">[</span> -f /etc/bashrc <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    . /etc/bashrc
<span class="k">fi</span>
</pre></div>
</div>
<p>Regarding interactive jobs, the environment obtained at the start of this kind of job is the one set when you call for these interactive jobs. Which means all the modulefiles loaded prior to the execution of an interactive job will be still loaded once this interactive job session will be established.</p>
</div>
</div>
<div class="section" id="major-modulefiles">
<h3>Major modulefiles<a class="headerlink" href="#major-modulefiles" title="Permalink to this headline">¶</a></h3>
<p>Modulefiles provided by the computing center staff are spread across categories to sort them by product function. These categories are <em>applications</em>, <em>compilers</em>, <em>environment</em>, <em>libraries</em>, <em>tools</em>, <em>parallel</em> and <em>graphics</em>. They represent the type of software, except for <em>parallel</em> and <em>graphics</em> categories which are transversal to the other categories and are made to promote these kind of software.</p>
<p>The <em>environment</em> category is a bit special as it does not contain modulefile definition for product like the other categories. A modulefile from the environment category defines aspects relative to the system or configuration properties for a group of user that can access and use these system functions.</p>
<p>Some modulefiles from the <em>environment</em> category shape environment usages and possibilities. These major modulefiles are described below.</p>
<div class="section" id="ccc">
<span id="id3"></span><h4>ccc<a class="headerlink" href="#ccc" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">ccc</span></code> modulefile defines global system variables and aliases needed to get a functional user environment. This modulefile is the first to be loaded in user environment and its load is done within <a class="reference internal" href="#initialization-and-scope"><span class="std std-ref">default environment load</span></a>. It is mandatory and thus cannot be unloaded.</p>
</div>
<div class="section" id="datadir">
<span id="id4"></span><h4>datadir<a class="headerlink" href="#datadir" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">datadir</span></code> modulefile helps user to localize his own or shared/application space-specific data end points. Personal or shared spaces provide multiple data end-points each for different needs. These endpoints are localized with environment variables to easily reference these various end-points. Data end-points variables are all prefixed with the name of the module version upper-cased, which corresponds to the name of the personal or shared space. For instance, data end-points for project <code class="docutils literal notranslate"><span class="pre">prj</span></code> will be all prefixed by <code class="docutils literal notranslate"><span class="pre">PRJ_</span></code> and end-points for personal space will be all prefixed by <code class="docutils literal notranslate"><span class="pre">OWN_</span></code>.</p>
<p>A version for the <code class="docutils literal notranslate"><span class="pre">datadir</span></code> modulefile exists for each shared/application space known in the computing center, named in accordance to the shared space name, and for the user personal space, named <code class="docutils literal notranslate"><span class="pre">own</span></code>. You can only view and access versions of the <code class="docutils literal notranslate"><span class="pre">datadir</span></code> modulefile that correspond to spaces you can access. Multiple versions of the <code class="docutils literal notranslate"><span class="pre">datadir</span></code> module can be loaded at the same time.</p>
<p>Following example display the variables set for the own version of the <code class="docutils literal notranslate"><span class="pre">datadir</span></code> modulefile:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ module show datadir/own
-------------------------------------------------------------------
/opt/Modules/default/modulefiles/environment/datadir/own:

setenv      OWN_STOREDIR    /ccc/store/contxxx/group/username
setenv      OWN_CCCSTOREDIR /ccc/store/contxxx/group/username
setenv      OWN_WORKDIR /ccc/work/contxxx/group/username
setenv      OWN_CCCWORKDIR  /ccc/work/contxxx/group/username
setenv      OWN_SCRATCHDIR  /ccc/scratch/contxxx/group/username
setenv      OWN_HOME    /ccc/contxxx/home/group/username
module-whatis   Data Directory
-------------------------------------------------------------------
</pre></div>
</div>
</div>
<div class="section" id="dfldatadir">
<span id="id5"></span><h4>dfldatadir<a class="headerlink" href="#dfldatadir" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">dfldatadir</span></code> modulefile sets personal or shared/application space data end-points targeted by a <a class="reference internal" href="#datadir"><span class="std std-ref">datadir</span></a> modulefile as default end-points. Data end-point variables set by <code class="docutils literal notranslate"><span class="pre">datadir</span></code> modulefile are all prefixed with the name of the module version upper-cased, <code class="docutils literal notranslate"><span class="pre">dfldatadir</span></code> module sets the default data end-point variable (without prefix) for each of these personal or shared-space specific variables set by corresponding <code class="docutils literal notranslate"><span class="pre">datadir</span></code> modulefile. Exception is made for <span class="target" id="index-4"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">HOME</span></code> variable which always refer to personal home directory and do not change if a <code class="docutils literal notranslate"><span class="pre">dfldatadir</span></code> modulefile different than default is loaded.</p>
<p>A version for <code class="docutils literal notranslate"><span class="pre">dfldatadir</span></code> modulefile exists for each shared/application space known in the computing center, named in accordance to the shared space name, and for the user personal space, named <code class="docutils literal notranslate"><span class="pre">own</span></code>. You can only view and access versions of the <code class="docutils literal notranslate"><span class="pre">datadir</span></code> modulefile that correspond to spaces you can access. Since <code class="docutils literal notranslate"><span class="pre">dfldatadir</span></code> module represents default data end-points, only one version of the module can be loaded at the same time.</p>
<p><code class="docutils literal notranslate"><span class="pre">dfldatadir</span></code> modulefile requires the <a class="reference internal" href="#datadir"><span class="std std-ref">datadir</span></a> modulefile with same version name. This <code class="docutils literal notranslate"><span class="pre">datadir</span></code> modulefile is thus automatically loaded when loading the <code class="docutils literal notranslate"><span class="pre">dfldatadir</span></code> modulefile. Default version of the <code class="docutils literal notranslate"><span class="pre">dfldatadir</span></code> module is the <code class="docutils literal notranslate"><span class="pre">own</span></code> modulefile, which is loaded by default when module environment is initialized.</p>
<p>To guaranty a coherent user environment with default datadir locations set (<span class="target" id="index-5"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCCSCRATCHDIR</span></code>, <span class="target" id="index-6"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">CCCSTOREDIR</span></code>, etc) <code class="docutils literal notranslate"><span class="pre">dfldatadir</span></code> is mandatory and thus cannot be unloaded. As a consequence, to change loaded <code class="docutils literal notranslate"><span class="pre">dfldatadir</span></code> module <strong class="command">module switch</strong> command has to be used as <strong class="command">module unload</strong> will fail:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module unload dfldatadir
module dfldatadir/own (Default Data Directory) cannot be unloaded
$ module switch dfldatadir/own dfldatadir/prj
unload module dfldatadir/own (Default Data Directory)
unload module datadir/own (Data Directory)
load module datadir/prj (Data Directory)
load module dfldatadir/prj (Default Data Directory)
</pre></div>
</div>
</div>
<div class="section" id="extenv">
<span id="id6"></span><h4>extenv<a class="headerlink" href="#extenv" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">extenv</span></code> modulefile enables users to extend the environment provided by the computing center staff with extra environment managed within its own home directory or within a shared/application space home directory. <code class="docutils literal notranslate"><span class="pre">extenv</span></code> introduces a standard layout to manage your software products through the module environment provided by the computing center. Details on this modulefile are exposed in <a class="reference internal" href="#extend-your-environment-with-modulefiles"><span class="std std-ref">the next section</span></a>.</p>
</div>
<div class="section" id="feature">
<span id="id7"></span><h4>feature<a class="headerlink" href="#feature" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">feature</span></code> modulefile enables users to adjust the settings of a product through environment variables. <code class="docutils literal notranslate"><span class="pre">feature</span></code> introduces a standard layout to manage your software products settings through the module environment provided by the computing center. Typical usages are:</p>
<ul class="simple">
<li><strong class="command">module whatis feature</strong> to list products with multiple settings</li>
<li><strong class="command">module whatis feature/openmpi</strong> to list and describe the available settings for the software <em>openmpi</em></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">feature</span></code> adjust the behaviour of a product without software recompilation. When behaviour changes requires dedicated build it will be in the <a class="reference internal" href="#flavor"><span class="std std-ref">flavor</span></a> modulefiles.</p>
<p>The following example illustrates how the <code class="docutils literal notranslate"><span class="pre">feature</span></code> modules for MKL load some environment variables that affect the product in some way of its own. You can list those features with <strong class="command">module av feature/mkl</strong>. Here is what they do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load feature/mkl/sequential
$ module load mkl
$ module show mkl
...
module-whatis Intel MKL LP64 Sequential
setenv        MKL_LDFLAGS ... -lmkl_sequential ...   # Here, link options will change
...
$ module switch feature/mkl/{sequential,multi-threaded}
$ module show mkl
...
module-whatis Intel MKL LP64 Multi-threaded
setenv        MKL_LDFLAGS ... -lmkl_intel_thread ... #... here we see the change
...
</pre></div>
</div>
</div>
<div class="section" id="flavor">
<span id="id8"></span><h4>flavor<a class="headerlink" href="#flavor" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">flavor</span></code> modulefile enables users to select a specific build for a product. <code class="docutils literal notranslate"><span class="pre">flavor</span></code> introduces a standard layout to manage the multiple compilations for a same software products through the module environment provided by the computing center. Typical usages are:</p>
<ul class="simple">
<li><strong class="command">module whatis flavor</strong> to list the products with multiple compilations/builds</li>
<li><strong class="command">module whatis flavor/hdf5</strong> to list and describe the available compilations/builds for the software <em>hdf5</em></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">flavor</span></code> adjust the behaviour of a product with dedicated software compilation. When behaviour changes does not requires it, it will be in the <a class="reference internal" href="#feature"><span class="std std-ref">feature</span></a> modulefiles.</p>
<p>Here is a more detailed illustration of what <code class="docutils literal notranslate"><span class="pre">flavor</span></code> modules do:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">flavor/%product%/%wish%</span></code> expresses a wish about the installed version of a product you want to choose, but it does not load anything by itself;</li>
<li><code class="docutils literal notranslate"><span class="pre">%product%/%version%</span></code> points to the installation of the product, depending on the <code class="docutils literal notranslate"><span class="pre">flavor</span></code> modules you may have loaded previously;</li>
</ul>
<p>Here is a real-life example: <strong class="command">module av flavor/hdf5</strong> mentions <code class="docutils literal notranslate"><span class="pre">parallel</span></code> and <code class="docutils literal notranslate"><span class="pre">serial</span></code>. Let’s try both:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load flavor/hdf5/serial
$ module load hdf5
$ module show hdf5
...
prepend-path  PATH    /.../serial/bin # Installation paths change with the flavor
...
$ module load mpi  #HDF5 parallel will require a MPI implementation
$ module switch flavor/hdf5/serial flavor/hdf5/parallel
$ module show hdf5
...
prepend-path  PATH    /.../parallel/bin # a new flavor changes the installation path
</pre></div>
</div>
</div>
<div class="section" id="licsrv">
<span id="id9"></span><h4>licsrv<a class="headerlink" href="#licsrv" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">licsrv</span></code> modulefile defines in user environment the variables required by software to query the license server they are related to. Each version of this modulefile represents an existing license server. <code class="docutils literal notranslate"><span class="pre">licsrv</span></code> modulefile is automatically loaded when loading a modulefile who requires the relative license server.</p>
</div>
<div class="section" id="products">
<span id="id10"></span><h4>products<a class="headerlink" href="#products" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">products</span></code> modulefiles provides functions to query the product catalog. These modulefiles can only be displayed, they are not intended to be loaded. They provide different kind of information on the installed software.</p>
<ul class="simple">
<li><strong class="command">module show products/keywords</strong> displays all the existing product keywords</li>
<li><strong class="command">module show products/newinstall</strong> lists all the software versions whose installation date is fresher than 8 weeks</li>
<li><strong class="command">module show products/endoflife</strong> lists all the decommission dates planned for software</li>
<li><strong class="command">module show products/restrict</strong> lists all the software whose usage is restricted and your current grant status for these software.</li>
</ul>
</div>
</div>
<div class="section" id="extend-your-environment-with-modulefiles">
<span id="id11"></span><h3>Extend your environment with modulefiles<a class="headerlink" href="#extend-your-environment-with-modulefiles" title="Permalink to this headline">¶</a></h3>
<p>Computing center staff provides you regular HPC software you can access through the <strong class="command">module</strong> environment. You may need to extend this regular environment with your own product installations or various setups. This section describes how to enable your environment extensions within the <strong class="command">module</strong> environment.</p>
<div class="section" id="using-the-extenv-modulefile">
<h4>Using the <code class="docutils literal notranslate"><span class="pre">extenv</span></code> modulefile<a class="headerlink" href="#using-the-extenv-modulefile" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">extenv</span></code> modulefile enables users to extend the environment provided by the computing center staff with extra environment managed within its own home directory or within a shared/application space home directory. <code class="docutils literal notranslate"><span class="pre">extenv</span></code> introduces a standard layout to manage your software products through the module environment provided by the computing center. This modulefile enables to define a common environment for all users of a given shared space.</p>
<p>A version for <code class="docutils literal notranslate"><span class="pre">extenv</span></code> modulefile exists for each shared space known in the computing center, named in accordance to the shared space name, and for the user personal space, named <code class="docutils literal notranslate"><span class="pre">own</span></code>. You can only view and access versions of the <code class="docutils literal notranslate"><span class="pre">extenv</span></code> modulefile that correspond to spaces you can access. Multiple versions of the <code class="docutils literal notranslate"><span class="pre">extenv</span></code> module can be loaded at the same time.</p>
<p>Loading the <code class="docutils literal notranslate"><span class="pre">extenv</span></code> modulefile will:</p>
<ul class="simple">
<li>Set environment variables defining the path to shared products and modulefiles (<span class="target" id="index-7"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SHSPACE_PRODUCTSHOME</span></code>, <span class="target" id="index-8"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SHSPACE_MODULEFILES</span></code>, <span class="target" id="index-9"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SHSPACE_MODULESHOME</span></code>)</li>
<li>Execute a module initialization script</li>
<li>Add shared modulefiles to the list of available modulefiles</li>
</ul>
<p>The environment extension mechanisms of <code class="docutils literal notranslate"><span class="pre">extenv</span></code> requires the use of specific paths. Products installed for the shared space named <em>shspace</em> should be installed in <span class="target" id="index-10"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$SHSPACE_PRODUCTSHOME</span></code> and the corresponding modulefiles should be in <span class="target" id="index-11"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$SHSPACE_MODULEFILES</span></code>.</p>
<div class="section" id="initialization-file">
<h5>Initialization file<a class="headerlink" href="#initialization-file" title="Permalink to this headline">¶</a></h5>
<p>If a file named <code class="file docutils literal notranslate"><span class="pre">init</span></code> is found in the path defined by <span class="target" id="index-12"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$SHSPACE_MODULESHOME</span></code>, then each time the <code class="docutils literal notranslate"><span class="pre">extenv/shspace</span></code> module is loaded, this initialization file will be executed as TCL code. This may be useful if you want to define other common environment variables or add prerequisites on modules to be used by the community.</p>
<p>For instance, with the following example, you will define two environment variables, one defining the path to a directory containing input files (<span class="target" id="index-13"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SHSPACE_INPUTDIR</span></code>), and the other defining the result directory (<span class="target" id="index-14"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SHSPACE_RESULTDIR</span></code>). It will also add <code class="file docutils literal notranslate"><span class="pre">$SHSPACE_PRODUCTSHOME/tools/bin</span></code> to the <span class="target" id="index-15"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">PATH</span></code> so that the tools installed in this directory are easily available.</p>
<div class="highlight-tcl notranslate"><div class="highlight"><pre><span></span><span class="nv">setenv</span> SHSPACE_INPUTDIR <span class="s2">&quot;$env(SHSPACE_CCCWORKDIR)/in&quot;</span>
<span class="nv">setenv</span> SHSPACE_RESULTDIR <span class="s2">&quot;$env(SHSPACE_CCCSCRATCHDIR)/res&quot;</span>
<span class="nb">append</span><span class="o">-</span>path PATH <span class="s2">&quot;$env(SHSPACE_PRODUCTSHOME)/tools/bin&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="expose-modulefiles">
<h5>Expose modulefiles<a class="headerlink" href="#expose-modulefiles" title="Permalink to this headline">¶</a></h5>
<p>Once the <code class="docutils literal notranslate"><span class="pre">extenv/shspace</span></code> modulefile is loaded, all the modulefiles located in <span class="target" id="index-16"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$SHSPACE_MODULEFILES</span></code> will be visible to the <strong class="command">module</strong> command. For each product, there should be one module file per version. You can also define modulefiles for configuration or environment change, it is not mandatory to relate each modulefiles to a product.</p>
<p>For example, if you create specific modules in the shared environment in the following paths:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ find $SHSPACE_MODULEFILES
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/thecode
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/thecode/1.2.3
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/thetool
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/thetool/2
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/conf
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/conf/thecode
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/conf/thecode/production
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/conf/thecode/tuningtest
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/libprod
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/libprod/1.0
/ccc/contxxx/home/shspace/shspace/products/modules/modulefiles/libprod/2.0
</pre></div>
</div>
<p>Then, those modules will be visible and accessible once the extenv/&lt;shspace&gt; module is loaded.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load extenv/shspace
load module extenv/shspace (Extra Environment)
$ module avail
---------------- /opt/Modules/default/modulefiles/applications -----------------
abinit/x.y.z        gaussian/x.y.z        openfoam/x.y.z
[...]
-------------------- /opt/Modules/default/modulefiles/tools --------------------
advisor/x.y.z       ipython/x.y.z         r/x.y.z
[...]
-------- /ccc/contxxx/home/shspace/shspace/products/modules/modulefiles --------
thecode       conf/thecode/production   conf/thecode/tuningtest
libprod/1.0   libprod/2.0               thetool/2

$ module load thetool
$ module list
Currently Loaded Modulefiles:
1) ccc          3) dfldatadir/own   5) extenv/shspace
2) datadir/own  4) datadir/shspace  6) thetool/2
</pre></div>
</div>
<p>Next section will give some hints to write your own modulefiles.</p>
</div>
</div>
<div class="section" id="write-your-own-modulefile">
<h4>Write your own modulefile<a class="headerlink" href="#write-your-own-modulefile" title="Permalink to this headline">¶</a></h4>
<p>This section describes how to write a modulefile through the example of a product installed in the shared space named <em>shspace</em>. This product is called <em>TheCode</em> and it is installed in version <em>1.2.3</em>. This product depends on the library <em>libprod</em> and on configuration enabled via the <em>conf/thecode</em> modulefile. It is advised to install this product in the <code class="file docutils literal notranslate"><span class="pre">$SHSPACE_PRODUCTSHOME/thecode-1.2.3</span></code> directory.</p>
<p>Now looking at modulefiles, we suggest to have one modulefile for each version of the product and one common modulefile referred by all version-specific modulefiles which contains all the definition relative to the product. In our example for <em>TheCode</em> product, it means having first a version-specific modulefile at <code class="file docutils literal notranslate"><span class="pre">$SHSPACE_MODULEFILES/thecode/1.2.3</span></code> containing:</p>
<div class="highlight-tcl notranslate"><div class="highlight"><pre><span></span><span class="c">#%Module1.0</span>

<span class="c"># Software description</span>
<span class="k">set</span> version <span class="s2">&quot;1.2.3&quot;</span>

<span class="c"># load common functions and behavior</span>
<span class="nb">source</span> <span class="nv">$env</span><span class="k">(</span><span class="nv">SHSPACE_MODULEFILES</span><span class="k">)</span><span class="o">/</span>thecode<span class="o">/</span>.common
</pre></div>
</div>
<p>In this version-specific modulefile, we just set the version number then we load the common definitions for the product. By doing so, product definition is easily shared between the different versions available of this product. Moving on the common modulefile at <code class="file docutils literal notranslate"><span class="pre">$SHSPACE_MODULEFILES/thecode/.common</span></code>:</p>
<div class="highlight-tcl notranslate"><div class="highlight"><pre><span></span><span class="c">#%Module1.0</span>

<span class="c"># Software description</span>
<span class="k">set</span> whatis      <span class="s2">&quot;TheCode&quot;</span>
<span class="k">set</span> software    <span class="s2">&quot;thecode&quot;</span>
<span class="k">set</span> description <span class="s2">&quot;One sentence to describe what TheCode is done for&quot;</span>

<span class="c"># Conflict</span>
<span class="nv">conflict</span> <span class="nv">$software</span>
<span class="c"># Prerequisite</span>
<span class="nv">prereq</span>   conf<span class="o">/</span>thecode
<span class="nv">prereq</span>   libprod

<span class="c"># load head common functions and behavior</span>
<span class="nb">source</span> <span class="nv">$env</span><span class="k">(</span><span class="nv">MODULEFILES</span><span class="k">)</span><span class="o">/</span>.headcommon

<span class="c"># Loads software&#39;s environment</span>
<span class="c"># application-specific variables</span>
<span class="k">set</span> prefix       <span class="s2">&quot;$env(SHSPACE_PRODUCTSHOME)/$software-$version&quot;</span>
<span class="k">set</span> libdir       <span class="s2">&quot;$prefix/lib&quot;</span>
<span class="k">set</span> incdir       <span class="s2">&quot;$prefix/include&quot;</span>
<span class="c"># compilerwrappers-specific variables</span>
<span class="k">set</span> ldflags      <span class="s2">&quot;&lt;ldflags&gt;&quot;</span>

<span class="nb">append</span><span class="o">-</span>path PATH            <span class="s2">&quot;$bindir&quot;</span>
<span class="nb">append</span><span class="o">-</span>path LD_LIBRARY_PATH <span class="s2">&quot;$libdir&quot;</span>

<span class="nv">setenv</span> VARNAME <span class="s2">&quot;VALUE&quot;</span>

<span class="c"># load common functions and behavior</span>
<span class="nb">source</span> <span class="nv">$env</span><span class="k">(</span><span class="nv">MODULEFILES</span><span class="k">)</span><span class="o">/</span>.common
</pre></div>
</div>
<p>This common modulefile first defines the identity card of the product, by setting the local variables <code class="docutils literal notranslate"><span class="pre">software</span></code>, <code class="docutils literal notranslate"><span class="pre">description</span></code>, etc. Conflicts and prerequisites are then setup with the <code class="docutils literal notranslate"><span class="pre">conflict</span></code> and <code class="docutils literal notranslate"><span class="pre">prereq</span></code> keywords. Some computing center global definitions are then loaded, and also at the end of the file. These definitions help to get the same behavior for your modulefiles as for the computing center regular modulefiles, like for instance the message printed at <strong class="command">module load</strong> and also the structured description returned when calling <strong class="command">module help</strong> on a product.</p>
<p>Then special local variables are set to define the environment of the software. Variables <code class="docutils literal notranslate"><span class="pre">prefix</span></code>, <code class="docutils literal notranslate"><span class="pre">libdir</span></code>, <code class="docutils literal notranslate"><span class="pre">incdir</span></code>, <code class="docutils literal notranslate"><span class="pre">cflags</span></code>, <code class="docutils literal notranslate"><span class="pre">ldflags</span></code> will automatically create the environment variables <span class="target" id="index-17"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">THECODE_ROOT</span></code>, <span class="target" id="index-18"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">THECODE_LIBDIR</span></code>, <span class="target" id="index-19"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">THECODE_INCDIR</span></code>, <span class="target" id="index-20"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">THECODE_CFLAGS</span></code> and <span class="target" id="index-21"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">THECODE_LDFLAGS</span></code> when the modulefile is loaded. These environment variables are guessed and set by the global common file <code class="file docutils literal notranslate"><span class="pre">$MODULEFILES/.common</span></code> sourced at the end of this application-specific common file <code class="file docutils literal notranslate"><span class="pre">$SHSPACE_MODULEFILES/thecode/.common</span></code>. Environment variables needed by the software can also be defined or ajusted as it is done in the example for the <span class="target" id="index-22"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">VARNAME</span></code>, <span class="target" id="index-23"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">PATH</span></code> and <span class="target" id="index-24"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">LD_LIBRARY_PATH</span></code> variables.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Modulefile inter-dependencies are managed automatically by <strong class="command">module</strong>. Any time the modulefile is loaded its dependencies, defined with the <code class="docutils literal notranslate"><span class="pre">prereq</span></code> keyword, are automatically loaded.</p>
</div>
<p>We recommend the use of the previous example as a template for all your modulefiles. If you use the recommended path for all product installations, you can keep major parts of this template as it is. Just specify the right software name and version, the correct dependencies and the product-specific environment variables like <span class="target" id="index-25"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">VARNAME</span></code> in the example. Using that template will ensure you that your modulefile behaves the same way as the default modules and that all the available <strong class="command">module</strong> commands will work for you.</p>
<p>To further learn the syntax of a modulefile, please refer to the <code class="docutils literal notranslate"><span class="pre">modulefile</span></code> and <code class="docutils literal notranslate"><span class="pre">module</span></code> man pages. Moreover a modulefile is interpreted by the <strong class="command">module</strong> command as a TCL script, so you can use the TCL code and functions. For more information on the TCL language, please refer to <a class="reference external" href="http://tcl.tk/doc/">http://tcl.tk/doc/</a>.</p>
</div>
</div>
</div>
<span id="document-toc/fulldoc/Software"></span><div class="section" id="softwares">
<span id="id1"></span><h2>Softwares<a class="headerlink" href="#softwares" title="Permalink to this headline">¶</a></h2>
<p>This section presents the various kinds of software products (binaries, libraries, scripts and tools) available on the center. It is organized as follows. After generally explaining the different kinds of software on the center, we will focus on specific cases (restricted and purchased products). Finally, we will talk about the software life cycle, from the installation request to the product removal.</p>
<div class="section" id="generalities-on-software">
<h3>Generalities on software<a class="headerlink" href="#generalities-on-software" title="Permalink to this headline">¶</a></h3>
<p>Lots of tools and products are available on the supercomputer. A distinction is made between the OS and CCC software.</p>
<div class="section" id="os-software">
<h4>OS software<a class="headerlink" href="#os-software" title="Permalink to this headline">¶</a></h4>
<p>They are software products provided by the operating system. They are installed by packages (rpm) and are locally stored on each node.</p>
<p>All common Linux software products enter in this category, such as:</p>
<ul class="simple">
<li>shells (<strong class="command">bash</strong>, <strong class="command">tcsh</strong>),</li>
<li>common scripting tools (<strong class="command">cat</strong>, <strong class="command">sed</strong>, <strong class="command">awk</strong>, …)</li>
<li>editors (<strong class="command">vi</strong>, <strong class="command">emacs</strong>, <strong class="command">gedit</strong>, …),</li>
<li>minimal installations of common scripting language (<strong class="command">perl</strong>, <strong class="command">python</strong>).</li>
</ul>
<p><strong>Updates occur during maintenance</strong> or during production only if they do not impact the operating system of the node.</p>
</div>
<div class="section" id="ccc-software">
<h4>CCC software<a class="headerlink" href="#ccc-software" title="Permalink to this headline">¶</a></h4>
<p>CCC software products are the third-party dedicated tools or dedicated compilations. They are shared by all center nodes and are installed by CCC dedicated service(s) during production. We prefer the term CCC software products over center software which is ambiguous.</p>
<p>Contrary to the OS software products, CCC software products are not within the standard operating system paths for binaries or libraries (eg. <code class="file docutils literal notranslate"><span class="pre">/usr/bin</span></code> or <code class="file docutils literal notranslate"><span class="pre">/usr/lib64</span></code>).</p>
<p>Each product is installed in a dedicated directory and requires an update of environment variables like and before use. These environment updates are handled by the <strong class="program">module</strong> tool detailed in the <a class="reference internal" href="irene.html#environment-management"><span class="std std-ref">Environment management</span></a> section.</p>
<p><strong>Updates occur during production</strong> as they do not interrupt nor interfere with the operating system installation.</p>
</div>
<div class="section" id="software-and-module">
<h4>Software and module<a class="headerlink" href="#software-and-module" title="Permalink to this headline">¶</a></h4>
<p>A CCC software product requires an environment update before use. The <strong class="command">module</strong> command is the tool for it, so a module exists for each CCC software product.</p>
<p>An OS software product is usually not referred to by a module, except when:</p>
<ul class="simple">
<li>it is usually the case in other computing centers (ex: <strong class="program">tcl</strong>)</li>
<li>there is a CCC software version of it (ex: <strong class="program">valgrind</strong>): it helps to avoid conflicts between the OS and CCC installation.</li>
</ul>
<p>Products referenced by <strong class="program">module</strong> have been organized into categories:</p>
<ul class="simple">
<li>applications: simulation products</li>
<li>environment: defines the user/group environment</li>
<li>tools: development tools</li>
<li>graphics: visualization or image manipulation tools</li>
<li>parallel: parallel execution software such as MPI</li>
<li>libraries: third-party libraries</li>
<li>compilers: the various compilers</li>
</ul>
<p>A domain-oriented view is provided by <strong class="command">module search &lt;keyword&gt;</strong>. To list the valid keywords use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">help</span> <span class="n">products</span><span class="o">/</span><span class="n">keywords</span>
</pre></div>
</div>
</div>
<div class="section" id="software-toolchains">
<h4>Software toolchains<a class="headerlink" href="#software-toolchains" title="Permalink to this headline">¶</a></h4>
<p>Most software products are built with several toolchains, a combination of Intel compilers and MPI libraries, that users are free to choose from:</p>
<ul class="simple">
<li>Intel composer 17</li>
<li>Intel composer 17 + OpenMPI 1.8</li>
<li>Intel composer 17 + OpenMPI 2.0</li>
<li>Intel composer 17 + Wi4MPI 3</li>
<li>Intel composer 19</li>
<li>Intel composer 19 + OpenMPI 4.0</li>
<li>Intel composer 20</li>
<li>Intel composer 20 + OpenMPI 4.0</li>
</ul>
<p>On Rome nodes, the users must use the Intel19/20 and openMPI 4.0. OpenMPI 1.8 and 2.0 are not available on irene-amd.</p>
<p>On-demand toolchains (please contact <a class="reference external" href="mailto:hotline&#46;tgcc&#37;&#52;&#48;cea&#46;fr">hotline<span>&#46;</span>tgcc<span>&#64;</span>cea<span>&#46;</span>fr</a>) :</p>
<ul class="simple">
<li>GCC 8</li>
<li>GCC 8 + OpenMPI 4</li>
<li>Intel composer 20 + IntelMPI 20</li>
<li>PGI 20 + OpenMPI 4.0</li>
<li>Intel 20 + Wi4MPI 3</li>
</ul>
<p>This approach provides a variety of compilation / runtime environments to users with consistency across products. To consult the list of available builds for a given product, type <strong class="command">module help &lt;product&gt;</strong>.</p>
<p>The selection between toolchains is made with two modules <code class="docutils literal notranslate"><span class="pre">flavor/buildcompiler/&lt;compiler&gt;/&lt;version&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">flavor/buildmpi/&lt;mpi&gt;/&lt;version&gt;</span></code>. It allows you to change the toolchain used for any loaded product regardless of the Intel compiler and MPI implementation used at runtime, which is determined by your current <code class="docutils literal notranslate"><span class="pre">intel</span></code> and <code class="docutils literal notranslate"><span class="pre">mpi</span></code> modules loaded.</p>
<p>More information on the <code class="docutils literal notranslate"><span class="pre">flavor</span></code> mechanism can be found on the <a class="reference internal" href="irene.html#flavor"><span class="std std-ref">dedicated section</span></a>.</p>
<p>The module <code class="docutils literal notranslate"><span class="pre">flavor/buildcompiler/&lt;compiler&gt;/&lt;version&gt;</span></code> lets you choose the version of the Intel compiler whereas the module <code class="docutils literal notranslate"><span class="pre">flavor/buildmpi/&lt;mpi&gt;/&lt;version&gt;</span></code> lets you choose the MPI implementation and version.</p>
<p>As a more meaningful example, let’s say a bug is introduced in your code with the latest MPI version, and you want to try the OpenMPI 1.8.8 MPI implementation instead. After loading the corresponding OpenMPI 1.8.8 module, you need to recompile your code.</p>
<p>If your code relies on the parallel NETCDF module, the flavor/buildmpi mechanism will automatically select the NETCDF product compiled with OpenMPI 1.8.8. For this particular example, you would only need to load the module mpi/openmpi/1.8.8 as the flavor/buildmpi/openmpi/1.8 will be automatically selected.</p>
</div>
</div>
<div class="section" id="specific-software">
<h3>Specific software<a class="headerlink" href="#specific-software" title="Permalink to this headline">¶</a></h3>
<p>The center has specific rules for restricted products and purchased products.</p>
<div class="section" id="restricted-software-products">
<h4>Restricted software products<a class="headerlink" href="#restricted-software-products" title="Permalink to this headline">¶</a></h4>
<p>A restricted product is referenced by <strong class="program">module</strong>, but its access is restricted to a specific Unix group. Although the reasons may vary, this usually comes from a license requirement.</p>
<p>For example, a licensed product may restrict its usage to academic purposes, or the purchased license is an academic one.</p>
<div class="section" id="module-and-restricted-products">
<h5>Module and restricted products<a class="headerlink" href="#module-and-restricted-products" title="Permalink to this headline">¶</a></h5>
<p><strong class="program">module</strong> has been extended to manage restricted products accordingly:</p>
<ul class="simple">
<li>restricted products are shown by the command <strong class="command">module avail</strong>, but <strong class="command">module load</strong> shows an error message if you are not authorized.</li>
<li>to list the authorizations, you should use:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">show</span> <span class="n">products</span><span class="o">/</span><span class="n">restrict</span>
</pre></div>
</div>
<ul class="simple">
<li>to get an authorization, see the information provided by <strong class="command">module show &lt;product&gt;</strong> or <strong class="command">module help product</strong>.</li>
</ul>
</div>
<div class="section" id="installation-request-and-restricted-products">
<span id="id2"></span><h5>Installation request and restricted products<a class="headerlink" href="#installation-request-and-restricted-products" title="Permalink to this headline">¶</a></h5>
<p>Simply explain in the installation request that you want the product access to be restricted, and tell why (see also <a class="reference internal" href="#installation-request"><span class="std std-ref">Installation request</span></a>).</p>
</div>
</div>
<div class="section" id="products-with-purchased-license">
<h4>Products with purchased license<a class="headerlink" href="#products-with-purchased-license" title="Permalink to this headline">¶</a></h4>
<p>Some products (such as Intel compilers) require a license server. We refer to them as <em>licensed products</em>.</p>
<div class="section" id="module-and-licensed-products">
<h5>Module and licensed products<a class="headerlink" href="#module-and-licensed-products" title="Permalink to this headline">¶</a></h5>
<p>Here are several adaptations of <strong class="program">module</strong> for <em>licensed products</em>:</p>
<ul class="simple">
<li>A <em>licensed product module</em> depends on a <em>license module</em> to find its license server.</li>
<li>Although the <em>license module</em> is not shown at load time, a <strong class="command">module list</strong> can display it.</li>
<li><em>license module</em> are named <em>licsrv/&lt;server&gt;</em> and are listed by:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">avail</span> <span class="n">licsrv</span>
</pre></div>
</div>
</div>
<div class="section" id="installation-request-and-purchased-products">
<span id="id3"></span><h5>Installation request and purchased products<a class="headerlink" href="#installation-request-and-purchased-products" title="Permalink to this headline">¶</a></h5>
<p>While requesting the installation of a <em>purchased product</em>, you may:</p>
<ul class="simple">
<li>have a license not requiring a dedicated server,</li>
<li>have the license and want to restrict its usage to a group of people (because you only have a few tokens),</li>
<li>have a global license (limited in time),</li>
<li>have no license and ask for the center to purchase it.</li>
</ul>
<p>The two first cases are handled by defining it as a <em>restricted product</em>.</p>
<p>The last case must be clearly justified. If so, you must at least:</p>
<ul class="simple">
<li>estimate the number of user,</li>
<li>specify its application domain,</li>
<li>tell us if you need the academic or the commercial license,</li>
<li>and tell us if you need a global license and/or how many tokens are necessary.</li>
</ul>
<p>Please note that, even if such installation follows the usual validation process, you may have additional delays, namely:</p>
<ul class="simple">
<li>if you need a non-FlexNet dedicated license server,</li>
<li>if you need to generate some license server identification (done by us and filtered for security reasons) before getting the license.</li>
</ul>
</div>
</div>
</div>
<div class="section" id="product-life-cycle">
<h3>Product Life cycle<a class="headerlink" href="#product-life-cycle" title="Permalink to this headline">¶</a></h3>
<p>Here are the phases of a software product life cycle, explained chronologically from its installation request to its deprecation and removal.</p>
<div class="section" id="installation-request">
<span id="id4"></span><h4>Installation request<a class="headerlink" href="#installation-request" title="Permalink to this headline">¶</a></h4>
<p>New products and/or product update(s) can be requested by mail to the CCC hotline.</p>
<p>Requests are usually accepted if:</p>
<ul class="simple">
<li>the product is the last stable version,</li>
<li>the product is useful to many users,</li>
<li>the product has no license issue.</li>
</ul>
<p>There are also special cases, namely:</p>
<ul class="simple">
<li>an installation for a group of persons is not possible since these persons are not part of the same user container,</li>
<li>or the product access should be restricted (see <a class="reference internal" href="#installation-request-and-restricted-products"><span class="std std-ref">Installation request and restricted products</span></a>),</li>
<li>or the product requires a license server (see <a class="reference internal" href="#installation-request-and-purchased-products"><span class="std std-ref">Installation request and purchased products</span></a>).</li>
</ul>
</div>
<div class="section" id="installation-phase">
<h4>Installation phase<a class="headerlink" href="#installation-phase" title="Permalink to this headline">¶</a></h4>
<p>If the installation request is approved, we will proceed to the installation itself:</p>
<ul class="simple">
<li>for an OS software product, it should be done at the next maintenance (or before if this is deemed safe).</li>
<li>and for an CCC software product, it should take several days.</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Those are estimated installation times. If technical difficulties occur the installation may take longer (example: licensed products)</p>
</div>
<p>Newly installed CCC software maybe listed with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">show</span> <span class="n">products</span><span class="o">/</span><span class="n">newinstall</span>
</pre></div>
</div>
</div>
<div class="section" id="production-phase">
<h4>Production phase<a class="headerlink" href="#production-phase" title="Permalink to this headline">¶</a></h4>
<p>During the production, the software product should be operational. If you detect an issue, a bug or a missing feature, please report it to the CCC hotline.</p>
</div>
<div class="section" id="end-of-life-and-removal">
<h4>End-of-life and removal<a class="headerlink" href="#end-of-life-and-removal" title="Permalink to this headline">¶</a></h4>
<p>An OS software product is considered obsolete when either the distribution considers it as such or when an update has been planned for the next maintenance.</p>
<p>For CCC software products, we try to respect the following rules. For each CCC software product, the center favors versions with the least bugs, the most features and the best performances. Hence the last stable version of a product is very welcome (new features, better performances and bug corrections). So when a new version of a product is installed, previous versions may become obsolete. To be more specific, we will only keep:</p>
<ul class="simple">
<li>the latest version,</li>
<li>its last known stable(s) version(s) (for reference purpose),</li>
<li>and the version(s) before retro-compatibility issues (mainly API break).</li>
</ul>
<p>As retro-compatibility issues may be unknown, removal of obsolete products are scheduled: they have reached their “end-of-life”.</p>
<p><strong class="program">module</strong> has been extended accordingly:</p>
<ul class="simple">
<li><strong class="command">load</strong>, <strong class="command">help</strong> or <strong class="command">show</strong> actions will display the following message for obsolete products:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">End</span><span class="o">-</span><span class="n">of</span><span class="o">-</span><span class="n">life</span> <span class="n">disclaimer</span><span class="p">:</span>
  <span class="o">&lt;</span><span class="n">product</span><span class="o">&gt;/&lt;</span><span class="n">version</span><span class="o">&gt;</span> <span class="ow">is</span> <span class="n">deprecated</span> <span class="ow">and</span> <span class="n">has</span> <span class="n">been</span> <span class="n">decommissioned</span> <span class="n">on</span>
  <span class="o">**</span> <span class="n">YYYY</span><span class="o">-</span><span class="n">MM</span><span class="o">-</span><span class="n">DD</span> <span class="o">**.</span> <span class="n">You</span> <span class="n">are</span> <span class="n">advised</span> <span class="n">to</span> <span class="n">use</span> <span class="n">the</span> <span class="n">default</span> <span class="n">version</span> <span class="n">of</span> <span class="n">the</span>
  <span class="n">software</span> <span class="n">instead</span> <span class="n">of</span> <span class="n">this</span> <span class="n">specific</span> <span class="n">version</span><span class="o">.</span> <span class="n">Please</span> <span class="n">contact</span> <span class="n">support</span> <span class="k">if</span>
  <span class="n">you</span> <span class="n">encounter</span> <span class="n">issue</span> <span class="k">with</span> <span class="n">software</span> <span class="n">default</span> <span class="n">version</span><span class="o">.</span>
</pre></div>
</div>
<ul class="simple">
<li>To list the products tagged as <em>end-of-life</em>, with their due date, type:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">show</span> <span class="n">products</span><span class="o">/</span><span class="n">endoflife</span>
</pre></div>
</div>
<p>At the due date, the CCC product in <em>end-of-life</em> state is uninstalled unless a user has given a valid reason to keep it. Hence, if the removal of a deprecated product is an issue for you, please contact the CCC hotline as soon as possible.</p>
</div>
</div>
</div>
<span id="document-toc/fulldoc/Job_submission"></span><div class="section" id="job-submission">
<span id="id1"></span><h2>Job submission<a class="headerlink" href="#job-submission" title="Permalink to this headline">¶</a></h2>
<p>Computing nodes are shared between all the users of the computing center. A job scheduler manages the access to the global resources and allows users to <em>book</em> the resources they need for their computation. Job submission, resource allocation and job launch are handled by the batch scheduler called SLURM. An abstraction layer called Bridge is provided to give uniform command-line tools and more integrated ways to access batch scheduling systems.</p>
<p>To submit a batch job, you first have to write a shell script containing:</p>
<ul class="simple">
<li>a set of directives to tell which resources your job needs.</li>
<li>instructions to execute your code.</li>
</ul>
<p>You can launch the job by submitting its script to the batch scheduler. It will enter a batch queue. When resources become available, the job is launched over its allocated nodes. Jobs can be monitored.</p>
<div class="section" id="scheduling-policy">
<span id="id2"></span><h3>Scheduling policy<a class="headerlink" href="#scheduling-policy" title="Permalink to this headline">¶</a></h3>
<p>Jobs are submitted to the supercomputer resource manager which will decide how to schedule them. There are hundreds of jobs submitted daily and the order in which they are launched depends on several parameters.</p>
<p>Jobs are sorted by priority. The priority is an integer value initially assigned to the job when it is submitted. The job with the highest priority will start first as soon as enough resources are available. Sometimes, a job with a lower priority may start first but only if it does not delay any job with a higher priority. This mechanism is called <em>backfill scheduling</em> and jobs can easily be backfilled if they require few computing resources and have a small time limit.</p>
<p>Here are the 3 components that are added to obtain the priority. They are listed below in order of importance:</p>
<ul class="simple">
<li><strong>The Quality of Service (QoS)</strong>: The QoS component is a constant value associated to the QoS chosen during the submission. Its value depends on the priority factor given by the <strong class="command">ccc_mqinfo</strong> command. This is the component that has the most influence on the overall value of the priority. Also, an usage limit can be set to prevent jobs from running as long as the project is not under a certain consumption. See <a class="reference internal" href="#qos"><span class="std std-ref">Qos</span></a> for more information.</li>
<li><strong>The project’s fair-share</strong>: The fair-share component reflects the ratio between the total share of allocated hours and the amount of hours consumed for the chosen project. The fair-share value will be high if the project is under-consuming its allocated hours whereas it will be low if the project is over-consuming its allocated hours. A half-life decay is applied to the computation of the fair-share with a half life period of 14 days. That way, an over-consumption or under-consumption of hours will have a decreasing impact on new jobs submissions. After 2 months, the negative impact of an over-consumption is almost insignificant.</li>
<li><strong>The job’s age</strong>: The age component depends on the time spent in a pending state while waiting for resources. Its value is incremented regularly for 7 days. After this delay, it will not increase anymore.</li>
</ul>
<p>In order to reduce the waiting time as much as possible, try to:</p>
<ul class="simple">
<li>Use your computing hours evenly throughout your project duration. It will increase your fair-share value, thus increase the priority of your jobs.</li>
<li>For small jobs, specify a time limit as close as possible to the real duration of the job instead of leaving default time limit of 2 hours. That way you are more likely to benefit from the <em>backfill scheduling</em> mechanism.</li>
<li>Since the default time limit is 2 hours for all jobs, try to specify a time limit as close as possible to the real duration of your job. That way you are more likely to benefit from the <em>backfill scheduling</em> mechanism.</li>
</ul>
</div>
<div class="section" id="choosing-the-file-systems">
<h3>Choosing the file systems<a class="headerlink" href="#choosing-the-file-systems" title="Permalink to this headline">¶</a></h3>
<p>Your job submissions can use the <code class="xref std std-option docutils literal notranslate"><span class="pre">-m</span></code> option to specify the file systems compute nodes will need for execution. This avoids job suspensions, if an unused file system becomes unavailable.</p>
<blockquote>
<div>example: <strong class="command">ccc_msub -m scratch,store</strong> will run even if the WORK file system is unavailable. You can choose the following file systems: <strong>scratch</strong>, <strong>work</strong> and <strong>store</strong>.</div></blockquote>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">On Irene, your job submissions <strong>MUST</strong> use the <code class="xref std std-option docutils literal notranslate"><span class="pre">-m</span></code> option. Failing to provide the <code class="xref std std-option docutils literal notranslate"><span class="pre">-m</span></code> option will actually prevent your compute nodes from using any of <strong>scratch</strong>, <strong>work</strong> or <strong>store</strong>.</p>
</div>
</div>
<div class="section" id="submission-scripts">
<h3>Submission scripts<a class="headerlink" href="#submission-scripts" title="Permalink to this headline">¶</a></h3>
<div class="section" id="ccc-msub">
<h4>ccc_msub<a class="headerlink" href="#ccc-msub" title="Permalink to this headline">¶</a></h4>
<p><strong class="command">ccc_msub &lt;script&gt;</strong> is the command used to submit your batch job to the resource manager. The options passed to <strong class="command">ccc_msub</strong> will determine the number of cores allocated to the job.</p>
<p>There are two ways of passing arguments to <strong class="command">ccc_msub</strong>.</p>
<ul class="simple">
<li>Use the <code class="code docutils literal notranslate"><span class="pre">#MSUB</span></code> keyword in the submission script. All the lines beginning with <code class="code docutils literal notranslate"><span class="pre">#MSUB</span></code> will be parsed and the corresponding parameters will be taken into account by the batch manager.</li>
<li>Use command line arguments. If the same argument is specified in the command line and the submission script, the command line argument will take precedence.</li>
</ul>
<p>Note that you cannot pass arguments to the submission script when launching with <strong class="command">ccc_msub</strong>.</p>
<p>For a short documentation and list of available options, see the help message:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_msub -h
</pre></div>
</div>
<div class="section" id="basic-options">
<h5>Basic options<a class="headerlink" href="#basic-options" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-o</span> <span class="pre">output_file</span></code>: standard output file (special character <code class="code docutils literal notranslate"><span class="pre">%I</span></code> will be replaced by the job ID)</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-e</span> <span class="pre">error_file</span></code>: standard error file (special character <code class="code docutils literal notranslate"><span class="pre">%I</span></code> will be replaced by the job ID)</li>
</ul>
<p>All the output and error messages generated by the job are redirected to the log files specified with <code class="xref std std-option docutils literal notranslate"><span class="pre">-o</span></code> and <code class="xref std std-option docutils literal notranslate"><span class="pre">-e</span></code>. If you want all output to be redirected in one single file, just set the same name for <code class="xref std std-option docutils literal notranslate"><span class="pre">-o</span></code> and <code class="xref std std-option docutils literal notranslate"><span class="pre">-e</span></code>.</p>
<ul>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-r</span> <span class="pre">reqname</span></code>: job name</p>
</li>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-A</span> <span class="pre">projid</span></code>: project/account name</p>
</li>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-m</span> <span class="pre">filesystem</span></code>: file system required by the job. If another file system is unavailable, the job will not be impacted. Without the option, the job is considered to use every file system</p>
<p>example: <strong class="command">ccc_msub -m scratch,store</strong> will run even if the WORK file system is unavailable. You can choose the following file systems: <strong>scratch</strong>, <strong>work</strong> and <strong>store</strong>.</p>
</li>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-&#64;</span> <span class="pre">mailopts</span></code>: mail options following the pattern <code class="regexp docutils literal notranslate"><span class="pre">mailaddr[:begin|end|requeue]</span></code></p>
<p>example: <strong class="command">ccc_msub -&#64; jdoe&#64;foo.com:begin,end</strong> will send a mail to jdoe at the beginning and the end of the job default behavior depends of the underlying batch system</p>
</li>
</ul>
</div>
<div class="section" id="partitions">
<h5>Partitions<a class="headerlink" href="#partitions" title="Permalink to this headline">¶</a></h5>
<p>The compute nodes are gathered in partitions according to their hardware characteristics (CPU architecture, amount of RAM, presence of GPU, etc). A partition is a set of identical nodes that can be targeted to host one or several jobs. Choosing the right partition for a job depends on code prerequisites in term of hardware resources. For example, executing a code designed to be GPU accelerated requires a partition with GPU nodes.</p>
<p>The partition is specified with the <code class="xref std std-option docutils literal notranslate"><span class="pre">-q</span></code> option. This option is mandatory while submitting.</p>
<p>The <strong class="command">ccc_mpinfo</strong> command lists the available partitions for the current supercomputer. For each partition, it will display the number of available cores and nodes but also give some hardware specifications of the nodes composing the partition. For more information, see the <a class="reference internal" href="irene.html#supercomputer-architecture"><span class="std std-ref">Supercomputer architecture</span></a> section.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>This choice is exclusive: your job can only be submitted on one of those architectures at a time.</li>
<li>Job priority and limits are not related to the partition but to the QoS (Quality of Service) parameter (option <code class="xref std std-option docutils literal notranslate"><span class="pre">-Q</span></code>). QoS is the main component of job priority.</li>
<li>Depending on the allocation granted to your project, you may not have access to all the partitions. You can check on which partition(s) your project has allocated hours thanks to the command <strong class="command">ccc_myproject</strong>.</li>
</ul>
</div>
</div>
<div class="section" id="resources">
<h5>Resources<a class="headerlink" href="#resources" title="Permalink to this headline">¶</a></h5>
<p>There are several options that will influence the number of cores that will be allocated for the job.</p>
<ul>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-n</span></code>: number of tasks that will be used in parallel mode (default=1)</p>
</li>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span></code>: number of cores per parallel task to allocate (default=1)</p>
<p>If the <code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span></code> parameter is not specified, the number of cores allocated is equal to the number of parallel tasks requested with <code class="xref std std-option docutils literal notranslate"><span class="pre">-n</span></code>. So specifying <code class="xref std std-option docutils literal notranslate"><span class="pre">-n</span></code> is enough for most of the basic jobs.
The <code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span></code> option is useful when each MPI process launched needs more resources than just one core. It can be either to require more cpu power or more memory:</p>
<ul class="simple">
<li>For hybrid MPI/OpenMP jobs, each MPI process will need several cores in order to spawn its OpenMP threads. In that case, usually, the <code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span></code> option is equal to the number passed to <span class="target" id="index-0"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">OMP_NUM_THREADS</span></code></li>
<li>For jobs requiring a lot of memory, each MPI process may need more than the 4 GB it is granted by default. In that case, the amount of memory may be multiplied by allocating more cores for each process. For example, by specifying <code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span> <span class="pre">2</span></code>, each process will be able to use the memory of 2 cores: 8GB.</li>
</ul>
</li>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-N</span></code>: number of nodes to allocate for parallel usage (default is chosen by the underlying system)</p>
<p>The <code class="xref std std-option docutils literal notranslate"><span class="pre">-N</span></code> option is not necessary in most of the cases. The number of nodes to use is inferred by the number of cores requested and the number of cores per node of the partition used.</p>
</li>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-x</span></code>: request for exclusive usage of allocated nodes</p>
<p>The <code class="xref std std-option docutils literal notranslate"><span class="pre">-x</span></code> options forces the allocation of a whole node, even if only a couple of cores were requested. This is the default configuration for jobs requiring more than 128 cores.</p>
</li>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-T</span> <span class="pre">time_limit</span></code>: maximum walltime of the batch job in seconds (optional directive, if not provided, set to default = 7200)</p>
<p>It may be useful to set an accurate walltime in order to benefit from backfill scheduling.</p>
</li>
</ul>
</div>
<div class="section" id="knl-partition">
<h5>KNL partition<a class="headerlink" href="#knl-partition" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>To submit a job on a KNL node, you need to load the feature given in the following submission script :</li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -q knl</span>
<span class="c1">#MSUB -n 256</span>
<span class="c1">#MSUB -N 4</span>
module sw feature/openmpi/net/aut
ccc_mprun ./my-application
</pre></div>
</div>
<ul class="simple">
<li>KNL nodes are disk-less, writing in /tmp reduce the amount of memory available to the application.</li>
<li>As of today, the default value of number of nodes (-N) is erroneous. You have to explicitly set its correct value depending of the resources asked in the submission script.</li>
</ul>
</div>
<div class="section" id="v100-partition-gpu">
<h5>V100 partition (GPU)<a class="headerlink" href="#v100-partition-gpu" title="Permalink to this headline">¶</a></h5>
<p>This section describes the submission policy concerning V100 nodes (GPU) on the Irene-PPI cluster. The different submission queues are presented as well as their respective dedicated use case.</p>
<p>The different hardware configurations are the following:</p>
<ul class="simple">
<li><strong>V100</strong>: dual-socket interactive nodes<ul>
<li>Partition name: v100</li>
<li>CPUs: 2 x 20 cores Intel <a class="reference external" href="mailto:Cascadelake&#37;&#52;&#48;2&#46;1GHz">Cascadelake<span>&#64;</span>2<span>&#46;</span>1GHz</a> x 2 hyperthreads</li>
<li>GPUs: 4x Nvidia Tesla V100-SXM2</li>
<li>RAM/Node: 180 GB</li>
<li>RAM/Core: 4.5 GB</li>
</ul>
</li>
<li><strong>V100l</strong>: dual-socket interactive nodes<ul>
<li>Partition name: v100l</li>
<li>CPUs: 2 x 18 cores Intel <a class="reference external" href="mailto:Cascadelake&#37;&#52;&#48;2&#46;6GHz">Cascadelake<span>&#64;</span>2<span>&#46;</span>6GHz</a> x 2 hyperthreads</li>
<li>GPUs: 1 x Nvidia Tesla V100-PCIE</li>
<li>RAM/Node: 360 GB</li>
<li>RAM/Core: 10 GB</li>
</ul>
</li>
<li><strong>V100xl</strong> quad-socket interactive nodes<ul>
<li>Partition name: v100xl</li>
<li>CPUs: 4 x 18 cores Intel <a class="reference external" href="mailto:Cascadelake&#37;&#52;&#48;2&#46;6GHz">Cascadelake<span>&#64;</span>2<span>&#46;</span>6GHz</a> x 2 hyperthreads</li>
<li>GPUs: 1 x Nvidia Tesla V100-PCIE</li>
<li>RAM/Node: 3 TB</li>
<li>RAM/Core: 41.5 GB</li>
</ul>
</li>
</ul>
<p>The usage of GPUs on v100, v100l, v100xl partitions does not require the exclusive submission mode. The allocation of the GPUs is made proportionately to the number of required cores. Thus jobs allocating GPUs and sharing the same nodes can only access to their respective allocated GPUs.</p>
<p>On v100, allocation of 1 to 9 core(s) will lead to no GPU allocation, 10 to 19 cores to 1 GPU, 20 cores to 29 to 2 GPUs, 30 cores to 39 cores to 3 GPUs and 40 cores to the total 4 GPUs allocation of the node. Equivalently, any GPU specific reservation will increase the number of allocated cores according to the same ratio (e.g. a 4 GPUs submission leads to the allocation of 40 cores). On v100l, v100xl where nodes have only one GPU, the complete allocation of the cores on the node is required to have access to the GPU. Equivalently, allocation of the GPU implies the allocation of all cores.</p>
<p>You will find below an example of a launching command (ccc_mprun) for each possible configuration (partition and number of cores/GPU).</p>
<ul class="simple">
<li>For the v100 partition</li>
</ul>
<p>Up to 9 cores allocation leads to no allocated GPU:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -p v100 ./show_my_ressources.sh v100
Number of cuda devices used <span class="m">0</span>
Partition JobID AllocCPUS AllocGRES
v100      <span class="m">422</span>      <span class="m">1</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -p v100 ./show_my_ressources.sh v100
Number of cuda devices used <span class="m">0</span>
Partition JobID AllocCPUS AllocGRES
v100      <span class="m">425</span>      <span class="m">9</span>
</pre></div>
</div>
<p>From 10 to 19 cores allocations leads to one allocated GPU:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -c <span class="m">10</span> -p v100 ./show_my_ressources.sh
Number of cuda devices used <span class="m">1</span>
Partition JobID AllocCPUS AllocGRES
v100      <span class="m">334</span>      <span class="m">10</span>       gpu:1
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -c <span class="m">19</span> -p v100 ./show_my_ressources.sh
Number of cuda devices used <span class="m">1</span>
Partition JobID AllocCPUS AllocGRES
v100      <span class="m">335</span>      <span class="m">19</span>       gpu:1
</pre></div>
</div>
<p>From 2O to 29 cores allocations leads to 2 allocated GPUs:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -c <span class="m">20</span> -p v100 ./show_my_ressources.sh
Number of cuda devices used <span class="m">2</span>
Partition JobID AllocCPUS AllocGRES
v100      <span class="m">336</span>      <span class="m">20</span>       gpu:2
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -c <span class="m">20</span> -p v100 ./show_my_ressources.sh
Number of cuda devices used <span class="m">2</span>
Partition JobID AllocCPUS AllocGRES
v100      <span class="m">337</span>      <span class="m">29</span>       gpu:2
</pre></div>
</div>
<p>From 3O to 39 cores allocations leads to 3 allocated GPUs:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -c <span class="m">30</span> -p v100 ./show_my_ressources.sh
Number of cuda devices used <span class="m">3</span>
Partition JobID AllocCPUS AllocGRES
v100      <span class="m">340</span>      <span class="m">30</span>       gpu:3
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -c <span class="m">39</span> -p v100 ./show_my_ressources.sh
Number of cuda devices used <span class="m">3</span>
Partition JobID AllocCPUS AllocGRES
v100      <span class="m">341</span>      <span class="m">39</span>       gpu:3
</pre></div>
</div>
<p>Total number of cores allocation leads to the allocation of the 4 GPUs:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -c <span class="m">40</span> -p v100 ./show_my_ressources.sh
Number of cuda devices used <span class="m">4</span>
Partition JobID AllocCPUS AllocGRES
v100      <span class="m">342</span>      <span class="m">40</span>       gpu:4
</pre></div>
</div>
<p>Similarly, allocation in exclusive mode forces the use of 4 GPUs with 40 cores:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -x -p v100 ./show_my_ressources.sh
Number of cude devices used <span class="m">4</span>
Partition JobID AllocCPUS AllocGRES
v100      <span class="m">347</span>      <span class="m">40</span>       gpu:4
</pre></div>
</div>
<p>Specific GPUs number demand increases the number of allocated cores according to the ratio explained above. To do so, the option <code class="xref std std-option docutils literal notranslate"><span class="pre">-E</span> <span class="pre">&quot;--gres=gpu=&lt;Number</span> <span class="pre">of</span> <span class="pre">GPU&gt;&quot;</span></code> must be added to the <strong class="command">ccc_mprun</strong> (or <strong class="command">ccc_msub</strong>) command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n -1 -E <span class="s2">&quot;--gres=gpu:2&quot;</span> -p v100 ./show_my_ressources.sh
Number of cude devices used <span class="m">2</span>
Partition JobID AllocCPUS AllocGRES
v100      <span class="m">349</span>      <span class="m">20</span>       gpu:2
</pre></div>
</div>
<p>Allocation of 4 GPUs implies full cores allocation:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -E <span class="s2">&quot;--gres=gpu:4&quot;</span> -p v100 ./show_my_ressources.sh
Number of cude devices used <span class="m">4</span>
Partition JobID AllocCPUS AllocGRES
v100      <span class="m">350</span>      <span class="m">40</span>       gpu:4
</pre></div>
</div>
<ul class="simple">
<li>For the v100l and v100xl partitions</li>
</ul>
<p>Up to 35 allocated cores lead to no allocated GPU:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun
Number of cude devices used <span class="m">0</span>
Partition JobID AllocCPUS AllocGRES
v100l     <span class="m">368</span>      <span class="m">35</span>
</pre></div>
</div>
<p>Whereas allocating the total number of cores per node leads to the allocation of the GPU:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -c <span class="m">36</span> -p v100l ./show_my_ressources.sh
Number of cude devices used <span class="m">1</span>
Partition JobID AllocCPUS AllocGRES
v100l     <span class="m">370</span>      <span class="m">36</span>     gpu:1
</pre></div>
</div>
<p>Equivalently GPU allocation leads to full cores allocation:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -E <span class="s2">&quot;--gres=gpu:1&quot;</span> -p v100l ./show_my_ressources.sh
Number of cude devices used <span class="m">4</span>
Partition JobID AllocCPUS AllocGRES
v100l     <span class="m">370</span>      <span class="m">36</span>     gpu:1
</pre></div>
</div>
<ul class="simple">
<li><strong>Oversubscription</strong></li>
</ul>
<p>If your job does not require performance such as in a debug session, you can reduce the CPU hours charged by using the v100l-os partition. Indeed this specific partition allows to share cores of the nodes up to 4 jobs, reducing by 4 the CPU hours charged. As a result of the job sharing, the default allocated memory per core is divided by 4 (2.5 GB per core) and the GPU is no more accessible. Note that it is possible to request more memory per core (up to 5 GB per core), thus dividing the CPU hours charged by 2 instead of 4.</p>
<ul>
<li><dl class="first docutils">
<dt><strong>V100l-os</strong>: dual-socket interactive nodes with oversubscribed cores</dt><dd><ul class="simple">
<li>Partition name: v100l</li>
<li>CPUs: 2 x 18 cores Intel <a class="reference external" href="mailto:Cascadelake&#37;&#52;&#48;2&#46;6GHz">Cascadelake<span>&#64;</span>2<span>&#46;</span>6GHz</a> x 2 hyperthreads</li>
<li>GPUs: 1x Nvidia Tesla V100-PCIE</li>
<li>RAM/Node: 360 GB</li>
<li>RAM/Core: 10 GB</li>
<li>GPU disabled</li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>Here is an example of use for 4 submitted jobs on the same node, same cores (note the 2.5 GB per core memory):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -c <span class="m">36</span> -p v100l-os ./show_my_cpus.sh
irene7100: Cpus_allowed_list:0-71

<span class="m">416</span>  v100l-os show_my_   PD       <span class="m">0</span>:00      <span class="m">1</span> <span class="o">(</span>Resources<span class="o">)</span>
<span class="m">412</span>  v100l-os show_my_    R       <span class="m">0</span>:11      <span class="m">1</span> irene7100
<span class="m">413</span>  v100l-os show_my_    R       <span class="m">0</span>:10      <span class="m">1</span> irene7100
<span class="m">414</span>  v100l-os show_my_    R       <span class="m">0</span>:08      <span class="m">1</span> irene7100
<span class="m">415</span>  v100l-os show_my_    R       <span class="m">0</span>:07      <span class="m">1</span> irene7100

JobID   ReqMem   AllocCPUS
<span class="m">412</span>     2500Mc    <span class="m">36</span>
<span class="m">413</span>     2500Mc    <span class="m">36</span>
<span class="m">414</span>     2500Mc    <span class="m">36</span>
<span class="m">415</span>     2500Mc    <span class="m">36</span>
</pre></div>
</div>
<p>If more memory is needed (up to 5 GB/core), one can request it by using the option <code class="xref std std-option docutils literal notranslate"><span class="pre">-E</span> <span class="pre">&quot;--mem-per-cpu=&lt;Memory</span> <span class="pre">in</span> <span class="pre">MB&gt;&quot;</span></code>. For instance for 5 GB per core resulting in 2 submitted jobs on the same node, same cores:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n <span class="m">1</span> -c <span class="m">36</span> -p v100l-os -E <span class="s2">&quot;--mem-per-cpu=5000&quot;</span>  ./show_my_cpus.sh <span class="p">&amp;</span>
irene7100: Cpus_allowed_list:0-71

<span class="m">516</span>  v100l-os show_my_   PD       <span class="m">0</span>:00      <span class="m">1</span> <span class="o">(</span>Resources<span class="o">)</span>
<span class="m">514</span>  v100l-os show_my_    R       <span class="m">0</span>:08      <span class="m">1</span> irene7100
<span class="m">515</span>  v100l-os show_my_    R       <span class="m">0</span>:07      <span class="m">1</span> irene7100

JobID   ReqMem   AllocCPUS
<span class="m">514</span>     5000Mc    <span class="m">36</span>
<span class="m">515</span>     5000Mc    <span class="m">36</span>
</pre></div>
</div>
</div>
<div class="section" id="qos">
<span id="id3"></span><h5>QoS<a class="headerlink" href="#qos" title="Permalink to this headline">¶</a></h5>
<p>One can specify a Quality of Service (QoS) for each job submitted to the scheduler. The quality of service associated to a job will affect it in two ways: scheduling priority and limits. Depending on the required quantity of resources, on duration or on the job purpose (debugging, normal production, etc), you have to select the appropriate job QoS. It enables to trade a high job submission limit for a lower job priority, or a high job priority for lesser resources and duration.</p>
<p><strong class="command">ccc_mqinfo</strong> displays the available job QoS and the associated limitations:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mqinfo
Name     Partition  Priority  MaxCPUs  SumCPUs  MaxNodes  MaxRun  MaxSub     MaxTime
-------  ---------  --------  -------  -------  --------  ------  ------  ----------
long             *        20     2048     2048                        32  3-00:00:00
normal           *        20                                         128  1-00:00:00
test             *        40                           2               2    00:30:00
test     partition        40      280      280        10               2    00:30:00
</pre></div>
</div>
<p>For instance, to develop or debug your code, you may submit a job using the <em>test</em> QoS which will allow it to be scheduled faster. This QoS is limited to 2 jobs of maximum 30 minutes and 10 nodes each. CPU time accounting is not dependent on the chosen QoS.</p>
<p>To specify a QoS, you can use the <code class="xref std std-option docutils literal notranslate"><span class="pre">-Q</span></code> option of command-line or add <code class="code docutils literal notranslate"><span class="pre">#MSUB</span> <span class="pre">-Q</span> <span class="pre">&lt;qosname&gt;</span></code> directive to your submission script. If no QoS is mentioned, default QoS <em>normal</em> will be used.</p>
<p>An usage limit can be set to manage hours consumption within a project. The usage limit can be set to <em>high</em>, <em>medium</em> or <em>low</em> with the option <code class="code docutils literal notranslate"><span class="pre">#MSUB</span> <span class="pre">-U</span> <span class="pre">&lt;limit&gt;</span></code>.</p>
<ul class="simple">
<li>A job submitted with <code class="xref std std-option docutils literal notranslate"><span class="pre">-U</span> <span class="pre">high</span></code> priority will be scheduled normally as described in <a class="reference internal" href="#scheduling-policy"><span class="std std-ref">Scheduling policy</span></a>. This is the default behavior if no usage limit is specified.</li>
<li>A job submitted with <code class="xref std std-option docutils literal notranslate"><span class="pre">-U</span> <span class="pre">medium</span></code> will only be scheduled if the current project consumption is less than 20% over the <em>suggested use at this time</em>.</li>
<li>A job submitted with <code class="xref std std-option docutils literal notranslate"><span class="pre">-U</span> <span class="pre">low</span></code> will only be scheduled if the current project consumption is more than 20% under the <em>suggested use at this time</em>.</li>
</ul>
<p>Medium and low priority jobs may stay pending even if all the resources are free. It allows to prevent non important jobs from over consuming project hours and thus lower the default priority of future important jobs.</p>
</div>
<div class="section" id="creating-a-virtual-cluster">
<h5>Creating a virtual cluster<a class="headerlink" href="#creating-a-virtual-cluster" title="Permalink to this headline">¶</a></h5>
<p>It’s possible to use the <strong class="command">ccc_msub -z &lt;pcocc_template&gt;</strong> command to submit a job on a virtual cluster created with pcocc VMs. More information on usage can be found in the <a class="reference internal" href="irene.html#bridge-plugin"><span class="std std-ref">Virtualization Bridge plugin</span></a> section.</p>
</div>
<div class="section" id="dependencies-between-jobs">
<h5>Dependencies between jobs<a class="headerlink" href="#dependencies-between-jobs" title="Permalink to this headline">¶</a></h5>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The following methods are equivalent concerning the priorities of dependent jobs. See the <a class="reference internal" href="#scheduling-policy"><span class="std std-ref">Scheduling policy</span></a> section for more details.</p>
</div>
<p>The command offers two options to prevent some jobs from running at the same time. Those options are <code class="xref std std-option docutils literal notranslate"><span class="pre">-w</span></code> and <code class="xref std std-option docutils literal notranslate"><span class="pre">-a</span></code>:</p>
<ul class="simple">
<li>The option <code class="xref std std-option docutils literal notranslate"><span class="pre">-w</span></code> makes jobs with the same submission name (specified with <code class="xref std std-option docutils literal notranslate"><span class="pre">-r</span></code>) run in the order they were submitted. For example, all jobs with the following options will not run at the same time.</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#MSUB -r SAME_NAME</span>
<span class="c1">#MSUB -w</span>
</pre></div>
</div>
<ul class="simple">
<li>The option <code class="xref std std-option docutils literal notranslate"><span class="pre">-a</span></code> indicates that a job depends on another (already submitted) job. Use it with the id of the existing job.</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_msub</span> <span class="o">-</span><span class="n">a</span> <span class="o">&lt;</span><span class="n">existing_job</span><span class="o">&gt;</span> <span class="n">script</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<ul class="simple">
<li>One can write multi step jobs that run sequentially by submitting the next job at the end of the current script. Here are some example scripts:</li>
</ul>
<p>JOB_A.sh:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -r JOB_A</span>
<span class="c1">#MSUB -n 32</span>
<span class="c1">#MSUB -q &lt;partition&gt;</span>
<span class="n">ccc_mprun</span> <span class="o">./</span><span class="n">a</span><span class="o">.</span><span class="n">out</span>
<span class="n">ccc_msub</span> <span class="n">JOB_B</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>JOB_B.sh:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -r JOB_B</span>
<span class="c1">#MSUB -n 16</span>
<span class="c1">#MSUB -q &lt;partition&gt;</span>
<span class="n">ccc_mprun</span> <span class="o">./</span><span class="n">b</span><span class="o">.</span><span class="n">out</span>
<span class="n">ccc_msub</span> <span class="n">JOB_C</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>JOB_C.sh:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -r JOB_C</span>
<span class="c1">#MSUB -n 8</span>
<span class="c1">#MSUB -q &lt;partition&gt;</span>
<span class="n">ccc_mprun</span> <span class="o">./</span><span class="n">c</span><span class="o">.</span><span class="n">out</span>
</pre></div>
</div>
<p>Then, only JOB_A.sh has to be submitted. When it finishes, the script submits JOB_B.sh, etc…</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If a job is killed or if it reaches its time limit, all the jobs are removed and the last <strong class="command">ccc_msub</strong> may not be launched.
To avoid this, you can use the <strong class="command">ccc_tremain</strong> from libccc_user or use the <code class="code docutils literal notranslate"><span class="pre">#MSUB</span> <span class="pre">-w</span></code> directive as described above.</p>
</div>
</div>
<div class="section" id="environment-variables">
<h5>Environment variables<a class="headerlink" href="#environment-variables" title="Permalink to this headline">¶</a></h5>
<p>When a job is submitted, some environment variables are set. Those variables may be used only within the job script.</p>
<ul class="simple">
<li><span class="target" id="index-1"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">BRIDGE_MSUB_JOBID</span></code>: batch id of the running job.</li>
<li><span class="target" id="index-2"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">BRIDGE_MSUB_MAXTIME</span></code>: timelimit in seconds of the job.</li>
<li><span class="target" id="index-3"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">BRIDGE_MSUB_PWD</span></code>: working directory. Usually the directory in which the job was submitted.</li>
<li><span class="target" id="index-4"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">BRIDGE_MSUB_NPROC</span></code>: number of requested processes</li>
<li><span class="target" id="index-5"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">BRIDGE_MSUB_NCORE</span></code>: number of requested cores per process</li>
<li><span class="target" id="index-6"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">BRIDGE_MSUB_REQNAME</span></code>: job name</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You cannot use those variables as input arguments to <strong class="command">ccc_msub</strong>. You cannot use them with the <code class="code docutils literal notranslate"><span class="pre">#MSUB</span></code> headers.</p>
</div>
</div>
</div>
<div class="section" id="ccc-mprun">
<h4>ccc_mprun<a class="headerlink" href="#ccc-mprun" title="Permalink to this headline">¶</a></h4>
<p><strong class="command">ccc_mprun</strong> command allows to launch parallel jobs over nodes allocated by resources manager. So inside a submission script, a parallel code will be launched with the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_mprun</span> <span class="o">./</span><span class="n">a</span><span class="o">.</span><span class="n">out</span>
</pre></div>
</div>
<p>By default, <strong class="command">ccc_mprun</strong> takes information (number of nodes, number of processors, etc) from the resources manager to launch the job. You can customize its behavior with the command line options. Type <strong class="command">ccc_mprun -h</strong> for an up-to-date and complete documentation.</p>
<p>Here are some basic options <strong class="command">ccc_mprun</strong>:</p>
<ul>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-n</span> <span class="pre">nproc</span></code>: number of tasks to run</p>
</li>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span> <span class="pre">ncore</span></code>: number of cores per task</p>
</li>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-N</span> <span class="pre">nnode</span></code>: number of nodes to use</p>
</li>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-T</span> <span class="pre">time</span></code>: maximum walltime of the allocations in seconds ( optional directive, if not provided, set to default=7200)</p>
</li>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-E</span> <span class="pre">extra</span></code>: extra parameters to pass directly to the underlying resource manager</p>
</li>
<li><p class="first"><code class="xref std std-option docutils literal notranslate"><span class="pre">-m</span> <span class="pre">filesystem</span></code>: file system required by the job. If another file system is unavailable, the job will not be impacted. Without the option, the job is considered to use every file system</p>
<p>example: <strong class="command">ccc_msub -m scratch,store</strong> will run even if the WORK file system is unavailable. You can choose the following file systems: <strong>scratch</strong>, <strong>work</strong> and <strong>store</strong>.</p>
</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the resources requested by <strong class="command">ccc_mprun</strong> are not compatible with the resources previously allocated with <strong class="command">ccc_msub</strong>, the job will crash with the following error message:</p>
<div class="last highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">srun</span><span class="p">:</span> <span class="n">error</span><span class="p">:</span> <span class="n">Unable</span> <span class="n">to</span> <span class="n">create</span> <span class="n">job</span> <span class="n">step</span><span class="p">:</span> <span class="n">More</span> <span class="n">processors</span> <span class="n">requested</span> <span class="n">than</span> <span class="n">permitted</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="script-examples">
<h4>Script examples<a class="headerlink" href="#script-examples" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><strong>Sequential job</strong></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -r MyJob               # Request name</span>
<span class="c1">#MSUB -n 1                   # Number of tasks to use</span>
<span class="c1">#MSUB -T 600                 # Elapsed time limit in seconds of the job (default: 7200)</span>
<span class="c1">#MSUB -o example_%I.o        # Standard output. %I is the job id</span>
<span class="c1">#MSUB -e example_%I.e        # Error output. %I is the job id</span>
<span class="c1">#MSUB -A projxxxx            # Project ID</span>
<span class="c1">#MSUB -q &lt;partition&gt;         # Choosing nodes (see ccc_mpinfo)</span>
<span class="nb">set</span> -x
<span class="nb">cd</span> <span class="si">${</span><span class="nv">BRIDGE_MSUB_PWD</span><span class="si">}</span>        <span class="c1"># The BRIDGE_MSUB_PWD environment variable contains the directory from which the script was submitted.</span>
./a.out
</pre></div>
</div>
<ul class="simple">
<li><strong>Parallel MPI job</strong></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -r MyJob_Para                # Request name</span>
<span class="c1">#MSUB -n 32                        # Number of tasks to use</span>
<span class="c1">#MSUB -T 1800                      # Elapsed time limit in seconds</span>
<span class="c1">#MSUB -o example_%I.o              # Standard output. %I is the job id</span>
<span class="c1">#MSUB -e example_%I.e              # Error output. %I is the job id</span>
<span class="c1">#MSUB -q &lt;partition&gt;</span>
<span class="c1">#MSUB -A projxxxx                  # Project ID</span>
<span class="nb">set</span> -x
<span class="nb">cd</span> <span class="si">${</span><span class="nv">BRIDGE_MSUB_PWD</span><span class="si">}</span>
ccc_mprun ./a.out
</pre></div>
</div>
<ul class="simple">
<li><strong>Parallel OpenMP/multi-threaded job</strong></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -r MyJob_Para                # Request name</span>
<span class="c1">#MSUB -n 1                         # Number of tasks to use</span>
<span class="c1">#MSUB -c 16                        # Number of threads per task to use</span>
<span class="c1">#MSUB -T 1800                      # Elapsed time limit in seconds</span>
<span class="c1">#MSUB -o example_%I.o              # Standard output. %I is the job id</span>
<span class="c1">#MSUB -e example_%I.e              # Error output. %I is the job id</span>
<span class="c1">#MSUB -q &lt;partition&gt;               # Choosing nodes (see ccc_mpinfo)</span>
<span class="c1">#MSUB -A projxxxx                  # Project ID</span>
<span class="nb">set</span> -x
<span class="nb">cd</span> <span class="si">${</span><span class="nv">BRIDGE_MSUB_PWD</span><span class="si">}</span>
<span class="nb">export</span> <span class="nv">OMP_NUM_THREADS</span><span class="o">=</span><span class="m">16</span>
 ./a.out
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">An OpenMP/multi-threaded program can only run inside a node. If you ask more threads than available cores in a node, your submission will be rejected.</p>
</div>
<ul class="simple">
<li><strong>Parallel hybrid OpenMP/MPI or multi-threaded/MPI</strong></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -r MyJob_ParaHyb             # Request name</span>
<span class="c1">#MSUB -n 8                         # Total number of tasks to use</span>
<span class="c1">#MSUB -c 4                         # Number of threads per task to use</span>
<span class="c1">#MSUB -T 1800                      # Elapsed time limit in seconds</span>
<span class="c1">#MSUB -o example_%I.o              # Standard output. %I is the job id</span>
<span class="c1">#MSUB -e example_%I.e              # Error output. %I is the job id</span>
<span class="c1">#MSUB -q &lt;partition&gt;               # Choosing nodes</span>
<span class="c1">#MSUB -A projxxxx                  # Project ID</span>
<span class="nb">set</span> -x
<span class="nb">cd</span> <span class="si">${</span><span class="nv">BRIDGE_MSUB_PWD</span><span class="si">}</span>
<span class="nb">export</span> <span class="nv">OMP_NUM_THREADS</span><span class="o">=</span><span class="m">4</span>
ccc_mprun ./a.out <span class="c1"># This script will launch 8 MPI tasks. Each task will have 4 OpenMP threads.</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>Simple one GPU job</strong></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -r GPU_Job                   # Request name</span>
<span class="c1">#MSUB -n 1                         # Total number of tasks to use</span>
<span class="c1">#MSUB -T 1800                      # Elapsed time limit in seconds</span>
<span class="c1">#MSUB -o example_%I.o              # Standard output. %I is the job id</span>
<span class="c1">#MSUB -e example_%I.e              # Error output. %I is the job id</span>
<span class="c1">#MSUB -q &lt;partition&gt;               # Choosing partition of GPU nodes</span>
<span class="c1">#MSUB -A projxxxx                  # Project ID</span>
<span class="nb">set</span> -x
<span class="nb">cd</span> <span class="si">${</span><span class="nv">BRIDGE_MSUB_PWD</span><span class="si">}</span>
module load cuda
ccc_mprun ./a.out
</pre></div>
</div>
<p>You should use to run your GPU code because manages the binding of processes (see <a class="reference internal" href="irene.html#process-distribution-affinity-and-binding"><span class="std std-ref">Process distribution, affinity and binding</span></a>).</p>
<ul class="simple">
<li><strong>Hybrid MPI/GPU job</strong>:</li>
</ul>
<p>GPU partition have several GPUs per node. For example, this script launches 8 MPI processes with one process per socket. Check the number of cores per socket with the <strong class="command">ccc_mpinfo</strong> command to know what value to specify for <code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -r MPI_GPU_Job               # Request name</span>
<span class="c1">#MSUB -n 8                         # Total number of tasks to use</span>
<span class="c1">#MSUB -c 4                         # 1 socket is reserved for 1 MPI process.</span>
<span class="c1">#MSUB -T 1800                      # Elapsed time limit in seconds</span>
<span class="c1">#MSUB -o example_%I.o              # Standard output. %I is the job id</span>
<span class="c1">#MSUB -e example_%I.e              # Error output. %I is the job id</span>
<span class="c1">#MSUB -q &lt;partition&gt;               # Choosing partition of GPU nodes</span>
<span class="c1">#MSUB -A projxxxx                  # Project ID</span>
<span class="nb">set</span> -x
<span class="nb">cd</span> <span class="si">${</span><span class="nv">BRIDGE_MSUB_PWD</span><span class="si">}</span>
ccc_mprun ./a.out
</pre></div>
</div>
</div>
</div>
<div class="section" id="job-monitoring-and-control">
<h3>Job monitoring and control<a class="headerlink" href="#job-monitoring-and-control" title="Permalink to this headline">¶</a></h3>
<p>Once a job is submitted with <strong class="command">ccc_msub</strong>, it is possible to follow its evolution with several bridge commands.</p>
<div class="section" id="ccc-mstat">
<h4>ccc_mstat<a class="headerlink" href="#ccc-mstat" title="Permalink to this headline">¶</a></h4>
<p>The <strong class="command">ccc_mstat</strong> command provides information about jobs on the supercomputer. By default, it displays all the jobs that are either running or pending on the different partitions of the supercomputer. Use the option <code class="xref std std-option docutils literal notranslate"><span class="pre">-u</span></code> to display only your jobs.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ ccc_mstat -u
BATCHID  NAME     USER     PROJECT             QUEUE      QOS     PRIO   SUBHOST  EXEHOST   STA    TUSED     TLIM    MLIM   CLIM
-------  ----     ----     -------             -----      ------  ------ -------  -------   --- -------- -------- ------- ------
229862   MyJob1   mylogin  projXXX@partition1  partition1 normal  210000 node174  node174   PEN        0    86400    1865   2240
233463   MyJob2   mylogin  projXXX@partition2  partition2 normal  210000 node175  node1331  R00    58631    85680    1865  43200
233464   MyJob3   mylogin  projXXX@partition3  partition3 normal  200000 node172  node1067  R01    12171    85680    1865  43200
233582   MyJob4   mylogin  projXXX@partition1  partition1 normal  200000 node172  node1104  R01     3620    85680    1865  43200
</pre></div>
</div>
<p>Here is the information that can be gathered from :</p>
<ul class="simple">
<li>Basic job information (USER,PROJECT,BATCHID,CLIM,QUEUE,TLIM,NAME): Describes the parameter with which the job was submitted. It allows to check that the parameters passed to <strong class="command">ccc_msub</strong> were taken into account correctly.</li>
<li>PRIO: The priority of the job depends on many parameters. For instance, it depends on your project and the amount of hours your project consumed. It also depends on how long the job has been waiting in queue. The priority is what will determine the order in which the jobs from different users and different projects will run when the resource is available.</li>
<li>SUBHOST: The host where the job was submitted.</li>
<li>EXEHOST: The first host where the job is running.</li>
<li>STA: The state of the job. Most of the time, it is either pending (PEN) if it is waiting for resources or running (R01) if it has started. Sometimes, the job is in a completing state (R00). It means the jobs has finished and computing resources are in a cleanup phase.</li>
<li>TUSED/TLIM: If the job is running, the TUSED field shows for how long it has been running in seconds. The TLIM field shows the maximum execution time requested at submission.</li>
<li>MLIM: The maximum memory allowed per core in MB.</li>
<li>CLIM: The number of core requested at submission.</li>
</ul>
<p>Here are command line options for <strong class="command">ccc_mstat</strong>:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-f</span></code>: show jobs full name.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-q</span> <span class="pre">queue</span></code>: show jobs of requested batch queue.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-u</span> <span class="pre">[user]</span></code>: show jobs of a requested user. If no user is given, it shows the job of the current user.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-b</span> <span class="pre">batchid</span></code>: show all the processes related to a job.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-r</span> <span class="pre">batchid</span></code>: show detailed information of a running job.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-H</span> <span class="pre">batchid</span></code>: show detailed information of a finished job.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-O</span></code>: show jobs exceeding the time limit.</li>
</ul>
</div>
<div class="section" id="ccc-mpp">
<h4>ccc_mpp<a class="headerlink" href="#ccc-mpp" title="Permalink to this headline">¶</a></h4>
<p><strong class="command">ccc_mpp</strong> provides information about jobs on the supercomputer. By default, it displays all the jobs that are either running or pending on the different partitions of the supercomputer. Use the option <code class="xref std std-option docutils literal notranslate"><span class="pre">-u</span> <span class="pre">$USER</span></code> to display only your jobs.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ ccc_mpp -u $USER
USER    ACCOUNT BATCHID    NCPU    QUEUE        PRIORITY  STATE   RLIM    RUN/START   SUSP   OLD     NAME    NODES/REASON
mylogin projXX  1680920    64      partition1   290281    RUN     1.0h    55.0s       -      53.0s   MyJob1  node8002
mylogin projXX  1680923    84      partition2   284040    PEN     10.0h   -           -      50.0s   MyJob3  Dependency
mylogin projXX  1661942    84      partition2   284040    RUN     24.0h   53.0s       -      51.0s   MyJob3  node[1283-1285]
mylogin projXX  1680917    1024    partition2   274036    PEN     24.0h   -           -      7.5m    MyJob4  Priority
mylogin projXX  1680921    28      partition3   215270    PEN     24.0h   ~05h36      -      52.0s   MyJob2  Resources
</pre></div>
</div>
<p>Here is the information that can be gathered from :</p>
<ul class="simple">
<li>Basic job information (USER,ACCOUNT,BATCHID,NCPU,QUEUE,RLIM,NAME): Describes the parameter with which the job was submitted. It allows to check that the parameters passed to <strong class="command">ccc_msub</strong> were taken into account correctly.</li>
<li>PRIORITY: The priority of the job depends on many parameters. For instance, it depends on your project and the amount of hours your project consumed. It also depends on how long the job has been waiting in queue. The priority is what will determine the order in which the jobs from different users and different projects will run when the resource is available.</li>
<li>STATE: The state of the job. Most of the time, it is either pending (PEN) if it is waiting for resources or running (RUN) if it has started. Sometimes, the job is in a completing state (COMP). It means the jobs has finished and computing resources are in a cleanup phase.</li>
<li>RUN/START: If the job is running, this field shows for how long it has been running. If the job is pending, it sometimes gives an evaluation of the estimated start time. This start time may vary depending on the jobs submitted by other users.</li>
<li>SUSP: The time spent in a suspended state. Jobs may be suspended by staff when an issue occur on the supercomputer. In that case, running jobs are not flushed but suspended in order to let them continue once the issue is solved.</li>
<li>OLD: The total amount of time since the job was submitted. It includes the time spent waiting and running.</li>
<li>NODES/REASON: If the job is running, this gives you the list of nodes used by the job. If it is pending, it gives you the reason. For example, “Dependency” means you submitted the job with a dependency to another unfinished job. “Priority” means there are other jobs that have a better priority and yours will start running after those. “Resources” means there are not enough cores available at the moment to let the job start. It will have to wait for some other jobs to end and free their allocated resources. “JobHeldAdmin” means that the current job has been held by a user who is not the owner (generaly an admin with the required rights). Please note that pending jobs with lower priority may display a pending reason not reflecting their current pending state since the batch scheduler only updates the pending reason of high priority jobs.</li>
</ul>
<p>Here are command line options for <strong class="command">ccc_mpp</strong>:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-r</span></code>: prints ‘running’ batch jobs</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-s</span></code>: prints ‘suspended’ batch jobs</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-p</span></code>: prints ‘pending’ batch jobs</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-q</span> <span class="pre">queue</span></code>: requested batch queue</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-u</span> <span class="pre">user</span></code>: requested user</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-g</span> <span class="pre">group</span></code>: requested group</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-n</span></code>: prints results without colors</li>
</ul>
</div>
<div class="section" id="ccc-mpeek">
<h4>ccc_mpeek<a class="headerlink" href="#ccc-mpeek" title="Permalink to this headline">¶</a></h4>
<p><strong class="command">ccc_mpeek</strong> gives information about a job while it runs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mpeek &lt;jobid&gt;
</pre></div>
</div>
<p>It is particularly useful to check the output of a job while it is running. The default behavior is to display the standard output. It is what you would basically find in the <code class="file docutils literal notranslate"><span class="pre">.o</span></code> log file.</p>
<p>Here are command line options for <strong class="command">ccc_mpeek</strong>:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-o</span></code>: prints the standard output</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-e</span></code>: prints the standard error output</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-s</span></code>: prints the job submission script</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-t</span></code>: same as <code class="xref std std-option docutils literal notranslate"><span class="pre">-o</span></code> in <strong class="command">tail -f</strong> mode</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-S</span></code>: print the launched script of the running job</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-d</span></code>: print the temporary directory of the running job</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-I</span></code>: print the INFO file of the running job</li>
</ul>
</div>
<div class="section" id="ccc-mpstat">
<h4>ccc_mpstat<a class="headerlink" href="#ccc-mpstat" title="Permalink to this headline">¶</a></h4>
<p><strong class="command">ccc_mpstat</strong> gives information about a parallel job during its execution.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mpstat &lt;jobid&gt;
</pre></div>
</div>
<p>It gives details about the MPI processes and their repartition across nodes with their rank and affinity.</p>
<p>Here are command line options for <strong class="command">ccc_mpstat</strong>:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-r</span> <span class="pre">jobid</span></code>    : display resource allocation characteristics</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-a</span> <span class="pre">jobid</span></code>    : display active steps belonging to a jobid</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-t</span> <span class="pre">stepid</span></code>   : print execution trace (tree format) for the specified stepid</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-m</span> <span class="pre">stepid</span></code>   : print mpi layout for the specified stepid</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-p</span> <span class="pre">partition</span></code>: only print jobs of a particular partition</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-u</span> <span class="pre">[user]</span></code>   : only print jobs of a particular user or the current one if not specified</li>
</ul>
</div>
<div class="section" id="ccc-macct">
<h4>ccc_macct<a class="headerlink" href="#ccc-macct" title="Permalink to this headline">¶</a></h4>
<p>Once the job is done, it will not appear in <strong class="command">ccc_mpp</strong> anymore. To display information afterwards, the command <strong class="command">ccc_macct</strong> is available. It works for pending and running jobs but information is more complete once the job has finished. It needs a valid jobID as input.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_macct &lt;jobid&gt;
</pre></div>
</div>
<p>Here is an example of the output of the <strong class="command">ccc_macct</strong> command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_macct 1679879

Jobid     : 1679879
Jobname   : MyJob
User      : login01
Account   : project01@partition
Limits    : time = 01:00:00 , memory/task = Unknown
Date      : submit = 14/05/2014 09:23:50 , start = 14/05/2014 09:23:50 , end = 14/05/2014 09:30:00
Execution : partition = partition , QoS = normal , Comment = avgpowe+
Resources : ncpus = 32 , nnodes = 2
   Nodes=node[1802,1805]

Memory / step
--------------
                   Resident Size (Mo)                     Virtual Size (Go)
JobID          Max     (Node:Task)       AveTask    Max  (Node:Task)            AveTask
-----------    ------------------------  -------    --------------------------  -------
1679879.bat+     151 (node1802   :   0)       0      0.00 (node1802   :   0)    0.00
1679879.0        147 (node1805   :   2)       0      0.00 (node1805   :   2)    0.00
1679879.1        148 (node1805   :   8)       0      0.00 (node1805   :   8)    0.00
1679879.2          0 (node1805   :  16)       0      0.00 (node1805   :  16)    0.00

Accounting / step
------------------

JobID          JobName             Ntasks  Ncpus Nnodes     Layout       Elapsed   Ratio      CPusage    Eff  State
------------   ------------        ------  ----- ------     -------      -------   -----      -------    ---  -----
1679879       MyJob                     -     32      2           -     00:06:10     100            -      -  -
1679879.bat+  batch                     1      1      1     Unknown     00:06:10   100.0            -      -  COMPLETED
1679879.0     exe0                      4      4      2      BBlock     00:03:18    53.5     00:02:49   85.3  COMPLETED
1679879.1     exe1                     16     16      2      BBlock     00:02:42    43.7     00:00:37   22.8  COMPLETED
1679879.2     exe2                     32     32      2      BBlock     00:00:03      .8            -      -  FAILED

Energy usage / job (experimental)
---------------------------------

Nnodes  MaxPower  MaxPowerNode  AvgPower     Duration      Energy
------  --------  ------------  --------     --------      ------
    2       169W  node1802         164W     00:06:10        0kWh
</pre></div>
</div>
<p>Sometimes, there are several steps for the same job described in <strong class="command">ccc_macct</strong>. Here, they are called <em>1679879.0</em>, <em>1679879.1</em> and <em>1679879.2</em>. This happens when there are several calls to <strong class="command">ccc_mprun</strong> in one submission script. In this case, 3 executables were run with <strong class="command">ccc_mprun</strong>: exe0, exe1 and exe2. Every other call to functions such as <strong class="command">cp</strong>, <strong class="command">mkdir</strong>, etc will be counted in the step called <em>1679879.batch</em></p>
<p>There are 4 specific sections in the <strong class="command">ccc_macct</strong> output.</p>
<ul class="simple">
<li>First section <em>Job summary</em>: It gives all the basic information about submission parameters you can also find in <strong class="command">ccc_mpp</strong>. There is also submission date and time, when the job has started to run and when it has finished.</li>
<li>Second section <em>Memory / step</em>: For each step, this section gives an idea of the amount of memory used by process. It gives the memory consumption of the top process.</li>
<li>Third section <em>Accounting / step</em>: It gives detailed information for each step.<ul>
<li><strong>Ntasks, Ncpus, Nnodes and Layout</strong> describes how the job is distributed among the allocated resources. <em>Ntasks</em> is the number of processes defined by the parameter <code class="xref std std-option docutils literal notranslate"><span class="pre">-n</span></code>. By default, Ncpus is the same as Ntasks except if the number of cores per process was set with the <code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span></code> parameter. The layout can be BBlock, CBlock, BCyclic or CCyclic depending on the process distribution. (more information given in the Advanced Usage documentation)</li>
<li><strong>Elapsed</strong> is the user time spent in each step. <strong>Ratio</strong> is the percentage of time spent in this specific step compared to the total time of the job.</li>
<li><strong>CPusage</strong> is the average cpu time for all the processes in one step and <strong>Eff</strong> is defined by <em>CPusage/Elapsed*100</em>. Which means that if Eff is close to 1, all the processes are equally busy.</li>
</ul>
</li>
<li>Fourth section <em>Energy usage</em>: It gives an idea of the amount of electric energy used while running this job. This section is only relevant if the job used entire nodes.</li>
</ul>
</div>
<div class="section" id="ccc-mdel">
<h4>ccc_mdel<a class="headerlink" href="#ccc-mdel" title="Permalink to this headline">¶</a></h4>
<p><strong class="command">ccc_mdel</strong> enables to kill your jobs. It works whether they are running or pending.</p>
<p>First, identify the batchid of the job you need to kill with <strong class="command">ccc_mpp</strong> for example. And then, kill the job with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mdel &lt;jobid&gt;
</pre></div>
</div>
</div>
<div class="section" id="ccc-malter">
<h4>ccc_malter<a class="headerlink" href="#ccc-malter" title="Permalink to this headline">¶</a></h4>
<p><strong class="command">ccc_malter</strong> enables to decrease your jobs time limit. It works only when they are running or pending.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_malter -T &lt;new time limit&gt; &lt;jobid&gt;
</pre></div>
</div>
<p>Here are available options:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-T</span> <span class="pre">time_limit</span></code>: Decrease the time limit of a job</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-L</span> <span class="pre">licenses_string</span></code>: Change licenses of your job</li>
</ul>
</div>
<div class="section" id="ccc-affinity">
<h4>ccc_affinity<a class="headerlink" href="#ccc-affinity" title="Permalink to this headline">¶</a></h4>
<p>The command <strong class="command">ccc_affinity</strong> show you the processes and threads affinity for a given job id. The usual format is <strong class="command">ccc_affinity [options] JOBID</strong>.</p>
<p>Here are available options:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-l</span></code>: Run on local node.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-t</span></code>: Display processes and threads. Default is to display processes only.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-u</span></code>: Specify a username.</li>
</ul>
<p>This is an example of output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_affinity 900481
Host             Rank  PID        %CPU  State MEM_kB     CPU   AFFINITY             NAME
node1434:
 |               2     8117       310   Sl    34656      28    0,28                 life_par_step7
 |               3     8118       323   Rl    34576      42    14,42                life_par_step7
node1038:
 |               0     6518       323   Rl    34636      0     0,28                 life_par_step7
 |               1     6519       350   Rl    34732      42    14,42                life_par_step7
</pre></div>
</div>
<p>And this is with thread option <code class="xref std std-option docutils literal notranslate"><span class="pre">-t</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_affinity -t 900481
Host             Rank  PID        %CPU   State ThreadID   MEM_kB     CPU   AFFINITY             NAME
node1434:
 |               2     8117       20.3   Sl    8117       34660      28    0,28                 life_par_step7
 |               `--   --         0.0    Sl    8125       34660      29    0-13,28-41           life_par_step7
 |               `--   --         0.0    Sl    8126       34660      0     0-13,28-41           life_par_step7
 |               `--   --         0.0    Sl    8142       34660      29    0-13,28-41           life_par_step7
 |               `--   --         0.0    Sl    8149       34660      36    0-13,28-41           life_par_step7
 |               `--   --         99.6   Rl    8150       34660      4     4,32                 life_par_step7
 |               `--   --         99.6   Rl    8151       34660      7     7,35                 life_par_step7
 |               `--   --         99.6   Rl    8152       34660      11    11,39                life_par_step7
 |               3     8118       33.6   Rl    8118       34580      42    14,42                life_par_step7
 |               `--   --         0.0    Sl    8124       34580      43    14-27,42-55          life_par_step7
 |               `--   --         0.0    Sl    8127       34580      18    14-27,42-55          life_par_step7
 |               `--   --         0.0    Sl    8143       34580      50    14-27,42-55          life_par_step7
 |               `--   --         0.0    Sl    8145       34580      23    14-27,42-55          life_par_step7
 |               `--   --         99.6   Rl    8146       34580      18    18,46                life_par_step7
 |               `--   --         99.6   Rl    8147       34580      21    21,49                life_par_step7
 |               `--   --         99.6   Rl    8148       34580      25    25,53                life_par_step7
node1038:
 |               0     6518       44.1   Rl    6518       34636      28    0,28                 life_par_step7
 |               `--   --         0.0    Sl    6526       34636      29    0-13,28-41           life_par_step7
 |               `--   --         0.0    Sl    6531       34636      11    0-13,28-41           life_par_step7
 |               `--   --         0.0    Sl    6549       34636      36    0-13,28-41           life_par_step7
 |               `--   --         0.0    Sl    6553       34636      10    0-13,28-41           life_par_step7
 |               `--   --         99.8   Rl    6554       34636      4     4,32                 life_par_step7
 |               `--   --         99.8   Rl    6555       34636      7     7,35                 life_par_step7
 |               `--   --         99.8   Rl    6556       34636      11    11,39                life_par_step7
 |               1     6519       71.1   Sl    6519       34736      42    14,42                life_par_step7
 |               `--   --         0.0    Sl    6525       34736      43    14-27,42-55          life_par_step7
 |               `--   --         0.0    Sl    6527       34736      17    14-27,42-55          life_par_step7
 |               `--   --         0.0    Sl    6548       34736      43    14-27,42-55          life_par_step7
 |               `--   --         0.0    Sl    6557       34736      50    14-27,42-55          life_par_step7
 |               `--   --         99.6   Rl    6558       34736      18    18,46                life_par_step7
 |               `--   --         99.6   Rl    6559       34736      21    21,49                life_par_step7
 |               `--   --         99.6   Rl    6560       34736      25    25,53                life_par_step7
</pre></div>
</div>
<p>We can see which process runs on which node and which thread runs on which core/CPU. The “State” column show if the thread is Running (R) or sleeping (S). The AFFINITY column shows CPUs on which a thread is allowed to move on and the CPU column shows the CPU on which a thread is currently running.</p>
<p>On a single node we can see CPU numbered to 55 though a node is 28 cores. It’s because of Intel Hyper-Threading that allows to run two threads on one core.</p>
</div>
<div class="section" id="ccc-mpp-curs">
<h4>ccc_mpp_curs<a class="headerlink" href="#ccc-mpp-curs" title="Permalink to this headline">¶</a></h4>
<div class="section" id="execution">
<h5>Execution<a class="headerlink" href="#execution" title="Permalink to this headline">¶</a></h5>
<p>The interactive version (interface curse) of <strong class="command">ccc_mpp</strong> is available with the appropriate command: <strong class="command">ccc_mpp_curs</strong></p>
</div>
<div class="section" id="performance">
<h5>Performance<a class="headerlink" href="#performance" title="Permalink to this headline">¶</a></h5>
<p>The interface updates the screen every 30 seconds.</p>
<div class="section" id="principal-widget">
<h6>Principal widget<a class="headerlink" href="#principal-widget" title="Permalink to this headline">¶</a></h6>
<p>One in the navigation mode ( key &lt;up&gt; and &lt;down&gt;), the automatic refresh is disable</p>
<p>The key &lt;enter&gt; allows enter in the detailed consultation mode/ edit the properties of a job</p>
<p>The key &lt;f&gt; allow to filter the jobs to visualize:</p>
<ul class="simple">
<li>only the user’s job</li>
<li>only the job of the user’s group</li>
<li>by search pattern (without regular expression) applicable on all displayed fields</li>
</ul>
<p>The filtering should be canceled using the keys &lt;f&gt; then &lt;a&gt;</p>
<p>The key &lt;d&gt; allows to delete a job.</p>
<p>The key &lt;q&gt; allows to quit the interface.</p>
</div>
<div class="section" id="widget-of-the-properties-of-the-job">
<h6>Widget of the properties of the job<a class="headerlink" href="#widget-of-the-properties-of-the-job" title="Permalink to this headline">¶</a></h6>
<p>The navigation is also done with the keys &lt;up&gt; and &lt;down&gt;.</p>
<p>The key &lt;enter&gt; enables to edit a property.</p>
<p>Once all the modifications are done on a job the can be submitted using the key &lt;w&gt;.</p>
<p>The key &lt;q&gt; enables to exit the mode and to cancel the modifications to be submitted.</p>
</div>
</div>
<div class="section" id="edition-mode">
<h5>Edition mode<a class="headerlink" href="#edition-mode" title="Permalink to this headline">¶</a></h5>
<div class="section" id="global-constraints">
<h6>global constraints<a class="headerlink" href="#global-constraints" title="Permalink to this headline">¶</a></h6>
<p>Only the jobs in mode “pending” are editable by their owner.</p>
</div>
<div class="section" id="achievable-actions-on-jobs">
<h6>Achievable actions on jobs<a class="headerlink" href="#achievable-actions-on-jobs" title="Permalink to this headline">¶</a></h6>
<p>As an owner of a job, one can do the following actions:</p>
<ul class="simple">
<li>delete a job</li>
<li>Modification of the following properties<ul>
<li>account: the account on which the job is charged</li>
<li>fileSystem: change the file system required by the job</li>
<li>jobname: the name of the job</li>
<li>LicensesApp: the license required by the job (format Slurm)</li>
<li>NumCpus: the number of required CPU</li>
<li>partition: the partition</li>
<li>QOS: change the Quality of Service</li>
<li>TimeLimit: the duration of the job</li>
<li>usage limit: the treashold of the job</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="role-of-the-coordinator">
<h5>Role of the coordinator<a class="headerlink" href="#role-of-the-coordinator" title="Permalink to this headline">¶</a></h5>
<p>The person in charge of imputation may request to be referenced as coordinator to the TGCC hotline.</p>
<p>The user with the role of coordinator has additional rights to interact with all imputation jobs.</p>
</div>
<div class="section" id="rapport">
<h5>Rapport<a class="headerlink" href="#rapport" title="Permalink to this headline">¶</a></h5>
<p>Every hour (at the 30th minute), a summary of the actions is sent to the owners of the jobs that had modified properties.</p>
</div>
</div>
</div>
<div class="section" id="special-jobs">
<h3>Special jobs<a class="headerlink" href="#special-jobs" title="Permalink to this headline">¶</a></h3>
<div class="section" id="embarrassingly-parallel-jobs">
<h4>Embarrassingly parallel jobs<a class="headerlink" href="#embarrassingly-parallel-jobs" title="Permalink to this headline">¶</a></h4>
<p>An embarrassingly parallel job is a job which launches independent processes in parallel. These processes need few or no communications. We call such an independent process a task.</p>
<p>There are two solutions we recommend for such jobs:</p>
<ul class="simple">
<li>use several <strong class="command">ccc_mprun</strong> calls simultaneously in the same job</li>
<li>use a tool called GLoST</li>
</ul>
<div class="section" id="multiple-ccc-mprun">
<h5>Multiple ccc_mprun<a class="headerlink" href="#multiple-ccc-mprun" title="Permalink to this headline">¶</a></h5>
<p>It is possible to call <strong class="command">ccc_mprun</strong> several times in a single job. It will create one job step per call. By default, the <strong class="command">ccc_mprun</strong> call is blocking so the next job step will only start once the first one is done. Adding the <strong>&amp;</strong> character at the end of the <strong class="command">ccc_mprun</strong> calls will make them non-blocking by running them in the background and thus allow them to run simultaneously. To make sure that they are not using the same resources, it is necessary to add the <code class="xref std std-option docutils literal notranslate"><span class="pre">--exclusive</span></code> option. Also, at the end of the script, the <strong>wait</strong> command will prevent the job from being killed before the <strong class="command">ccc_mprun</strong> calls are completed.</p>
<p>Here is an example script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -r MyJob_Para                # Request name</span>
<span class="c1">#MSUB -n 16                        # Number of tasks to use</span>
<span class="c1">#MSUB -T 3600                      # Elapsed time limit in seconds</span>
<span class="c1">#MSUB -o example_%I.o              # Standard output. %I is the job id</span>
<span class="c1">#MSUB -e example_%I.e              # Error output. %I is the job id</span>
<span class="c1">#MSUB -q &lt;partition&gt;               # Queue</span>

<span class="nb">set</span> <span class="o">-</span><span class="n">x</span>

<span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">E</span> <span class="s1">&#39;--exclusive&#39;</span> <span class="o">-</span><span class="n">n</span> <span class="mi">2</span> <span class="o">./</span><span class="n">bin1</span>  <span class="o">&amp;</span>
<span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">E</span> <span class="s1">&#39;--exclusive&#39;</span> <span class="o">-</span><span class="n">n</span> <span class="mi">1</span> <span class="o">./</span><span class="n">bin2</span>  <span class="o">&amp;</span>
<span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">E</span> <span class="s1">&#39;--exclusive&#39;</span> <span class="o">-</span><span class="n">n</span> <span class="mi">3</span> <span class="o">./</span><span class="n">bin3</span>  <span class="o">&amp;</span>
<span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">E</span> <span class="s1">&#39;--exclusive&#39;</span> <span class="o">-</span><span class="n">n</span> <span class="mi">1</span> <span class="o">./</span><span class="n">bin4</span>  <span class="o">&amp;</span>
<span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">E</span> <span class="s1">&#39;--exclusive&#39;</span> <span class="o">-</span><span class="n">n</span> <span class="mi">4</span> <span class="o">./</span><span class="n">bin5</span>  <span class="o">&amp;</span>
<span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">E</span> <span class="s1">&#39;--exclusive&#39;</span> <span class="o">-</span><span class="n">n</span> <span class="mi">8</span> <span class="o">./</span><span class="n">bin6</span>  <span class="o">&amp;</span>
<span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">E</span> <span class="s1">&#39;--exclusive&#39;</span> <span class="o">-</span><span class="n">n</span> <span class="mi">4</span> <span class="o">./</span><span class="n">bin7</span>  <span class="o">&amp;</span>

<span class="n">wait</span>  <span class="c1"># wait for all ccc_mprun(s) to complete.</span>
</pre></div>
</div>
<p>The total number of processes requested by all the <strong class="command">ccc_mprun</strong> calls may be larger than the total number of core allocated. In that case, the batch scheduler rightly handles them by a waiting/resume system. This will be noticeable in the output by the following messages:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">srun</span><span class="p">:</span> <span class="n">Job</span> <span class="n">step</span> <span class="n">creation</span> <span class="n">temporarily</span> <span class="n">disabled</span><span class="p">,</span> <span class="n">retrying</span>
<span class="n">srun</span><span class="p">:</span> <span class="n">Job</span> <span class="n">step</span> <span class="n">creation</span> <span class="n">temporarily</span> <span class="n">disabled</span><span class="p">,</span> <span class="n">retrying</span>
<span class="n">srun</span><span class="p">:</span> <span class="n">Job</span> <span class="n">step</span> <span class="n">created</span>
<span class="n">srun</span><span class="p">:</span> <span class="n">Job</span> <span class="n">step</span> <span class="n">created</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">We ask users not to create too many job steps in one job and to limit the submission of jobs with several job steps. More than 100 job steps may cause performance issue for all users and your right to submit a job may be temporarily revoked if you do so.</p>
</div>
</div>
<div class="section" id="glost-greedy-launcher-of-small-tasks">
<h5>GLoST: Greedy Launcher of Small Tasks<a class="headerlink" href="#glost-greedy-launcher-of-small-tasks" title="Permalink to this headline">¶</a></h5>
<p>GLoST is a lightweight, highly scalable tool for launching independent non-MPI processes in parallel. It has been developed by the TGCC for handling huge to-do list like operations. The source code is available on the <a class="reference external" href="https://github.com/cea-hpc/glost">cea-hpc github</a>. GLoST manages the launch and scheduling of a list of tasks with the command <strong class="command">glost_launch</strong>. It also allows error detection, continuation of undone operations and relaunch of failed operations thanks to the post processing script <code class="file docutils literal notranslate"><span class="pre">glost_filter.sh</span></code>.</p>
<p>The different tasks to launch must be listed in a simple text file. Commented and blank lines and supported. Comments added at the end of a line will be printed to the job output. This can be used to tag different tasks. Here is an example of a task file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cat taskfile.list
./bin1 # Tag for task 1
./bin2 # Tag for task 2
./bin3 # Tag for task 3
./bin4 # Tag for task 4
./bin5 # Tag for task 5
./bin6 # Tag for task 6
./bin7 # Tag for task 7
./bin8 # Tag for task 8
./bin9 # Tag for task 9
./bin10 # Tag for task 10
</pre></div>
</div>
<p>Or with MPI binaries:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cat task_mpi.list
ccc_mprun -E&quot;--jobid=${SLURM_JOBID}&quot; -E&quot;--exclusive&quot; -n 3 ./mpi_init
ccc_mprun -E&quot;--jobid=${SLURM_JOBID}&quot; -E&quot;--exclusive&quot; -n 5 ./mpi_init
</pre></div>
</div>
<p>Here is an example of submission script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -r MyJob_Para                # Request name</span>
<span class="c1">#MSUB -n 4                         # Number of tasks to use</span>
<span class="c1">#MSUB -T 3600                      # Elapsed time limit in seconds</span>
<span class="c1">#MSUB -o example_%I.o              # Standard output. %I is the job id</span>
<span class="c1">#MSUB -e example_%I.e              # Error output. %I is the job id</span>
<span class="c1">#MSUB -q &lt;partition&gt;               # Queue</span>

<span class="n">module</span> <span class="n">load</span> <span class="n">glost</span>
<span class="n">ccc_mprun</span> <span class="n">glost_launch</span> <span class="n">taskfile</span><span class="o">.</span><span class="n">list</span>
</pre></div>
</div>
<p>GLoST will automatically manage the different tasks and schedule them on the different available nodes. Note that one MPI process is reserved for task management so GLoST cannot run on 1 process. For more information, please check out the man page for <strong class="command">glost_launch</strong>.</p>
<p>Once the job is submitted, information on the task scheduling is provided in the error output of the job. For each task, it shows which process launched it, its exit status and its duration. Here is a typical output for a 4 process job. Process 0 is used for scheduling and the 10 tasks to launch are treated by processes 1,2 or 3.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#executed by process    3 in 7.01134s     with status     0 : ./bin3 # Tag for task 3</span>
<span class="c1">#executed by process    1 in 8.01076s     with status     0 : ./bin2 # Tag for task 2</span>
<span class="c1">#executed by process    2 in 9.01171s     with status     0 : ./bin1 # Tag for task 1</span>
<span class="c1">#executed by process    2 in 0.00851917s  with status     12 : ./bin6 # Tag for task 6</span>
<span class="c1">#executed by process    2 in 3.00956s     with status     0 : ./bin7 # Tag for task 7</span>
<span class="c1">#executed by process    1 in 5.01s        with status     0 : ./bin5 # Tag for task 5</span>
<span class="c1">#executed by process    3 in 6.01114s     with status     0 : ./bin4 # Tag for task 4</span>
</pre></div>
</div>
<p>Some tasks may exit on errors or not be executed if the job has reached its timelimit before launching all the tasks in the taskfile. To help analysing the executed, failed or not executed tasks, we provide the script <code class="file docutils literal notranslate"><span class="pre">glost_filter.sh</span></code>. By default, lists all the executed tasks and adding the option <code class="xref std std-option docutils literal notranslate"><span class="pre">-H</span></code> will highlight the failed tasks. Let’s say the error output file is called <code class="file docutils literal notranslate"><span class="pre">example_1050311.e</span></code>. Here are some useful options:</p>
<ul class="simple">
<li>List all failed tasks (with exit status other than 0)</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ glost_filter.sh -n taskfile example_1050311.e
./bin6 # Tag for task 6
</pre></div>
</div>
<ul class="simple">
<li>List all tasks not executed (may be used to generate the next taskfile)</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ glost_filter.sh -R taskfile example_1050311.e
./bin8 # Tag for task 8
./bin9 # Tag for task 9
./bin10 # Tag for task 10
</pre></div>
</div>
<p>For more information and options, please check out <strong class="command">glost_filter.sh -h</strong>.</p>
<p>GLoST also provides the tool <strong class="command">glost_bcast.sh</strong> which broadcasts a file from a shared filesystem to the local temporary directory (<code class="file docutils literal notranslate"><span class="pre">/tmp</span></code> by default). Typical usage on the center is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -r MyJob_Para                # Request name
#MSUB -n 32                        # Number of tasks to use
#MSUB -T 3600                      # Elapsed time limit in seconds
#MSUB -o example_%I.o              # Standard output. %I is the job id
#MSUB -e example_%I.e              # Error output. %I is the job id
#MSUB -q &lt;partition&gt;               # Queue

module load glost

# Broadcast &lt;file&gt; on each node under /tmp/&lt;file&gt;
ccc_mprun -n ${BRIDGE_MSUB_NNODE} -N ${BRIDGE_MSUB_NNODE} glost_bcast &lt;file&gt;

# Alternatively, to broadcast &lt;file&gt; on each node under /dev/shm/&lt;file&gt;
TMPDIR=/dev/shm ccc_mprun -n ${BRIDGE_MSUB_NNODE} -N ${BRIDGE_MSUB_NNODE} glost_bcast &lt;file&gt;
</pre></div>
</div>
</div>
</div>
<div class="section" id="mpmd-jobs">
<h4>MPMD jobs<a class="headerlink" href="#mpmd-jobs" title="Permalink to this headline">¶</a></h4>
<p>An MPMD job (for Multi Program Multi Data) is a parallel job that launches different executables over the processes. The different codes are still sharing the same MPI environment. This can be done with the <code class="xref std std-option docutils literal notranslate"><span class="pre">-f</span></code> option of <strong class="command">ccc_mprun</strong> and by creating an appfile. The appfile should specify the different executables to launch and the number of processes for each.</p>
<div class="section" id="homogeneous">
<h5>Homogeneous<a class="headerlink" href="#homogeneous" title="Permalink to this headline">¶</a></h5>
<p>An homogeneous MPMD job is a parallel job where each process have the same cores number. Here is an example of an appfile:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cat app.conf
1       ./bin1
5       ./bin2
26      ./bin3

# This script will launch the 3 executables
# respectively on 1, 5 and 26 cores
</pre></div>
</div>
<p>And the submission script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -r MyJob_Para                # Request name
#MSUB -n 32                        # Total number of tasks to use
#MSUB -T 1800                      # Elapsed time limit in seconds
#MSUB -o example_%I.o              # Standard output. %I is the job id
#MSUB -e example_%I.e              # Error output. %I is the job id
#MSUB -q &lt;partition&gt;               # Choosing nodes
#MSUB -A paxxxx                    # Project ID
set -x
cd ${BRIDGE_MSUB_PWD}

ccc_mprun -f app.conf
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The total number of processes specified on the appfile cannot be larger than the number of cores allocated for the job.</p>
</div>
<p>In order to have several calls per line in the appfile, it is necessary to execute the whole line in the <strong class="command">bash</strong> command.</p>
<ul class="simple">
<li>For example, if each binary has to be executed in its own directory</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span> <span class="n">bash</span> <span class="o">-</span><span class="n">c</span> <span class="s2">&quot;cd ./dir-1 &amp;&amp; ./bin1&quot;</span>
<span class="mi">4</span> <span class="n">bash</span> <span class="o">-</span><span class="n">c</span> <span class="s2">&quot;cd ./dir-2 &amp;&amp; ./bin2&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li>Or if you need to export an environment variable that is different for each binary.</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span> <span class="n">bash</span> <span class="o">-</span><span class="n">c</span> <span class="s2">&quot;export OMP_NUM_THREADS=3; ./bin1;&quot;</span>
<span class="mi">4</span> <span class="n">bash</span> <span class="o">-</span><span class="n">c</span> <span class="s2">&quot;export OMP_NUM_THREADS=1; ./bin2;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="heterogeneous">
<h5>Heterogeneous<a class="headerlink" href="#heterogeneous" title="Permalink to this headline">¶</a></h5>
<p>An heterogeneous MPMD job is a parallel job where each process could have a different threads number. Heterogeneous MPMD is enabled by loading <strong>feature/bridge/heterogenous_mpmd</strong> module. Here is an example of an appfile:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cat app.conf
1-2 bash -c &quot;export OMP_NUM_THREADS=2; ./bin1&quot;
5-4 bash -c &quot;export OMP_NUM_THREADS=4; ./bin2&quot;
2-5 bash -c &quot;export OMP_NUM_THREADS=5; ./bin3&quot;

# This script will launch the 3 executables
# respectively on 1, 5 and 2 processes with 2, 4 and 5 cores
# 1*2 + 5*4 + 2*5 = 32 (#MSUB -n 32)
</pre></div>
</div>
<p>The first number describes how many processes to run the followed command while the second one indicates the number of cores allocated to each process.</p>
<p>And the submission script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -r MyJob_Para                # Request name
#MSUB -n 32                        # Total number of tasks and cores to use
#MSUB -T 1800                      # Elapsed time limit in seconds
#MSUB -o example_%I.o              # Standard output. %I is the job id
#MSUB -e example_%I.e              # Error output. %I is the job id
#MSUB -q &lt;partition&gt;               # Choosing nodes
#MSUB -A paxxxx                    # Project ID
set -x
cd ${BRIDGE_MSUB_PWD}
module load feature/bridge/heterogenous_mpmd

ccc_mprun -f app.conf
</pre></div>
</div>
</div>
</div>
</div>
</div>
<span id="document-toc/fulldoc/Project_accounting"></span><div class="section" id="project-accounting">
<span id="id1"></span><h2>Project accounting<a class="headerlink" href="#project-accounting" title="Permalink to this headline">¶</a></h2>
<p>A project or partner account will be granted a certain amount of computing hours or a computing share. Those hours are spent by running jobs on the available partitions. There are some processes and tools that help to regulate the accounting of project consumption.</p>
<div class="section" id="computing-hours-consumption-control-process">
<h3>Computing hours consumption control process<a class="headerlink" href="#computing-hours-consumption-control-process" title="Permalink to this headline">¶</a></h3>
<p>To guarantee a smooth and fair use of the computing resources available on Irene, projects must use their awarded core hours on a regular basis without being late.</p>
<p>To encourage users to respect this rule, projects consumption is automatically and periodically checked. In case of under-consumption, the number of core hours awarded gets reduced. On the other hand, this mechanism doesn’t prevent over-consumption.</p>
<p>The process respects the following rules:</p>
<ul class="simple">
<li>The 15th of each month, the current accounting of each project is compared with the theoretical one (awarded hours / total number of days in project * elapsed number of days).</li>
<li>Between 30 days and 59 days of lateness, an e-mail warns the project leader.</li>
<li>If a project has more than 60 days of lateness, a 30-days amount of core hours is deducted from the global awarded core hours.</li>
</ul>
<p>Note that:</p>
<ul class="simple">
<li>This process concerns PRACE Regular Access projects.</li>
<li>At any time, users can check their project accounting with the <strong class="command">ccc_myproject</strong> command.</li>
<li>No hour will be subtracted without a warning e-mail being sent a month beforehand.</li>
<li>Derogation requests must be sent to the TGCC Hotline.</li>
</ul>
<p>In case of over-consumption, jobs still can be run. They will run only if there is no job from a nominal-consuming or from an under-consuming project in queue waiting for computing resources. A running job from an over-consuming project is called a “bonus job”. This mechanism is automatically managed by the scheduler and no option is necessary to use it. For DARI projects, the project is closed when the consumed hours reach 125% of the granted hours amount and can therefore consume more than the initially granted hours amount if it has benefited of bonus jobs.</p>
</div>
<div class="section" id="ccc-myproject">
<h3>ccc_myproject<a class="headerlink" href="#ccc-myproject" title="Permalink to this headline">¶</a></h3>
<p>It is very important to consume the project awarded hours or your computing share on a regular basis. Therefore, you should check the project consumption. The command <strong class="command">ccc_myproject</strong> gives information about the accounting of your project(s)</p>
<div class="section" id="for-prace-and-genci-projects">
<h4>For PRACE and GENCI projects<a class="headerlink" href="#for-prace-and-genci-projects" title="Permalink to this headline">¶</a></h4>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_myproject

Accounting for project XXXXXXX on |Machine| at 2014-04-13
Login                             Time in hours
login01     ...........................75382.44
login02     ..............................20.02

Total       ...........................75402.46
Allocated   .........................2000000.00

Suggested use at this time...............12.25%
Real use at this time     ................3.75%

Project deadline 201X-0X-0X
</pre></div>
</div>
<p>You will find:</p>
<ul class="simple">
<li>The consumed compute time in hours for each member of the project</li>
<li>The total consumed compute time of the project</li>
<li>The total amount of hours allocated for this project</li>
<li>The project’s deadline</li>
</ul>
<p>The suggested use gives the percentage of hours you should ideally have used at this point depending on your total amount of allocated hours and your project deadline. Your real use should be as close as possible to the suggested value.</p>
<p>If you are part of several projects, information will be displayed for each project you are member of.</p>
<p>Accounting information are updated once a day.</p>
</div>
<div class="section" id="for-ccrt-partners">
<h4>For CCRT partners<a class="headerlink" href="#for-ccrt-partners" title="Permalink to this headline">¶</a></h4>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_myproject

Accounting for partner XXXXXXX on partition1 at 2012-11-07
Login       Imputation     Hours (1 month)     Hours (3 months)      Hours (1 year)

login01     *****     ................0.00...............19.10...............19.10
login02     *****     ..............609.33.............1187.34.............1187.34
login03     *****     ..............472.89..............472.89..............472.89

Total used            ............38397.85............59700.49............59700.49
Total suggested used  ...........226271.24...........671514.63..........2671460.39
</pre></div>
</div>
<p>This information is given in the following periods: 30 days rolling, 3 months rolling, 1 year rolling.</p>
<p>The suggested use gives the amount of hours you should ideally have used at this point depending on your total amount corresponding to your computing share. Your real use should be as close as possible to the suggested value.</p>
<p>Accounting information are updated once a day.</p>
</div>
<div class="section" id="for-france-genomique-projects">
<h4>For France Genomique projects<a class="headerlink" href="#for-france-genomique-projects" title="Permalink to this headline">¶</a></h4>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_myproject

Accounting for project fgXXXX on Airain fat/large at 2015-11-06
Login                             Time in hours
login01     ...........................75382.44
login02     ..............................20.02

Total       ...........................75402.46
Allocated   .........................2000000.00

Suggested use at this time...............12.25%
Real use at this time     ................3.75%

Project deadline 201X-0X-0X
</pre></div>
</div>
<p>You will find:</p>
<ul class="simple">
<li>The consumed compute time in hours for each member of the project</li>
<li>The total consumed compute time of the project</li>
<li>The total amount of hours allocated for this project</li>
<li>The project’s deadline</li>
</ul>
<p>The suggested use gives the percentage of hours you should ideally have used at this point depending on your total amount of allocated hours and your project deadline. Your real use should be as close as possible to the suggested value.</p>
<p>If you are part of several projects, information will be displayed for each project you are member of.</p>
<p>Accounting information are updated once a day.</p>
</div>
</div>
<div class="section" id="ccc-compuse">
<h3>ccc_compuse<a class="headerlink" href="#ccc-compuse" title="Permalink to this headline">¶</a></h3>
<p>The command <strong class="command">ccc_compuse</strong> indicates how the batch scheduler prioritize of your next job(s) according to your project(s) and its associated partition.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_compuse
Account Status
genxxxx@partitionxxx regular consumption
genxxxx@partitionxxx under-consumption
</pre></div>
</div>
<p>It as the following 3 states:</p>
<ul class="simple">
<li>Under-consumption: you will get a higher priority</li>
<li>Regular consumption: you will get a regular priority</li>
<li>Over-consumption: your will get a decrease priority</li>
</ul>
<p>All your project usage is taken into account but with digressive weighting factors from 1 to 0. For your information a job which ran 14 days ago gets a 0.5 weighting factor.</p>
<p>Moreover the over-consumption is not directly computed from a ratio between the attributed hours and the consumed hours. In fact, it is computed with a comparison between, on one side the percentage of the consumed hours of your project to the whole available hours of the partition, and on the other side the percentage of the attributed hours of your project on the partition. Usually the 2 methods are closely equivalent, but in special cases such as during a Grand Challenge where there are only several projects and more unavailability, their results may differ significantly.</p>
</div>
</div>
<span id="document-toc/fulldoc/Compiling"></span><div class="section" id="compilation">
<span id="compiling"></span><h2>Compilation<a class="headerlink" href="#compilation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="language-standard">
<h3>Language standard<a class="headerlink" href="#language-standard" title="Permalink to this headline">¶</a></h3>
<p>The most of IT languages are ruled by some entities called norme or standard. Those entities define explicitly the purpose of a language, how to use it, and how users should use it. For example the C language have several standards:</p>
<ul class="simple">
<li>K&amp;R C</li>
<li>ANSI C (C89) – ISO C (C90)</li>
<li>C99</li>
<li>C11</li>
<li>C embedded</li>
</ul>
<p>Each standard comes with changes and new features, and most of it are just a revision of the current standard. Nowadays the Intel Suite compilers covers the last release of the different standards existing for the C, C++ and Fortran languages. Since the covers of a standard is compiler dependent, users should be aware of the different features implemented by looking at the official website.</p>
</div>
<div class="section" id="available-compilers">
<h3>Available compilers<a class="headerlink" href="#available-compilers" title="Permalink to this headline">¶</a></h3>
<p>Several well-known compilers are available for the C, C++ and Fortran languages. The most common being:</p>
<ul class="simple">
<li>Intel Compiler suite (<strong class="command">icc</strong>, <strong class="command">icpc</strong>, <strong class="command">ifort</strong>)</li>
<li>GNU compiler suite (<strong class="command">gcc</strong>, <strong class="command">g++</strong>, <strong class="command">gfortran</strong>)</li>
</ul>
<p>To get a complete list of available compilers and versions use the <strong class="command">search</strong> parameter of <strong class="command">module</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module search compiler
</pre></div>
</div>
<p>We recommend to use the Intel Compiler Suite for better performances.</p>
<p>Here is how you would basically compile a serial code</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ icc [options] -o serial_prog.exe serial_prog.c
$ icpc [options] -o serial_prog.exe serial_prog.cpp
$ ifort [options] -o serial_prog.exe serial_prog.f90
</pre></div>
</div>
<div class="section" id="intel">
<h4>Intel<a class="headerlink" href="#intel" title="Permalink to this headline">¶</a></h4>
<div class="section" id="compiler-flags">
<h5>Compiler flags<a class="headerlink" href="#compiler-flags" title="Permalink to this headline">¶</a></h5>
<p>The following sections are an overview of the most frequent options for each compiler.</p>
<div class="section" id="c-c">
<h6>C/C++<a class="headerlink" href="#c-c" title="Permalink to this headline">¶</a></h6>
<p>The Intel compilers <strong class="command">icc</strong> and <strong class="command">icpc</strong> use mostly the same options. Their behaviors differ slightly: <strong class="command">icpc</strong> assumes that all source files are C++, whereas <strong class="command">icc</strong> distinguishes between .c and .cpp filenames.</p>
<p>Basic flags:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-o</span> <span class="pre">exe_file</span></code>: <code class="xref std std-option docutils literal notranslate"><span class="pre">names</span></code> the executable <code class="file docutils literal notranslate"><span class="pre">exe_file</span></code></li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span></code>: generates the corresponding object file, without creating an executable.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-g</span></code>: compiles with the debug symbols.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-I</span> <span class="pre">dir_name</span></code>: specifies the path of the include files.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-L</span> <span class="pre">dir_name</span></code>: specifies the path of the libraries.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-l</span> <span class="pre">bib</span></code>: asks to link the <code class="file docutils literal notranslate"><span class="pre">libbib.a</span></code> library</li>
</ul>
<p>Preprocessor:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-E</span></code>: preprocess the files and sends the result to the standard output</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-P</span></code>: preprocess the files and sends the result in <code class="file docutils literal notranslate"><span class="pre">file.i</span></code></li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-Dname=</span></code>: defines the <span class="target" id="index-0"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">name</span></code> variable</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-M</span></code>: creates a list of dependencies</li>
</ul>
<p>Practical:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-p</span></code>: profiling with gprof (needed at compilation time)</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-mp</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-mp1</span></code>: IEEE arithmetic, mp1 is a compromise between time and accuracy</li>
</ul>
<p>To tell the compiler to conform to a specific language standard :</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-std=val</span></code>: where <strong>val</strong> can take the following values (cf. <strong class="command">man icc</strong> or <strong class="command">man icpc</strong>)<ul>
<li>c++14 : Enables support for the 2014 ISO C++ standard features.</li>
<li>c++11 : Enables support for many C++11 (formerly known as C++0x) features.</li>
<li>C99 : Conforms to The ISO/IEC 9899:1999 International Standard for the C language.</li>
<li>…</li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If the desired standard is not fully supported by the current version of the Intel compiler (some features of the standard are not yet implemented), it might be supported by the last version of the GNU compilers. Since the Intel suit compilers are compiled against the gcc system (the one from the OS), load a recent version of the GNU compilers might solve this issue.</p>
</div>
</div>
<div class="section" id="fortran">
<h6>Fortran<a class="headerlink" href="#fortran" title="Permalink to this headline">¶</a></h6>
<p>The Intel compiler for Fortran is <code class="file docutils literal notranslate"><span class="pre">ifort</span></code>.</p>
<p>Basic flags:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-o</span></code> <em>exe_file</em>: name the executable <code class="file docutils literal notranslate"><span class="pre">exe_file</span></code></li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span></code>: generate the object file without creating an executable.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-g</span></code>: compile with the debug symbols.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-I</span> <span class="pre">dir_name</span></code>: add <code class="file docutils literal notranslate"><span class="pre">dir_name</span></code> to the list of directories where include files are looked for.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-L</span> <span class="pre">dir_name</span></code>: add <code class="file docutils literal notranslate"><span class="pre">dir_name</span></code> to the list of directories where libraries are looked for.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-l</span> <span class="pre">bib</span></code>: link the <code class="file docutils literal notranslate"><span class="pre">libbib.a</span></code> library</li>
</ul>
<p>Run-time check</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-C</span></code> or <code class="xref std std-option docutils literal notranslate"><span class="pre">-check</span></code>: generates a code which ends up in ‘run time error’ (ex: segmentation fault)</li>
</ul>
<p>Preprocessor:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-E</span></code>: pre-process the files and send the result to the standard output</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-P</span></code>: pre-process the files and send the result to <code class="file docutils literal notranslate"><span class="pre">file.i</span></code></li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-Dname=</span></code>: assign the value <em>value</em> to the variable <span class="target" id="index-1"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">name</span></code></li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-M</span></code>: creates a list of dependencies</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-fpp</span></code>: pre-process the files and compile</li>
</ul>
<p>Practical:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-p</span></code>: compile for profiling with <strong class="command">gprof</strong>. You will not be able to use <strong class="command">gprof</strong> otherwise.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-mp</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-mp1</span></code>: IEEE arithmetic (mp1 is a compromise between time and accuracy)</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-i8</span></code>: promote integers to 64 bits by default</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-r8</span></code>: promote reals to 64 bits by default</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-module</span> <span class="pre">dir</span></code>: send/read the files <code class="file docutils literal notranslate"><span class="pre">*.mod</span></code> in the <code class="file docutils literal notranslate"><span class="pre">dir</span></code> directory</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-fp-model</span> <span class="pre">strict</span></code>: strictly adhere to value-safe optimizations when implementing floating-point calculations, and enable floating-point exception semantics. This may slow down your program.</li>
</ul>
<p>To tell the compiler to conform to a specific language standard :</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-stand=val</span></code>: where <strong>val</strong> can take the following values (cf. <strong class="command">man ifort</strong>)<ul>
<li>f15: Issues messages for language elements that are not standard in draft Fortran 2015.</li>
<li>f08: Tells the compiler to issue messages for language elements that are not standard in Fortran 2008</li>
<li>f03: Tells the compiler to issue messages for language elements that are not standard in Fortran 2003</li>
<li>…</li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Please refer to the <em>man pages</em> for more information about the compilers.</p>
</div>
</div>
</div>
<div class="section" id="optimization-flags">
<h5>Optimization flags<a class="headerlink" href="#optimization-flags" title="Permalink to this headline">¶</a></h5>
<p>Compilers provide many optimization options: this section describes them.</p>
<p>Basic optimization options :</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-O0</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-O1</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-O2</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-O3</span></code>: optimization levels - default: <code class="xref std std-option docutils literal notranslate"><span class="pre">-O2</span></code></li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-opt_report</span></code> : writes an optimization report to stderr (<code class="xref std std-option docutils literal notranslate"><span class="pre">-O3</span></code> required)</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-ip</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-ipo</span></code>: inter-procedural optimizations (mono and multi files). The command xiar must be used instead of ar to generate a static library file with objects compiled with <code class="xref std std-option docutils literal notranslate"><span class="pre">-ipo</span></code> option.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-fast</span></code> : default high optimization level (<code class="xref std std-option docutils literal notranslate"><span class="pre">-O3</span> <span class="pre">-ipo</span> <span class="pre">-static</span></code>).</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-ftz</span></code> : considers all the denormalized numbers (like INF or NAN) as zeros at runtime.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-fp-relaxed</span></code> : mathematical optimization functions. Leads to a small loss of accuracy.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-pad</span></code> : makes the modification of the memory positions operational (<strong class="command">ifort</strong> only)</li>
</ul>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">The <code class="xref std std-option docutils literal notranslate"><span class="pre">-fast</span></code> option is not allowed with MPI because the MPI context needs some libraries which only exist in dynamic mode. This is incompatible with the <code class="xref std std-option docutils literal notranslate"><span class="pre">-static</span></code> option. You need to replace <code class="xref std std-option docutils literal notranslate"><span class="pre">-fast</span></code> by <code class="xref std std-option docutils literal notranslate"><span class="pre">-O3</span> <span class="pre">-ipo</span></code>.</p>
</div>
</div>
<div class="section" id="vectorization-flags">
<h5>Vectorization flags<a class="headerlink" href="#vectorization-flags" title="Permalink to this headline">¶</a></h5>
<p>Some options allow to use specific vectorization instructions of Intel processors to optimize the code. They are compatible with most Intel processors. The compiler will try to generate these instructions if the processor allows them.</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-xcode</span></code> : Tells the compiler which processor features it may target, including which instruction sets and optimization it may generate. “code” is one of the following:<ul>
<li>CORE-AVX2</li>
<li>AVX</li>
<li>SSE4.2</li>
<li>SSE2</li>
</ul>
</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-xHost</span></code> : Applies the highest level of vectorization supported depending on the processor where the compilation is performed. The login nodes may not have the same level of support as the compute nodes. So this option is to be used only if the compilation is done on the targeted compute nodes.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-axcode</span></code> : Tells the compiler to generate a single executable with multiple levels of vectorization. “code” is a comma-separated list of instructions sets.</li>
</ul>
<p>The default level of vectorization is sse2. However, it is only be activated for optimization level <code class="xref std std-option docutils literal notranslate"><span class="pre">-O2</span></code> and more.</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-vec-report[=n]</span></code> : depending on the value of n, the option <code class="xref std std-option docutils literal notranslate"><span class="pre">-vec-report</span></code> enables information reports by the vectorizer.</li>
</ul>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">A code compiled for a given instruction set will not run on a processor that only supports a lower instruction set</p>
</div>
</div>
<div class="section" id="default-compilation-flags">
<h5>Default compilation flags<a class="headerlink" href="#default-compilation-flags" title="Permalink to this headline">¶</a></h5>
<p>By default each of the Intel compiler provide the <code class="xref std std-option docutils literal notranslate"><span class="pre">-sox</span></code> option which allows to save all the options provided at the compilation time in the comment section of the ELF binary file. To display the comment section :</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ icc -g -O3 hello.c -o helloworld
$ readelf -p .comment ./helloworld
 String dump of section &#39;.comment&#39;:
 [     0]  GCC: (GNU) &lt;x.y.z&gt; (Red Hat &lt;x.y.z&gt;)
 [    2c]  -?comment:Intel(R) C Intel(R) 64 Compiler for applications running on Intel(R) 64, Version &lt;x.y.z&gt; Build &lt;XXXXXX&gt;  : hello.c : -sox -g -O3 -o helloworld
</pre></div>
</div>
</div>
</div>
<div class="section" id="gnu">
<h4>GNU<a class="headerlink" href="#gnu" title="Permalink to this headline">¶</a></h4>
<div class="section" id="id1">
<h5>Compiler flags<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h5>
<p>Basic flags:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-o</span> <span class="pre">exe_file</span></code>: names the executable <code class="file docutils literal notranslate"><span class="pre">exe_file</span></code></li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span></code>: generates the corresponding object file, without creating an executable.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-g</span></code>: compiles with the debug symbols.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-I</span> <span class="pre">dir_name</span></code>: specifies the path where the include files are located.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-L</span> <span class="pre">dir_name</span></code>: specifies the path where the libraries are located.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-l</span> <span class="pre">bib</span></code>: asks to link the <code class="file docutils literal notranslate"><span class="pre">libbib.a</span></code> library</li>
</ul>
<p>To tell the compiler to conform to a specific language standard (g++/gcc/gfortran) :</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-std=val</span></code>: where <strong>val</strong> can take the following values (cf. <strong class="command">man gcc/g++/gfortran</strong>)<ul>
<li>c++14 : Enables support for the 2014 ISO C++ standard features.</li>
<li>C99 : Conforms to The ISO/IEC 9899:1999 International Standard.</li>
<li>f03: Tells the compiler to issue messages for language elements that are not standard in Fortran 2003</li>
<li>f08: Tells the compiler to issue messages for language elements that are not standard in Fortran 2008</li>
<li>…</li>
</ul>
</li>
</ul>
<p>Below are some specific flags for the <strong class="command">gfortran</strong> commands.</p>
<p>Debugging:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-Wall</span></code>: short for “warn about all”, warns about usual causes of bugs, such as having a subroutine or function named like a built-in one, or passing the same variable as an intent(in) and an intent(out) argument of the same subroutine</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-Wextra</span></code>: used with <code class="xref std std-option docutils literal notranslate"><span class="pre">-Wall</span></code>, warns about even more potential problems, like unused subroutine arguments</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-w</span></code>: inhibits all warning messages (not recommended)</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-Werror</span></code>: considers any warning as an error</li>
</ul>
</div>
<div class="section" id="id2">
<h5>Optimization flags<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h5>
<p>Compilers provide many optimization options: this section describes them.</p>
<p>Basic optimization options :</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-O0</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-O1</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-O2</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-O3</span></code>: optimization levels - default: <code class="xref std std-option docutils literal notranslate"><span class="pre">-O0</span></code></li>
</ul>
<p>Some options allow usage of specific set of instructions for Intel processors, to optimize code behavior. They are compatible with most Intel processors. The compiler will try to use them if the processor allows them.</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-mavx2</span></code> / <code class="xref std std-option docutils literal notranslate"><span class="pre">-mno-avx2</span></code> : Switch on or off the usage of said instruction set.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-mavx</span></code> / <code class="xref std std-option docutils literal notranslate"><span class="pre">-mno-avx</span></code> : idem.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-msse4.2</span></code> / <code class="xref std std-option docutils literal notranslate"><span class="pre">-mno-sse4.2</span></code> : idem.</li>
</ul>
</div>
</div>
</div>
<div class="section" id="available-numerical-libraries">
<h3>Available numerical libraries<a class="headerlink" href="#available-numerical-libraries" title="Permalink to this headline">¶</a></h3>
<div class="section" id="mkl-library">
<h4>MKL library<a class="headerlink" href="#mkl-library" title="Permalink to this headline">¶</a></h4>
<p>The Intel MKL library is integrated in the Intel package and contains:</p>
<ul class="simple">
<li>BLAS, SparseBLAS;</li>
<li>LAPACK, ScaLAPACK;</li>
<li>Sparse Solver, CBLAS ;</li>
<li>Discrete Fourier and Fast Fourier transform</li>
</ul>
<p>If you don’t need ScaLAPACK:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load mkl
$ ifort -o myexe myobject.o ${MKL_LDFLAGS}
</pre></div>
</div>
<p>If you need ScaLAPACK:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load scalapack
$ mpif90 -o myexe myobject.o ${SCALAPACK_LDFLAGS}
</pre></div>
</div>
<p>We provide multi-threaded versions for compiling with MKL:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load feature/mkl/multi-threaded
$ module load mkl
$ ifort -o myexe myobject.o ${$MKL_LDFLAGS}
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load feature/mkl/multi-threaded
$ module load scalapack
$ mpif90 -o myexe myobject.o ${SCALAPACK_LDFLAGS}
</pre></div>
</div>
<p>To use multi-threaded MKL, you have to set the OpenMP environment variable <span class="target" id="index-2"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">OMP_NUM_THREADS</span></code>.</p>
<p>We strongly recommend you to use the <span class="target" id="index-3"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">MKL_XXX</span></code> and <span class="target" id="index-4"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SCALAPACK_XXX</span></code> environment variables made available by the mkl and scalapack modules.</p>
</div>
<div class="section" id="fftw">
<h4>FFTW<a class="headerlink" href="#fftw" title="Permalink to this headline">¶</a></h4>
<p>FFTW is a C subroutine library for computing the discrete Fourier transform (DFT) in one or more dimensions, with an arbitrary input size, and with both real and complex data. It is provided by the <strong class="command">fftw3/gnu</strong> module. The variables <span class="target" id="index-5"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">FFTW3_CFLAGS</span></code> and <span class="target" id="index-6"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">FFTW3_LDFLAGS</span></code> should be used to compile a code using fftw routines.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load fftw3/gnu
$ icc ${FFTW3_CFLAGS} -o test example_fftw3.c ${FFTW3_LDFLAGS}
$ ifort ${FFTW3_FFLAGS} -o test example_fftw3.f90 ${FFTW3_LDFLAGS}
</pre></div>
</div>
<p>Intel MKL also provides Fourier transform functions. FFTW3 wrappers are able to link programes so that they can use Intel MKL Fourier transforms instead of the FFTW3 library, without changing the source code. The correct compiling options are provided by the <strong class="command">fftw3/mkl</strong> module.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load fftw3/mkl
$ icc ${FFTW3_CFLAGS} -o test example_fftw3.c ${FFTW3_LDFLAGS}
$ ifort ${FFTW3_FFLAGS} -o test example_fftw3.f90 ${FFTW3_LDFLAGS}
</pre></div>
</div>
</div>
</div>
<div class="section" id="compiling-for-skylake">
<span id="id3"></span><h3>Compiling for Skylake<a class="headerlink" href="#compiling-for-skylake" title="Permalink to this headline">¶</a></h3>
<p>With the <code class="xref std std-option docutils literal notranslate"><span class="pre">-ax</span></code> option, <strong class="command">icc</strong> and <strong class="command">ifort</strong> can generate code for several architectures.</p>
<p>For example, from a Broadwell login nodes, you can generate an executable with both AVX2 (Broadwell) and AVX512 (Skylake) instructions set. To do so, you need to add the <code class="xref std std-option docutils literal notranslate"><span class="pre">-axCORE-AVX2,CORE-AVX512</span></code> option to <strong class="command">icc</strong> or <strong class="command">ifort</strong>.</p>
<p>An executable compiled with <code class="xref std std-option docutils literal notranslate"><span class="pre">-axCORE-AVX2,CORE-AVX512</span></code> can be run on both Broadwell and Skylake as the best instruction set available on the architecture will be chosen.</p>
</div>
<div class="section" id="compiling-for-rome-milan">
<span id="id4"></span><h3>Compiling for Rome/Milan<a class="headerlink" href="#compiling-for-rome-milan" title="Permalink to this headline">¶</a></h3>
<p>With the <code class="xref std std-option docutils literal notranslate"><span class="pre">-m</span></code> option, <strong class="command">icc</strong> and <strong class="command">ifort</strong> can generate specific instruction sets for Intel and non-Intel processors.</p>
<p>AMD Rome and Milan processors are able to run AVX2 instructions.
To generate an AVX2 instructions for AMD processors, you need to add the <code class="xref std std-option docutils literal notranslate"><span class="pre">-mavx2</span></code> option to <strong class="command">icc</strong> or <strong class="command">ifort</strong>.
An executable compiled with <code class="xref std std-option docutils literal notranslate"><span class="pre">-mavx2</span></code> can run on both AMD and Intel processors.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>The <code class="xref std std-option docutils literal notranslate"><span class="pre">-mavx2</span></code> option is compatible with <strong class="command">gcc</strong>.</li>
<li>Both <code class="xref std std-option docutils literal notranslate"><span class="pre">-mavx2</span></code> and <code class="xref std std-option docutils literal notranslate"><span class="pre">-axCORE-AVX2,CORE-AVX512</span></code> options can be used simultaneously with <strong class="command">icc</strong> and <strong class="command">ifort</strong> to generate both specific instructions for Intel processors and more generic instructions for AMD processors.</li>
</ul>
</div>
</div>
</div>
<span id="document-toc/fulldoc/Parallel_programming"></span><div class="section" id="parallel-programming">
<span id="id1"></span><h2>Parallel programming<a class="headerlink" href="#parallel-programming" title="Permalink to this headline">¶</a></h2>
<div class="section" id="mpi">
<h3>MPI<a class="headerlink" href="#mpi" title="Permalink to this headline">¶</a></h3>
<p>The MPI (Message Passing Interface) standard is an API for processes that need to send, wait or receive messages. A full documentation of all the implemented functions can be found in the <a class="reference external" href="http://www.mpi-forum.org/docs/docs.html">MPI Standard documentation</a>.</p>
<div class="section" id="mpi-implementations">
<h4>MPI implementations<a class="headerlink" href="#mpi-implementations" title="Permalink to this headline">¶</a></h4>
<p>The supercomputer comes with a default MPI implementation provided by the manufacturer. The supported MPI implementation is OpenMPI.</p>
<p>Other existing implementations include IntelMPI, MVAPICH2, PlatformMPI but all are not made available on the cluster. To see a list of implementations available, use the command <strong class="command">module avail mpi</strong>.</p>
<p>The default MPI implementation is loaded in your environment at connexion time.</p>
</div>
<div class="section" id="compiling-mpi-programs">
<h4>Compiling MPI programs<a class="headerlink" href="#compiling-mpi-programs" title="Permalink to this headline">¶</a></h4>
<p>You can compile and link MPI programs using the wrappers <strong class="command">mpicc</strong>, <strong class="command">mpic++</strong>, <strong class="command">mpif77</strong> and <strong class="command">mpif90</strong>. Those wrappers actually call basic compilers but add the correct paths to MPI include files and linking options to MPI libraries.</p>
<p>For example to compile a simple program using MPI:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ mpicc -o mpi_prog.exe mpi_prog.c
$ mpic++ -o mpi_prog.exe mpi_prog.cpp
$ mpif90 -o mpi_prog.exe mpi_prog.f90
</pre></div>
</div>
<p>To see the full compiling call made by the wrapper, use the command <strong class="command">mpicc -show</strong>.</p>
</div>
<div class="section" id="wi4mpi">
<h4>Wi4MPI<a class="headerlink" href="#wi4mpi" title="Permalink to this headline">¶</a></h4>
<p>Interoperability between MPI implementations is usually not possible because each one has a specific Application Binary Interface (ABI). To overcome this, we have Wi4MPI. Wi4MPI provides two modes (Interface and Preload) with the same promise, one compilation for several run on different MPI implementations (OpenMPI, IntelMPI).</p>
<div class="section" id="interface">
<h5>Interface<a class="headerlink" href="#interface" title="Permalink to this headline">¶</a></h5>
<p>In this mode, Wi4MPI works as an MPI implementation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load mpi/wi4mpi
feature/wi4mpi/to/openmpi/x.y.z (WI4MPI feature to openmpi x.y.z)
wi4mpi/a.b.c (Wi4MPI with openmpi/x.y.z)
$ mpicc hello.c -o hello
$ ccc_mprun ./hello
</pre></div>
</div>
<p>By default, Wi4MPI is set to run application under OpenMPI. To choose the runtime MPI implementation please proceed as follow:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module switch feature/wi4mpi/to/openmpi/x.y.z feature/wi4mpi/to/intelmpi/a.b.c
</pre></div>
</div>
<div class="figure align-default" id="id4">
<a class="reference internal image-reference" href="_images/interface.png"><img alt="interface" src="_images/interface.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">interface</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="preload">
<h5>Preload<a class="headerlink" href="#preload" title="Permalink to this headline">¶</a></h5>
<p>In this mode, Wi4MPI works as a plugin.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load mpi/wi4mpi
feature/wi4mpi/to/openmpi/x.y.z (WI4MPI feature to openmpi x.y.z)
wi4mpi/a.b.c (Wi4MPI with openmpi/x.y.z)
</pre></div>
</div>
<p>This time the MPI implementation used for the compilation of the application needs to be provided as follow:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load feature/wi4mpi/from/openmpi/x.y.z
$ module list
1) ccc              4) licsrv/intel           7) fortran/intel/x.y.z  10) mkl/x.y.z          13) hwloc/x.y.z                     16) mpi/wi4mpi/x.y.z
2) datadir/own      5) c/intel/x.y.z     8) feature/mkl/lp64          11) intel/x.y.z        14) flavor/openmpi/cea               17) feature/wi4mpi/from/openmpi/x.y.z
3) dfldatadir/own   6) c++/intel/x.y.z   9) feature/mkl/sequential    12) flavor/wi4mpi/standard  15) feature/wi4mpi/to/openmpi/x.y.z
$ ccc_mprun exe_OpenMPI
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/preload.png"><img alt="_images/preload.png" src="_images/preload.png" style="width: 600px;" /></a>
<p>To see all available features:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module avail feature/wi4mpi
</pre></div>
</div>
<p>To know more about Wi4MPI please visit the <a class="reference external" href="https://github.com/cea-hpc/wi4mpi">cea-hpc github</a>.</p>
</div>
</div>
<div class="section" id="tuning-mpi">
<h4>Tuning MPI<a class="headerlink" href="#tuning-mpi" title="Permalink to this headline">¶</a></h4>
<div class="section" id="openmpi">
<h5>OpenMPI<a class="headerlink" href="#openmpi" title="Permalink to this headline">¶</a></h5>
<div class="section" id="mca-parameters">
<h6>MCA Parameters<a class="headerlink" href="#mca-parameters" title="Permalink to this headline">¶</a></h6>
<p>OpenMPI can be tuned with parameters. The command <strong class="command">ompi_info -a</strong> gives you a list of all parameters and their description.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ompi_info -a
(...)
  MCA mpi: parameter &quot;mpi_show_mca_params&quot; (current value: &lt;none&gt;, data source: default value)
           Whether to show all MCA parameter values during MPI_INIT or not (good for
           reproducibility of MPI jobs for debug purposes). Accepted values are all,
           default, file, api, and environment - or a comma delimited combination of them
(...)
</pre></div>
</div>
<p>Theses parameters can be modified with environment variables set before the <strong class="command">ccc_mprun</strong> command. The form of the corresponding environment variable is <span class="target" id="index-0"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">OMPI_MCA_xxxxx</span></code> where <em>xxxxx</em> is the parameter.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -r MyJob_Para                # Request name
#MSUB -n 32                        # Number of tasks to use
#MSUB -T 1800                      # Elapsed time limit in seconds
#MSUB -o example_%I.o              # Standard output. %I is the job id
#MSUB -e example_%I.e              # Error output. %I is the job id
#MSUB -A paxxxx                    # Project ID
#MSUB -q partition                 # Queue

set -x
cd ${BRIDGE_MSUB_PWD}
export OMPI_MCA_mpi_show_mca_params=all
ccc_mprun ./a.out
</pre></div>
</div>
<p>For more information on MCA parameters, check out the <em>tuning</em> part of the <a class="reference external" href="https://www.open-mpi.org/faq/">openmpi FAQ</a>.</p>
</div>
<div class="section" id="predefined-mpi-profiles">
<h6>Predefined MPI profiles<a class="headerlink" href="#predefined-mpi-profiles" title="Permalink to this headline">¶</a></h6>
<p>Some common MCA parameters are defined in several features (openmpi) to simplify their usage.</p>
<p>Here are those modules:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module avail feature/openmpi
----------------- /opt/Modules/default/modulefiles/applications -----------------
----------------- /opt/Modules/default/modulefiles/environment -----------------
feature/openmpi/big_collective_io  feature/openmpi/gnu  feature/openmpi/mxm  feature/openmpi/performance  feature/openmpi/performance_test
</pre></div>
</div>
<p>Here is their description and their limitation(s):</p>
<ul>
<li><p class="first"><strong>performance</strong></p>
<blockquote>
<div><p>Description : Improve communication performances in classic applications (namely those with fixed communication scheme).
Limitation : Moderately increase the memory consumption of the MPI layer.</p>
</div></blockquote>
</li>
<li><p class="first"><strong>big_collective_io</strong></p>
<blockquote>
<div><p>Description : Increase data bandwidth when accessing big files on lustre file system.
Limitation : Only useful when manipulating big files through MPI_IO and derivated (parallel hdf5, etc.).</p>
</div></blockquote>
</li>
<li><p class="first"><strong>collective_performance</strong></p>
<blockquote>
<div><p>Description : Improve the performance of several MPI collective routines by using the GHC feature developed by BULL.
Limitation : Improvements may not be seen on small cases.
Namely change the order in which MPI reduction operations are performed and may impact the reproductability and/or the numerical stability of very sensible systems.</p>
</div></blockquote>
</li>
<li><p class="first"><strong>low_memory_footprint</strong></p>
<blockquote>
<div><p>Description : Reduce the memory consumption of the MPI layer.
Limitation : May have strong impact over communication performances.
Should only be used when you are near the memory limits.</p>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="compiler-features">
<h6>Compiler Features<a class="headerlink" href="#compiler-features" title="Permalink to this headline">¶</a></h6>
<p>By default, MPI wrappers use Intel compilers. To use GNU compilers, you need to set the following environment variables:</p>
<ul class="simple">
<li><span class="target" id="index-1"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">OMPI_CC</span></code> for C</li>
<li><span class="target" id="index-2"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">OMPI_CXX</span></code> for C++</li>
<li><span class="target" id="index-3"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">OMPI_F77</span></code> for fortran77</li>
<li><span class="target" id="index-4"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">OMPI_FC</span></code> for fortran90</li>
</ul>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ export OMPI_CC=gcc
$ mpicc -o test.exe test.c
</pre></div>
</div>
<p>It’s also possible to use the feature <strong>feature/openmpi/gnu</strong> which set all variables define above at GNU compilers (gcc, g++, gfortran).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load feature/openmpi/gnu
load module feature/openmpi/gnu (OpenMPI profile feature)
</pre></div>
</div>
</div>
</div>
<div class="section" id="intelmpi">
<h5>IntelMPI<a class="headerlink" href="#intelmpi" title="Permalink to this headline">¶</a></h5>
<div class="section" id="id2">
<h6>Compiler Features<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h6>
<p>By default, MPI wrappers use Intel compilers. To use GNU compilers, you need to set the following environment variables:</p>
<ul class="simple">
<li><span class="target" id="index-5"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">I_MPI_CC</span></code> for C</li>
<li><span class="target" id="index-6"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">I_MPI_CXX</span></code> for C++</li>
<li><span class="target" id="index-7"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">I_MPI_F77</span></code> for fortran77</li>
<li><span class="target" id="index-8"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">I_MPI_FC</span></code> for fortran90</li>
</ul>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ export I_MPI_CC=gcc
$ mpicc -o test.exe test.c
</pre></div>
</div>
<p>It’s also possible to use the feature <strong>feature/intelmpi/gnu</strong> which set all variables define above at GNU compilers (gcc, g++, gfortran).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load feature/intelmpi/gnu
load module feature/intelmpi/gnu (IntelMPI profile feature)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="openmp">
<h3>OpenMP<a class="headerlink" href="#openmp" title="Permalink to this headline">¶</a></h3>
<p>OpenMP is an API that supports multi-platform shared memory multiprocessing programming in C, C++, and Fortran. It consists of a set of compiler directives, library routines, and environment variables that influence run-time behavior. More information and a full documentation can be found on the <a class="reference external" href="http://openmp.org/">official website</a>.</p>
<div class="section" id="compiling-openmp-programs">
<h4>Compiling OpenMP programs<a class="headerlink" href="#compiling-openmp-programs" title="Permalink to this headline">¶</a></h4>
<p>The Intel and GNU compilers both support OpenMP. Use the <code class="xref std std-option docutils literal notranslate"><span class="pre">-fopenmp</span></code> flag to generate multi-threaded code with those compilers.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><code class="xref std std-option docutils literal notranslate"><span class="pre">-openmp</span></code> works only for intel whereas <code class="xref std std-option docutils literal notranslate"><span class="pre">-fopenmp</span></code> works with both Intel and GNU compilers.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ icc -fopenmp -o openmp_prog.exe openmp_prog.c
$ icpc -fopenmp -o openmp_prog.exe openmp_prog.cpp
$ ifort -fopenmp -o openmp_prog.exe openmp_prog.f90
</pre></div>
</div>
</div>
<div class="section" id="intel-thread-affinity">
<span id="id3"></span><h4>Intel thread affinity<a class="headerlink" href="#intel-thread-affinity" title="Permalink to this headline">¶</a></h4>
<p>By default, threads inherit the same affinity than their parent process (see <a class="reference internal" href="irene.html#process-distribution-affinity-and-binding"><span class="std std-ref">Process distribution, affinity and binding</span></a> for more information). For example, if the parent process has been allocated 4 cores, the OpenMP threads spawned by this process will be allowed to run freely on those 4 cores.</p>
<p>To set a more specific binding for threads among the allocated cores, Intel provides environment variables: <span class="target" id="index-9"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">KMP_AFFINITY</span></code></p>
<p>The values given to <span class="target" id="index-10"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">KMP_AFFINITY</span></code> should be a comma-separated list of the following keywords:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">verbose</span></code>: prints messages concerning the supported affinity.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">granularity=</span></code>: specifies whether to pin OpenMP threads to physical cores (<code class="xref std std-option docutils literal notranslate"><span class="pre">granularity=core</span></code>, this is the default) or pin to logical cores (<code class="xref std std-option docutils literal notranslate"><span class="pre">granularity=fine</span></code>). This is only effective on nodes that support hyperthreading.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">compact</span></code>: assigns the threads as close as possible together.</li>
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">scatter</span></code>: distributes the threads as evenly as possible across the entire system.</li>
</ul>
</div>
</div>
<div class="section" id="using-gpus">
<h3>Using GPUs<a class="headerlink" href="#using-gpus" title="Permalink to this headline">¶</a></h3>
<div class="section" id="cuda">
<h4>CUDA<a class="headerlink" href="#cuda" title="Permalink to this headline">¶</a></h4>
<p>The CUDA compiler is available for hybrid nodes to compile GPU-accelerated programs for Nvidia devices.</p>
<p>To compile a simple CUDA code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load cuda
$ nvcc -o test_cuda test.cu
</pre></div>
</div>
<p>Each new generation of GPU comes with new CUDA features. To use those features in a code, you may need to specify the <em>compute capability</em> of the target GPU. Check out the kind of GPU provided on the hybrid partition in <a class="reference internal" href="irene.html#supercomputer-architecture"><span class="std std-ref">Supercomputer architecture</span></a> and check the related compute capability on the <a class="reference external" href="https://developer.nvidia.com/cuda-gpus">nvidia website</a>. For example, to generate a code for a targeted GPU with a 3.5 compute capability:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ nvcc -gencode arch=compute_35,code=sm_35 -o test_cuda test.cu
</pre></div>
</div>
<p>You may specify several levels of support if you need the code to run on different GPU generations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ nvcc -gencode arch=compute_35,code=sm_35 -gencode arch=compute_30,code=sm_30 -o test_cuda test.cu
</pre></div>
</div>
<p>The <strong class="command">nvcc</strong> command uses C and C++ compilers underneath. Compiling with <strong class="command">nvcc -v</strong> will show the detail of the underlying compiling calls. By default, the GNU compilers are used. To change the underlying compiler, use the <code class="xref std std-option docutils literal notranslate"><span class="pre">ccbin</span></code> option:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ nvcc -v -ccbin=icc -o test_cuda test.cu
</pre></div>
</div>
<p>Most GPU codes are partially composed of basic sequential codes in separate files. They need to be compiled separately:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ls
   cuda_file.cu    file.c
$ icc -o file.o -c file.c
$ nvcc -ccbin=icc -o cuda_file.o -c cuda_file.cu
$ icc -o test_cuda -L${CUDA_LIBDIR} -lcudart file.o cuda_file.o
</pre></div>
</div>
</div>
<div class="section" id="opencl">
<h4>OpenCL<a class="headerlink" href="#opencl" title="Permalink to this headline">¶</a></h4>
<p>OpenCL is provided both with the CUDA installation and by a separated Intel installation. Compatibility modules are available to simply switch from one version to another: <code class="docutils literal notranslate"><span class="pre">opencl/nvidia</span></code> and <code class="docutils literal notranslate"><span class="pre">opencl/intel</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load opencl/nvidia
or
$ module load opencl/intel

$ icc -I${OPENCL_INCDIR} -o test_ocl opencl.c -lOpenCL
</pre></div>
</div>
</div>
</div>
</div>
<span id="document-toc/fulldoc/Runtime_tuning"></span><div class="section" id="runtime-tuning">
<span id="id1"></span><h2>Runtime tuning<a class="headerlink" href="#runtime-tuning" title="Permalink to this headline">¶</a></h2>
<div class="section" id="memory-allocation-tuning">
<h3>Memory allocation tuning<a class="headerlink" href="#memory-allocation-tuning" title="Permalink to this headline">¶</a></h3>
<div class="section" id="feature-tbb-malloc">
<h4>Feature TBB malloc<a class="headerlink" href="#feature-tbb-malloc" title="Permalink to this headline">¶</a></h4>
<p>Intel <abbr title="Threading Building Blocks">TBB</abbr> presents an <abbr title="Application Program Interface">API</abbr> that take full advantage of multicore performance. Among this API, there is some allocator that could be found in the GNU C Library as malloc or calloc but performing in a more efficient way inside TBB. The easiest way for an application to benefit from it (without any changes within it) is to provide the following librairies to the environment variable <span class="target" id="index-0"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">LD_PRELOAD</span></code>, or to use the <strong>feature</strong> available on Irene as follow.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load feature/optimization/tbb_malloc
</pre></div>
</div>
<p>Now, at each use of the command <strong class="command">ccc_mprun</strong>, any application will benefit from those allocator.</p>
</div>
</div>
</div>
<span id="document-toc/fulldoc/Process_distribution_affinity_binding"></span><div class="section" id="process-distribution-affinity-and-binding">
<span id="id1"></span><h2>Process distribution, affinity and binding<a class="headerlink" href="#process-distribution-affinity-and-binding" title="Permalink to this headline">¶</a></h2>
<div class="section" id="hardware-topology">
<h3>Hardware topology<a class="headerlink" href="#hardware-topology" title="Permalink to this headline">¶</a></h3>
<p>Hardware topology is the organization of cores, processors, sockets, memory, network cards and accelerators (like graphic cards) in a node. An image of the topology of a node is shown by <strong class="command">lstopo</strong>. This function comes with <a class="reference external" href="http://www.open-mpi.org/projects/hwloc/">hwloc</a>, and you can access it with the command <strong class="command">module load hwloc</strong>. For example, a simple graphical representation of a compute node layout can be obtained with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lstopo</span>  <span class="o">--</span><span class="n">no</span><span class="o">-</span><span class="n">caches</span> <span class="o">--</span><span class="n">no</span><span class="o">-</span><span class="n">io</span> <span class="o">--</span><span class="n">of</span> <span class="n">png</span>
</pre></div>
</div>
<div class="figure align-default" id="id3">
<a class="reference internal image-reference" href="_images/Cobalt_Broadwell_Topo.png"><img alt="Hardware topology of a 28 core node with 4 sockets and Hyper-Threading activated" src="_images/Cobalt_Broadwell_Topo.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Hardware topology of a 28 core node with 4 sockets and Hyper-Threading activated</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="definitions">
<h3>Definitions<a class="headerlink" href="#definitions" title="Permalink to this headline">¶</a></h3>
<p>We define here some vocabulary:</p>
<ul class="simple">
<li><strong>Process distribution</strong> : the distribution of MPI processes describes how these processes are spread across the cores, sockets or nodes.</li>
<li><strong>Process affinity</strong> : represents the policy of resources management (cores and memory) for processes.</li>
<li><strong>Process binding</strong> : a Linux process can be bound (or stuck or pinned) to one or many cores. It means a process and its threads can run only on a given selection of cores.</li>
</ul>
<p>The default behavior for distribution, affinity and binding is managed by the batch scheduler through the <strong class="command">ccc_mprun</strong> command. <abbr title="Simple Linux Utility for Resource Management">SLURM</abbr> is the batch scheduler for jobs on the supercomputer. SLURM manages the distribution, affinity and binding of processes even for sequential jobs. That is why we recommend you to use <strong class="command">ccc_mprun</strong> even for non-MPI codes.</p>
</div>
<div class="section" id="process-distribution">
<span id="id2"></span><h3>Process distribution<a class="headerlink" href="#process-distribution" title="Permalink to this headline">¶</a></h3>
<p>We present here the most common MPI process distributions. The cluster naturally has a two dimensional distribution. The first level of distribution manages the process layout across nodes and the second level manages process layout within a node, across sockets.</p>
<ul class="simple">
<li>Distribution across nodes<ul>
<li><strong>block</strong> by node: The block distribution method will distribute tasks such that consecutive tasks share a node.</li>
<li><strong>cyclic</strong> by node: The cyclic distribution method will distribute tasks such that consecutive tasks are distributed over consecutive nodes (in a round-robin fashion).</li>
</ul>
</li>
<li>Distribution across sockets<ul>
<li><strong>block</strong> by socket: The block distribution method will distribute tasks to a socket such that consecutive tasks share a same socket.</li>
<li><strong>cyclic</strong> by socket: The cyclic distribution method will distribute tasks to a socket such that consecutive tasks are distributed over consecutive socket (in a round-robin fashion).</li>
</ul>
</li>
</ul>
<p>The default distribution on the supercomputer is block by node and block by socket. To change the distribution of processes, you can use the option <code class="xref std std-option docutils literal notranslate"><span class="pre">-E</span> <span class="pre">&quot;-m</span> <span class="pre">block|cyclic:[block|cyclic]&quot;</span></code> for <strong class="command">ccc_mprun</strong> or for <strong class="command">ccc_msub</strong>. The first argument refers to the node level distribution and the second argument refers to the socket level distribution.</p>
<p>In the following examples, let us consider 2 nodes composed of 2 sockets. Each socket with 8 cores.</p>
<ul>
<li><p class="first">Block by node and block by socket distribution:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">n</span> <span class="mi">32</span> <span class="o">-</span><span class="n">E</span> <span class="s1">&#39;-m block:block&#39;</span> <span class="o">./</span><span class="n">a</span><span class="o">.</span><span class="n">out</span>
</pre></div>
</div>
<ul class="simple">
<li>Processes 0 to 7 are gathered on the first socket of the first node</li>
<li>Processes 8 to 15 are gathered on the second socket of the first node</li>
<li>Processes 16 to 23 are gathered on the first socket of the second node</li>
<li>Processes 24 to 31 are gathered on the second socket of the second node</li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="_images/BlockBlock.png"><img alt="_images/BlockBlock.png" src="_images/BlockBlock.png" style="width: 300px;" /></a>
<p>This is the default distribution.</p>
<ul>
<li><p class="first">Cyclic by node and block by socket distribution:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">n</span> <span class="mi">32</span> <span class="o">-</span><span class="n">E</span> <span class="s1">&#39;-m cyclic:block&#39;</span> <span class="o">./</span><span class="n">a</span><span class="o">.</span><span class="n">out</span>
</pre></div>
</div>
<ul class="simple">
<li>Process 0 runs on the first socket of the first node</li>
<li>Process 1 runs on the first socket of the second node</li>
<li>…</li>
</ul>
<p>And once the first socket is full, processes are distributed on the next sockets:</p>
<ul class="simple">
<li>Process 16 runs on the second socket of the first node</li>
<li>Process 17 runs on the second socket of the second node</li>
<li>…</li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="_images/CyclicCyclic.png"><img alt="_images/CyclicCyclic.png" src="_images/CyclicCyclic.png" style="width: 300px;" /></a>
<ul>
<li><p class="first">Block by node and cyclic by socket distribution:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">n</span> <span class="mi">32</span> <span class="o">-</span><span class="n">E</span> <span class="s1">&#39;-m block:cyclic&#39;</span> <span class="o">./</span><span class="n">a</span><span class="o">.</span><span class="n">out</span>
</pre></div>
</div>
<ul class="simple">
<li>Process 0 runs on the first socket of the first node</li>
<li>Process 1 runs on the second socket of the first node</li>
<li>…</li>
</ul>
<p>And once the first node is full, processes are distributed on both sockets of the next node:</p>
<ul class="simple">
<li>Process 16 runs on the first socket of the second node</li>
<li>Process 17 runs on the second socket of the second node</li>
<li>…</li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="_images/Cyclic.png"><img alt="_images/Cyclic.png" src="_images/Cyclic.png" style="width: 300px;" /></a>
<ul>
<li><p class="first">Cyclic by node and cyclic by socket distribution:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">n</span> <span class="mi">32</span> <span class="o">-</span><span class="n">E</span> <span class="s1">&#39;-m cyclic:cyclic&#39;</span> <span class="o">./</span><span class="n">a</span><span class="o">.</span><span class="n">out</span>
</pre></div>
</div>
<ul class="simple">
<li>Process 0 runs on the first socket of the first node</li>
<li>Process 1 runs on the first socket of the second node</li>
<li>Process 2 runs on the second socket of the first node</li>
<li>Process 3 runs on the second socket of the second node</li>
<li>Process 4 runs on the first socket of the first node</li>
<li>…</li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="_images/RealCyclicCyclic.png"><img alt="_images/RealCyclicCyclic.png" src="_images/RealCyclicCyclic.png" style="width: 300px;" /></a>
</div>
<div class="section" id="process-and-thread-affinity">
<h3>Process and thread affinity<a class="headerlink" href="#process-and-thread-affinity" title="Permalink to this headline">¶</a></h3>
<div class="section" id="why-is-affinity-important-for-improving-performance">
<h4>Why is affinity important for improving performance ?<a class="headerlink" href="#why-is-affinity-important-for-improving-performance" title="Permalink to this headline">¶</a></h4>
<p>Most recent nodes are <abbr title="Non-Uniform Memory Access">NUMA</abbr> nodes: they need more time to access some regions of memory than others, because all memory regions are not physically on the same bus.</p>
<div class="figure align-default" id="id4">
<a class="reference internal image-reference" href="_images/Numa_Node.png"><img alt="NUMA node : Memory access" src="_images/Numa_Node.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-text">NUMA node : Memory access</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
<p>This picture shows that if a data is in the memory module 0, a process running on the second socket like the 9th process will take more time to access the data. We can introduce the notion of <em>local data</em> vs <em>remote data</em>. In our example, if we consider a process running on the socket 0, a data is <em>local</em> if it is on the memory module 0. The data is <em>remote</em> if it is on the memory module 1.</p>
<p>We can then deduce the reasons why tuning the process affinity is important:</p>
<ul class="simple">
<li>Data locality improve performance. If your code uses shared memory (like pthreads or OpenMP), the best choice is to group your threads on the same socket. The shared data should be local to the socket and moreover, the data may stay in the processor’s cache.</li>
<li>System processes can interrupt your process running on a core. If your process is not bound to a core or to a socket, it can be moved to another core or to another socket. In this case, all data for this process have to be moved with the process too and it can take some time.</li>
<li>MPI communications are faster between processes which are on the same socket. If you know that two processes have many communications, you can bind them to the same socket.</li>
<li>On Hybrid nodes, the GPUs are connected to buses which are local to a socket. Processes can take more time to access a GPU which is not connected to its socket.</li>
</ul>
<div class="figure align-default" id="id5">
<a class="reference internal image-reference" href="_images/GPU_numa.png"><img alt="NUMA node : Example of a hybrid node with GPU" src="_images/GPU_numa.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-text">NUMA node : Example of a hybrid node with GPU</span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
<p>For all these reasons, knowing the NUMA configuration of the partition’s nodes is strongly recommended. The next section presents some ways to tune your processes affinity for your jobs.</p>
</div>
<div class="section" id="process-thread-affinity">
<h4>Process/thread affinity<a class="headerlink" href="#process-thread-affinity" title="Permalink to this headline">¶</a></h4>
<p>The batch scheduler sets a default binding for processes. Each process is bound to the core it was distributed to, as described in <a class="reference internal" href="#process-distribution"><span class="std std-ref">Process distribution</span></a>.</p>
<p>For multi-threaded jobs, the batch scheduler provides the option <code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span></code> to bind each process to several cores. Each thread created by a process will inherit its affinity. Here is an example of a hybrid OpenMP/MPI code running on 8 MPI processes, each process using 4 OpenMP threads.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -r MyJob_Para                # Request name</span>
<span class="c1">#MSUB -n 8                         # Number of tasks to use</span>
<span class="c1">#MSUB -c 4                         # Assign 4 cores per process</span>
<span class="c1">#MSUB -T 1800                      # Elapsed time limit in seconds</span>
<span class="c1">#MSUB -o example_%I.o              # Standard output. %I is the job id</span>
<span class="c1">#MSUB -A paxxxx                    # Project ID</span>
<span class="c1">#MSUB -q partition                 # Queue</span>

<span class="n">export</span> <span class="n">OMP_NUM_THREADS</span><span class="o">=</span><span class="mi">4</span>
<span class="n">ccc_mprun</span> <span class="o">./</span><span class="n">a</span><span class="o">.</span><span class="n">out</span>
</pre></div>
</div>
<p>The process distribution will take the <code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span></code> option into account and set the binding accordingly. For example, in the default <em>block:block</em> mode:</p>
<ul class="simple">
<li>Process 0 is bound to cores 0 to 3 of the first node</li>
<li>Process 1 is bound to cores 4 to 7 of the first node</li>
<li>Process 2 is bound to cores 8 to 11 of the first node</li>
<li>Process 3 is bound to cores 12 to 15 of the first node</li>
<li>Process 4 is bound to cores 0 to 3 of the second node</li>
<li>…</li>
</ul>
<a class="reference internal image-reference" href="_images/Binding_OMP.png"><img alt="_images/Binding_OMP.png" src="_images/Binding_OMP.png" style="width: 400px;" /></a>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Since the default distribution is block, with the <code class="xref std std-option docutils literal notranslate"><span class="pre">-c</span></code> option, the batch scheduler will try to gather the cores as close as possible. This usually provides the best performances for multi-threaded jobs. In the previous example, all the cores of a MPI process will be located on the same socket.</p>
</div>
<p>Thread affinity may be set even more thoroughly within the process binding. For example, check out the <a class="reference internal" href="irene.html#intel-thread-affinity"><span class="std std-ref">Intel thread affinity</span></a> description.</p>
</div>
</div>
<div class="section" id="hyper-threading-usage">
<h3>Hyper-Threading usage<a class="headerlink" href="#hyper-threading-usage" title="Permalink to this headline">¶</a></h3>
<p>Hyper-Threading is Intel’s proprietary simultaneous multithreading implementation used to improve parallelization of computations performed on x86 microprocessors. It is activated on compute nodes. Therefore, each physical core appears as two processors to the operating system, allowing concurrent scheduling of two processes or threads per core. Unless specified, the resource manager will only consider physical cores and ignore this feature.</p>
<p>In case an application may positively benefits from this technology, MPI processes or OpenMP threads can be bind to logical cores. Here is the procedure:</p>
<ul class="simple">
<li>Doubling the processes:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -q partition
#MSUB -n 2

ccc_mprun -n $((BRIDGE_MSUB_NPROC*2)) -E&#39;--cpu_bind=threads --overcommit&#39; ./a.out   # 4 processes are run on 2 physical cores
</pre></div>
</div>
<ul class="simple">
<li>Doubling the threads:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -q partition
#MSUB -n 2
#MSUB -c 8

export OMP_NUM_THREADS=$((BRIDGE_MSUB_NCORE*2))   # threads number must be equal to logical cores
ccc_mprun ./a.out   # each process runs 16 threads on 8 physical cores / 16 logical cores
</pre></div>
</div>
</div>
<div class="section" id="turbo">
<h3>Turbo<a class="headerlink" href="#turbo" title="Permalink to this headline">¶</a></h3>
<p>The processor turbo technology (Intel Turbo Boost or AMD turbo core) is available and activated by default on Irene. This technology dynamically adjusts CPU frequency in order to reach the highest frequency allowed by the available power and thermal limits. The Turbo can be responsible of performance variation because of hardware differences between two nodes and if other jobs are running on the same node. One can choose to disable this technology by loading the module feature/turbo/off:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">feature</span><span class="o">/</span><span class="n">turbo</span><span class="o">/</span><span class="n">off</span>
</pre></div>
</div>
<p>Deactivating this technology allows a better control of the timing of the execution of the codes but can trigger poor performances. One can choose to have capped performances by loading the feature feature/turbo/capped:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">feature</span><span class="o">/</span><span class="n">turbo</span><span class="o">/</span><span class="n">capped</span>
</pre></div>
</div>
<p>which sets the CPU frequency to a determined value which prevents Turbo to be activated for vectorized operations.</p>
</div>
</div>
<span id="document-toc/fulldoc/IO"></span><div class="section" id="parallel-io">
<span id="id1"></span><h2>Parallel IO<a class="headerlink" href="#parallel-io" title="Permalink to this headline">¶</a></h2>
<div class="section" id="mpi-io">
<h3>MPI-IO<a class="headerlink" href="#mpi-io" title="Permalink to this headline">¶</a></h3>
<p>MPI-IO provides a low level implementation of parallel I/O. It was introduced as a standard in MPI-2.</p>
<p>More information on how to use MPI-IO can be found in the I/O section of the <a class="reference external" href="https://www.mpi-forum.org/docs/">official MPI documentation</a>.</p>
</div>
<div class="section" id="recommended-data-usage-on-parallel-file-system">
<span id="id2"></span><h3>Recommended data usage on parallel file system<a class="headerlink" href="#recommended-data-usage-on-parallel-file-system" title="Permalink to this headline">¶</a></h3>
<div class="section" id="technical-considerations">
<h4>Technical considerations<a class="headerlink" href="#technical-considerations" title="Permalink to this headline">¶</a></h4>
<p>On the computing center, parallel file systems are implemented with Lustre technology as follows:</p>
<ul class="simple">
<li>One <abbr title="MetaData Server">MDS</abbr> stores namespace metadata, such as file names, directories, access permissions, and file layout.</li>
<li>Multiple <abbr title="Object Storage Servers">OSSes</abbr> store file data.</li>
<li>Each supercomputer node is a <em>client</em> that accesses and uses the data.</li>
</ul>
<p>When a file is opened or created:</p>
<ol class="arabic simple">
<li>Supercomputer node requests it to the MDS.</li>
<li>The MDS performs a hand-shake between the supercomputer node and the OSSes.</li>
<li>The node can now read and/or write directly by transferring data to the OSSes.</li>
</ol>
<p>The important point is that <strong>all open, close and file name related calls from all the supercomputer nodes go to a unique server: the MDS</strong>.</p>
<p>These calls are often referred to as <em>meta-data calls</em> and too many of these calls can badly affect the overall performances of the file system.</p>
<p>The following sections provide data usage guidelines to ensure the good operation of the parallel file systems.</p>
</div>
<div class="section" id="big-files-vs-small-files">
<h4>Big files vs small files<a class="headerlink" href="#big-files-vs-small-files" title="Permalink to this headline">¶</a></h4>
<p>Lustre file system is optimized for bandwidth rather than latency.</p>
<ul class="simple">
<li>While manipulating small files, I/O performances are mainly latency-based (the hand-shakes with the MDS).</li>
<li>While manipulating big files, latency impact is considerably reduced.</li>
</ul>
<p>Thus, prefer having several big files instead of having many small files.</p>
</div>
<div class="section" id="number-of-files-per-directory">
<h4>Number of files per directory<a class="headerlink" href="#number-of-files-per-directory" title="Permalink to this headline">¶</a></h4>
<p>Many meta-data operations involve the MDS but also the OSSes.</p>
<p>Let us see with an example, a classic <strong class="command">ls -l</strong>, what happens behind the scene:</p>
<ol class="arabic simple">
<li>Client asks the MDS to list all files in the current directory.</li>
<li>The MDS lists the names of the files (sub-directories, regular files, etc.).</li>
<li>The MDS knows everything about the sub-directories.</li>
<li>But MDS does not know the sizes of non-directory files (nor the date of last modification)!</li>
<li>So for each file the MDS synchronizes with each OSSes involved (sum of sizes, max of the date of modification, etc.).</li>
</ol>
<p>Hence the more non-directory files you have within the directory, the slower the operation will be.</p>
<p>A similar scheme occurs to any file operation using <strong class="command">stat</strong> system call for each file, like done with <strong class="command">find</strong> or <strong class="command">du</strong> commands.</p>
<p>This is the main reason why many file operations become slower as the number of regular files within a directory increases.</p>
<ul class="simple">
<li>As a consequence, it is strongly advised to <strong>have less than 10.000 files per directory</strong>.</li>
<li>If you have more files, organize them into sub-directories (directories do not involve OSSes).</li>
</ul>
</div>
<div class="section" id="files-on-store">
<h4>Files on STORE<a class="headerlink" href="#files-on-store" title="Permalink to this headline">¶</a></h4>
<p>STORE is a Lustre file systems linked to a Hierarchical Storage Management (HSM) relying on a magnetic tape storage system.</p>
<p>Thus they share the constraints of Lustre file systems and those of the magnetic tape storage.</p>
<p>Because tape storage has a long latency and the number of tape readers are limited, having big files becomes nearly mandatory.</p>
<p>That’s why in order to reduce the time of retrieval :</p>
<ul class="simple">
<li><strong>each file should be bigger than 1GB</strong> (if needed, use <strong class="command">tar</strong> to aggregate your small files)</li>
<li><strong>each file should be less than 1TB</strong></li>
</ul>
<p>When you can manipulate the file size (e.g. using tarball), making it <strong>around 100GB</strong> is recommended. Practical experience shows that a 100GB file is quick to retrieve with <strong class="command">ccc_hsm get</strong> and subsequent manipulation or extraction is also fast.</p>
<p>You may use <strong class="command">ccc_quota</strong> to check file size statistics on STORE (they are updated daily).</p>
</div>
<div class="section" id="example-of-a-good-usage-of-filesystems">
<h4>Example of a good usage of filesystems<a class="headerlink" href="#example-of-a-good-usage-of-filesystems" title="Permalink to this headline">¶</a></h4>
<p>You have compiled your own program and installed it in your home directory under <code class="file docutils literal notranslate"><span class="pre">~/products</span></code>. In your home, your program will be safe. Also, you may use some user defined modules that you would create in <code class="file docutils literal notranslate"><span class="pre">~/products/modules/modulefiles</span></code> as described in <a class="reference internal" href="irene.html#extend-your-environment-with-modulefiles"><span class="std std-ref">Extend your environment with modulefiles</span></a>. It may simplify the use of your code. To avoid reaching the quota limit on the home, don’t use it by default for any work. The best place to write submission files and to launch your jobs would be the workdir. One of the advantages of the workdir is that it is shared between calculators. By launching your jobs from the workdir, you will be able to keep the submission scripts and the log files. Let us say the code generates lots of files, for example restart files, so that a new job can start where the last one stopped. In that case, the best is to launch the code on the scratchdir. It is the fastest and largest filesystem. However, data located on the scratchdir may be purged if they are not used for a while. Therefore, once your job ran successfully and you obtained the result files, you need to move them to an appropriate location if you want to keep them. That is the main purpose of the storedir. Once the job is finished, you can gather its result files in a big tar file that you shall copy on the storedir.</p>
<p>So, a typical job would be launched from the workdir, where the submission scripts are located. The job would go through the following steps :</p>
<ul class="simple">
<li>Create a temporary directory on the scratchdir and go to this directory</li>
<li>Untar large input files from the storedir to our directory in the scratchdir</li>
<li>Launch the code</li>
<li>Once it has finished running, check the results</li>
<li>If the results are not needed at the moment for other runs, make a tar of the useful files and copy the tar on the storedir</li>
<li>Remove the temporary directory</li>
</ul>
<p>Note that those steps are not compulsory and do not apply to every job. It is just one possible example of correct use of the different filesystems.</p>
</div>
</div>
<div class="section" id="parallel-compression-and-decompression-with-pigz">
<h3>Parallel compression and decompression with pigz<a class="headerlink" href="#parallel-compression-and-decompression-with-pigz" title="Permalink to this headline">¶</a></h3>
<p>Instead of using classical compression tools like <strong class="command">gzip</strong> (included by default with <strong class="command">tar</strong>), we recommend to use his parallel counterpart <strong class="command">pigz</strong> to get faster processing.</p>
<p>With this tool, we advise you to limit the number of threads used for compression between 4 and 8 to have a good performance / resources ratio. Increasing the number of threads should not dramatically improve performance and could even slow your compression. To speed up the process you may also adjust the compression level at the cost of reducing the compression quality. Decompression will be done by only one thread in any case and three more threads will be used for various purposes (read, write, check).</p>
<p>Please do not use this tool on login nodes, and prefer an interactive submission with <strong class="command">ccc_mprun -s</strong> or with a batch script.</p>
<p>Compression and decompression example using 6 threads:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -n 1</span>
<span class="c1">#MSUB -c 6</span>
module load pigz

<span class="c1"># compression:</span>
<span class="c1"># we are forced to create a wrapper around pigz if we want to use</span>
<span class="c1"># specific options to change the default behaviour of pigz.</span>
<span class="c1"># Note that &#39;$@&#39; is important because tar can pass arguments to pigz</span>
cat <span class="s">&lt;&lt;EOF &gt; pigz.sh</span>
<span class="s">#!/bin/bash</span>
<span class="s">pigz -p 6 \$@</span>
<span class="s">EOF</span>
chmod +x ./pigz.sh

tar -I ./pigz.sh -cf folder.tar.gz folder

<span class="c1"># decompression:</span>
tar -I pigz -xf folder.tar.gz
</pre></div>
</div>
<p>For additional information, please refer to the man-pages of the software:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ man pigz
</pre></div>
</div>
</div>
</div>
<span id="document-toc/fulldoc/Debugging"></span><div class="section" id="debugging">
<span id="id1"></span><h2>Debugging<a class="headerlink" href="#debugging" title="Permalink to this headline">¶</a></h2>
<p>Parallel applications are difficult to debug. Depending on the kind of problem, the type of parallelism, some tools may provide a great help in the debugging process.</p>
<div class="section" id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils" id="id2">
<caption><span class="caption-text">Supported programming model and functionality</span><a class="headerlink" href="#id2" title="Permalink to this table">¶</a></caption>
<colgroup>
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head stub">Name</th>
<th class="head">MPI</th>
<th class="head">OpenMP</th>
<th class="head">Cuda</th>
<th class="head">GUI</th>
<th class="head">Step by step</th>
<th class="head">Memory Debugging</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><th class="stub">Arm-forge DDT</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="row-odd"><th class="stub">Electric Fence</th>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
</tr>
<tr class="row-even"><th class="stub">GDB</th>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">Intel Inspector</th>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
</tr>
<tr class="row-even"><th class="stub">Totalview</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="row-odd"><th class="stub">Valgrind</th>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
</tr>
</tbody>
</table>
<p>To display a list of all available debuggers use the search option of the module command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module search debugger
</pre></div>
</div>
</div>
<div class="section" id="compiler-flags">
<h3>Compiler flags<a class="headerlink" href="#compiler-flags" title="Permalink to this headline">¶</a></h3>
<div class="section" id="common-flags">
<h4>Common flags<a class="headerlink" href="#common-flags" title="Permalink to this headline">¶</a></h4>
<p>To debug codes, you need to enable debug symbols. You get these symbols by compiling with the appropriate options:</p>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-g</span></code> to generate debug symbols usable by most debugging and profiling tools.</li>
<li>or <code class="xref std std-option docutils literal notranslate"><span class="pre">-g3</span></code> to generate even more debugging information (available for GNU and Intel, C, C++ or Fortran compilers).</li>
<li>and optionally <code class="xref std std-option docutils literal notranslate"><span class="pre">-O0</span></code> to avoid code optimization (this is strongly recommended for first debug sessions).</li>
</ul>
</div>
<div class="section" id="flags-for-fortran">
<h4>Flags for Fortran<a class="headerlink" href="#flags-for-fortran" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-traceback</span></code> with <strong class="command">ifort</strong> or <code class="xref std std-option docutils literal notranslate"><span class="pre">-fbacktrace</span></code> with <strong class="command">gfortran</strong>: specifies that a backtrace should be produced if the program crashes, showing which functions or subroutines were being called when the error occurs.</li>
</ul>
<p>For example, when getting a segmentation fault in Fortran, you may get the following error message which is not very useful:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">forrtl</span><span class="p">:</span> <span class="n">severe</span> <span class="p">(</span><span class="mi">174</span><span class="p">):</span> <span class="n">SIGSEGV</span><span class="p">,</span> <span class="n">segmentation</span> <span class="n">fault</span> <span class="n">occurred</span>
<span class="n">Image</span>    <span class="n">PC</span>               <span class="n">Routine</span> <span class="n">Line</span>    <span class="n">Source</span>
<span class="n">run_exe</span>  <span class="mi">000000010005</span><span class="n">EAC7</span> <span class="n">Unknown</span> <span class="n">Unknown</span> <span class="n">Unknown</span>
<span class="n">run_exe</span>  <span class="mi">000000010005</span><span class="n">DDA9</span> <span class="n">Unknown</span> <span class="n">Unknown</span> <span class="n">Unknown</span>
<span class="n">run_exe</span>  <span class="mi">00000001000009</span><span class="n">BC</span> <span class="n">Unknown</span> <span class="n">Unknown</span> <span class="n">Unknown</span>
<span class="n">run_exe</span>  <span class="mi">0000000100000954</span> <span class="n">Unknown</span> <span class="n">Unknown</span> <span class="n">Unknown</span>
</pre></div>
</div>
<p>A code compiled with <code class="xref std std-option docutils literal notranslate"><span class="pre">-fbacktrace</span></code> or <code class="xref std std-option docutils literal notranslate"><span class="pre">-traceback</span></code> will give a more relevant output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">forrtl</span><span class="p">:</span> <span class="n">severe</span> <span class="p">(</span><span class="mi">174</span><span class="p">):</span> <span class="n">SIGSEGV</span><span class="p">,</span> <span class="n">segmentation</span> <span class="n">fault</span> <span class="n">occurred</span>
<span class="n">Image</span>    <span class="n">PC</span>               <span class="n">Routine</span>   <span class="n">Line</span>    <span class="n">Source</span>
<span class="n">run_exe</span>  <span class="mi">000000010005</span><span class="n">EAC7</span> <span class="n">test_m_</span>   <span class="mi">265</span>     <span class="n">mod_test</span><span class="o">.</span><span class="n">f90</span>
<span class="n">run_exe</span>  <span class="mi">000000010005</span><span class="n">DDA9</span> <span class="n">io_</span>       <span class="mi">52</span>      <span class="n">io</span><span class="o">.</span><span class="n">f90</span>
<span class="n">run_exe</span>  <span class="mi">00000001000009</span><span class="n">BC</span> <span class="n">setup_</span>    <span class="mi">65</span>      <span class="n">test_Setup</span><span class="o">.</span><span class="n">f90</span>
<span class="n">run_exe</span>  <span class="mi">0000000100000954</span> <span class="n">main_</span>     <span class="mi">110</span>     <span class="n">launch</span><span class="o">.</span><span class="n">f90</span>
</pre></div>
</div>
<ul class="simple">
<li><code class="xref std std-option docutils literal notranslate"><span class="pre">-check</span> <span class="pre">bounds</span></code> with <strong class="command">ifort</strong> or <code class="xref std std-option docutils literal notranslate"><span class="pre">-fbounds-check</span></code> with <strong class="command">gfortran</strong>: checks that an index is within the bounds of the array each time an array element is accessed. This option is expected to substantially slow down program execution but is a convenient way to track down bugs related to arrays. Without this flag, an illegal array access would produce either a subtle error that might not become apparent until much later in the program or will cause an immediate segmentation fault with poor information on the origin of the error.</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Be careful. Most of these compiler options will slow down your code performances.</p>
</div>
</div>
</div>
<div class="section" id="available-debuggers">
<h3>Available debuggers<a class="headerlink" href="#available-debuggers" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>GDB: The GNU Project Debugger</li>
<li>DDT: Arm-forge Distributed Debugging Tool</li>
<li>TotalView: RogueWave TotalView Graphical Debugger</li>
</ul>
<div class="section" id="gdb">
<h4>GDB<a class="headerlink" href="#gdb" title="Permalink to this headline">¶</a></h4>
<p>GDB is the Gnu DeBugger. It is a lightweight simple serial debugger available on most systems.</p>
<p>To start a program under GDB, first make sure it is compiled with <code class="xref std std-option docutils literal notranslate"><span class="pre">-g</span></code>. Start a GDB session for your code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ gdb ./gdb_test
GNU gdb (GDB) Red Hat Enterprise Linux
Copyright (C) 2010 Free Software Foundation, Inc.
(gdb)
</pre></div>
</div>
<p>Once the GDB session is started, launch the code with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">gdb</span><span class="p">)</span> <span class="n">run</span>
</pre></div>
</div>
<p>If an error occurs, you will be able to get information with <strong class="command">backtrace</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Program</span> <span class="n">received</span> <span class="n">signal</span> <span class="n">SIGSEGV</span><span class="p">,</span> <span class="n">Segmentation</span> <span class="n">fault</span><span class="o">.</span>
<span class="p">(</span><span class="n">gdb</span><span class="p">)</span> <span class="n">backtrace</span>
<span class="c1">#0  0x00000000004005e0 in func1 (rank=1) at test.c:14</span>
<span class="c1">#1  0x0000000000400667 in main (argc=1, argv=0x7fffffffacc8) at test.c:30</span>
</pre></div>
</div>
<p>GDB allows to set breakpoints, run the code step by step and more. See <strong class="command">man gdb</strong> for more information and options.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">GDB only works for serial code. For parallel programs, other tools are available such as Arm-forge DDT and Totalview.</p>
</div>
</div>
<div class="section" id="ddt">
<h4>DDT<a class="headerlink" href="#ddt" title="Permalink to this headline">¶</a></h4>
<p>DDT is a highly scalable debugger specifically adapted to supercomputers.</p>
<div class="section" id="basics">
<h5>Basics<a class="headerlink" href="#basics" title="Permalink to this headline">¶</a></h5>
<p>You can use DDT after loading the appropriate module:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load arm-forge
</pre></div>
</div>
<p>Then use the command <strong class="command">ddt</strong>. For parallel codes, edit your submission script and replace the line</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n 16 ./a.out
</pre></div>
</div>
<p>with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ddt -n 16 ./a.out
</pre></div>
</div>
<p>You may want to add the <code class="xref std std-option docutils literal notranslate"><span class="pre">-noqueue</span></code> option to make sure DDT will not submit a new job to the scheduler. You have to specify the good version of the mpi distribution by selecting <strong>run</strong> and select <strong>SLURM (generic)</strong> implementation as shown on the figures below.</p>
<div class="figure align-default" id="id3">
<a class="reference internal image-reference" href="_images/Ddt0-1.png"><img alt="DDT opening window: choose 'Run'" src="_images/Ddt0-1.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">DDT opening window: choose ‘Run’</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id4">
<a class="reference internal image-reference" href="_images/Ddt0-2.png"><img alt="Choose 'change'" src="_images/Ddt0-2.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Choose ‘change’</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id5">
<a class="reference internal image-reference" href="_images/Ddt0-3.png"><img alt="Choose 'SLURM (generic)'" src="_images/Ddt0-3.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Choose ‘SLURM (generic)’</span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
<p>Example of submission script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cat ddt.job
#!/bin/bash
#MSUB -r MyJob_Para                # Request name
#MSUB -q partition                 # Queue
#MSUB -n 32                        # Number of tasks to use
#MSUB -T 1800                      # Elapsed time limit in seconds
#MSUB -o example_%I.o              # Standard output. %I is the job id
#MSUB -e example_%I.e              # Error output. %I is the job id
set -x
cd ${BRIDGE_MSUB_PWD}
ddt -n 32 ./ddt_test

$ ccc_msub -X ddt.job
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The <code class="xref std std-option docutils literal notranslate"><span class="pre">-X</span></code> option for <strong class="command">ccc_msub</strong> enables X11 forwarding.</p>
</div>
<div class="figure align-default" id="id6">
<a class="reference internal image-reference" href="_images/DDT1.png"><img alt="Example of DDT window" src="_images/DDT1.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Example of DDT window</span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Arm-forge DDT is a licensed product.</p>
</div>
<p>Check the output of <strong class="command">module show ddt</strong> or <strong class="command">module help ddt</strong> to get more information on the amount of licenses available.</p>
<p>A full documentation is available in the installation path on the cluster. To open it:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ evince ${ARMFORGE_ROOT}/doc/userguide-forge.pdf
</pre></div>
</div>
</div>
<div class="section" id="advanced-debug-mpmd-scripts">
<h5>Advanced: debug MPMD scripts<a class="headerlink" href="#advanced-debug-mpmd-scripts" title="Permalink to this headline">¶</a></h5>
<p>Prior to start <strong class="command">ddt</strong> you need to create an appropriate script in MPMD mode:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cat ddt.job
#!/bin/bash
#MSUB -r MyJob_Para                # Request name
#MSUB -q partition                 # Queue
#MSUB -n 4                         # Number of tasks to use
#MSUB -T 1800                      # Elapsed time limit in seconds
#MSUB -X
#MSUB -o example_%I.o              # Standard output. %I is the job id
#MSUB -e example_%I.e              # Error output. %I is the job id
set -x
cd ${BRIDGE_MSUB_PWD}

module load arm-forge
cat &lt;&lt; END &gt; exe.conf
1   env ddt-client ./algo1
3   env ddt-client ./algo2
END

ccc_mprun -f exe.conf
</pre></div>
</div>
<p>Now, as well as before, load the appropriate module:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load arm-forge
</pre></div>
</div>
<p>Then start <strong class="command">ddt</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ddt&amp;
</pre></div>
</div>
<p>Once ddt interface is visible, select <code class="docutils literal notranslate"><span class="pre">MANUAL</span> <span class="pre">LAUNCH</span></code>:</p>
<a class="reference internal image-reference" href="_images/ddt_started.png"><img alt="_images/ddt_started.png" src="_images/ddt_started.png" style="width: 600px;" /></a>
<p>Select the same number of processes that you choose on your script at <code class="code docutils literal notranslate"><span class="pre">#MSUB</span> <span class="pre">-n</span></code> (4 here) and press <code class="docutils literal notranslate"><span class="pre">Listen</span></code>:</p>
<a class="reference internal image-reference" href="_images/ddt_manual2.png"><img alt="_images/ddt_manual2.png" src="_images/ddt_manual2.png" style="width: 600px;" /></a>
<p>Then, launch your script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_msub -X ddt.job
</pre></div>
</div>
<p>Wait and your job will be automatically attach to <strong class="command">ddt</strong>. Now you have an an interface with <code class="docutils literal notranslate"><span class="pre">algo1</span></code> and <code class="docutils literal notranslate"><span class="pre">algo2</span></code> running at the same time:</p>
<a class="reference internal image-reference" href="_images/ddt_run.png"><img alt="_images/ddt_run.png" src="_images/ddt_run.png" style="width: 600px;" /></a>
</div>
</div>
<div class="section" id="totalview">
<h4>TotalView<a class="headerlink" href="#totalview" title="Permalink to this headline">¶</a></h4>
<p>TotalView may be used by loading a module and by submitting an appropriate job:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load totalview
</pre></div>
</div>
<p>Then launch your job with a submission script like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -r MyJob               # Request name
#MSUB -q partition           # Queue
#MSUB -n 8                   # Number of tasks to use
#MSUB -T 600
#MSUB -o totalview_%I.o        # Standard output. %I is the job id
#MSUB -e totalview_%I.e        # Error output. %I is the job id
set -x
cd ${BRIDGE_MSUB_PWD}
ccc_mprun -d tv ./totalview_test
</pre></div>
</div>
<p>It needs to be submitted with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_msub -X totalview.job
</pre></div>
</div>
<p>Totalview should open on the Startup Parameters window. There is nothing to change here, just hit <strong>OK</strong>. Once in the main window, you can either come back to the parameter window with “&lt;ctrl-a&gt;” or launch the code with “g”.</p>
<div class="figure align-default" id="id7">
<a class="reference internal image-reference" href="_images/Totalview.png"><img alt="Example of Totalview window" src="_images/Totalview.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Example of Totalview window</span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Totalview is a licensed product.</p>
</div>
<p>Check the output of <strong class="command">module show totalview</strong> or <strong class="command">module help totalview</strong> to get more information on the amount of licenses available.</p>
<p>A full documentation is available in the installation path on the cluster. To open it:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ evince ${TOTALVIEW_ROOT}/doc/pdf/TotalView_User_Guide.pdf
</pre></div>
</div>
</div>
</div>
<div class="section" id="other-tools">
<h3>Other tools<a class="headerlink" href="#other-tools" title="Permalink to this headline">¶</a></h3>
<div class="section" id="valgrind-memcheck">
<h4>Valgrind Memcheck<a class="headerlink" href="#valgrind-memcheck" title="Permalink to this headline">¶</a></h4>
<p>Valgrind is an instrumentation framework for dynamic analysis tools. It comes with a set of tools for profiling and debugging.</p>
<p>Memcheck is a memory error detector. It is the default use of Valgrind so any call to <strong class="command">valgrind</strong> is equivalent to calling</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ valgrind --tools=memcheck
</pre></div>
</div>
<p>To check your code with Valgrind, just call <strong class="command">valgrind</strong> before the program :</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load valgrind
$ valgrind ./test
</pre></div>
</div>
<p>To run MPI programs under Valgrind, use the available library “libmpiwrap” to filter false positives on MPI functions. It is available through the <span class="target" id="index-0"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">VALGRIND_PRELOAD</span></code> environment variable. It is also possible to specify the output file and to force Valgrind to output one file per process (with <code class="xref std std-option docutils literal notranslate"><span class="pre">--log-file</span></code>)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -n 32</span>
<span class="c1">#MSUB -T 1800</span>
<span class="c1">#MSUB -q partition</span>

module load valgrind

<span class="nb">export</span> <span class="nv">LD_PRELOAD</span><span class="o">=</span><span class="si">${</span><span class="nv">VALGRIND_PRELOAD</span><span class="si">}</span>

ccc_mprun valgrind --log-file<span class="o">=</span>valgrind_%q<span class="o">{</span>SLURM_JOBID<span class="o">}</span>_%q<span class="o">{</span>SLURM_PROCID<span class="o">}</span> ./test
</pre></div>
</div>
<p>Here is the kind of output Valgrind returns :</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">==</span><span class="mi">22860</span><span class="o">==</span> <span class="n">Invalid</span> <span class="n">write</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span>
<span class="o">==</span><span class="mi">22860</span><span class="o">==</span> <span class="n">at</span> <span class="mh">0x4005DD</span><span class="p">:</span> <span class="n">func1</span> <span class="p">(</span><span class="n">test1</span><span class="o">.</span><span class="n">c</span><span class="p">:</span><span class="mi">12</span><span class="p">)</span>
<span class="o">==</span><span class="mi">22860</span><span class="o">==</span> <span class="n">by</span> <span class="mh">0x40061E</span><span class="p">:</span> <span class="n">main</span> <span class="p">(</span><span class="n">test1</span><span class="o">.</span><span class="n">c</span><span class="p">:</span><span class="mi">20</span><span class="p">)</span>
<span class="o">==</span><span class="mi">22860</span><span class="o">==</span> <span class="n">Address</span> <span class="mh">0x4c11068</span> <span class="ow">is</span> <span class="mi">0</span> <span class="nb">bytes</span> <span class="n">after</span> <span class="n">a</span> <span class="n">block</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">40</span> <span class="n">alloc</span><span class="s1">&#39;d</span>
<span class="o">==</span><span class="mi">22860</span><span class="o">==</span> <span class="n">at</span> <span class="mh">0x4A05FDE</span><span class="p">:</span> <span class="n">malloc</span> <span class="p">(</span><span class="n">vg_replace_malloc</span><span class="o">.</span><span class="n">c</span><span class="p">:</span><span class="mi">236</span><span class="p">)</span>
<span class="o">==</span><span class="mi">22860</span><span class="o">==</span> <span class="n">by</span> <span class="mh">0x4005B0</span><span class="p">:</span> <span class="n">func1</span> <span class="p">(</span><span class="n">test1</span><span class="o">.</span><span class="n">c</span><span class="p">:</span><span class="mi">9</span><span class="p">)</span>
<span class="o">==</span><span class="mi">22860</span><span class="o">==</span> <span class="n">by</span> <span class="mh">0x40061E</span><span class="p">:</span> <span class="n">main</span> <span class="p">(</span><span class="n">test1</span><span class="o">.</span><span class="n">c</span><span class="p">:</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="electric-fence">
<h4>Electric Fence<a class="headerlink" href="#electric-fence" title="Permalink to this headline">¶</a></h4>
<p>Electric Fence helps you detect two common programming bugs: software that overruns the boundaries of a malloc() memory allocation, and software that touches a memory allocation that has been released by free(). Those errors do not always lead to a crash but may cause some unexpected behavior. Running your program with Electric Fence will force a segmentation fault (SIGSEGV) when any of these errors are detected, thus helping to detect the offending instruction.</p>
<p>The Electric Fence library can be loaded at runtime through <span class="target" id="index-1"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">LD_PRELOAD</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load electricfence
$ export LD_PRELOAD=${EF_PRELOAD}
$ ./a.out
</pre></div>
</div>
<p>The best way to proceed if a segfault occurs is to combine the use of Electric Fence with a debugger.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For parallel codes launched with <strong class="command">ccc_mprun</strong>, the <span class="target" id="index-2"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">LD_PRELOAD</span></code> does not need to be modified, just loading the module is enough.</p>
</div>
</div>
<div class="section" id="intel-inspector">
<h4>Intel Inspector<a class="headerlink" href="#intel-inspector" title="Permalink to this headline">¶</a></h4>
<p>Inspector is a memory and thread debugger developed by Intel which aim to help debug OpenMP programs. Because of the notion of shared memory, multi-threading comes with its own, very specific bugs. Intel Inspector will detect any deadlock or memory concurrency which will be hightlighted and identified in the source code via the GUI (Graphic User Interface).</p>
<p>To use it, you need to load the corresponding module as follow:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load inspector
</pre></div>
</div>
<p>Information is collected by launching the code with the command line tool. It needs to be done in a submission script or an interactive session. Never on the login nodes. There are two different analyse types characterized by three levels each which define the degree of the analysis and so the associated overhead (The highest level is most expensive consumer of time) :</p>
<ul class="simple">
<li>Memory analysis:<ul>
<li>mi1 : Detect Leaks</li>
<li>mi2 : Detect Memory Problems</li>
<li>mi3 : Locate Memory Problems</li>
</ul>
</li>
<li>Threading error analysis<ul>
<li>ti1 : Detect Deadlocks</li>
<li>ti2 : Detect Deadlocks and Data Races</li>
<li>ti3 : Locate Deadlocks and Data Races</li>
</ul>
</li>
</ul>
<p>Information analyse type and options are available under the command <strong class="command">inspxe-cl -help collect</strong></p>
<p>To launch the collection please proceed as follow :</p>
<p>Submission script example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#MSUB -r insp_code
#MSUB -q partition
#MSUB -n 28                # Number of task
#MSUB -c 1                 # Number of core per task
#MSUB -o inspe_code_%J.e   # Error output
#MSUB -e inspe_code_%J.o   # Output
#MSUB -x
ccc_mprun inspxe-cl -r mybinary_mi1 -collect mi1 -knob detect-leaks-on-exit=true -knob enable-memory-growth-detection=false -knob enable-on-demand-leak-detection=false -knob still-allocated-memory=true -knob stack-depth=8 -module-filter-mode=include -appdebug=off -no-trace-mpi -app-working-dir $PWD -- ./a.out #Do not forget the -r option
</pre></div>
</div>
<p>Once the collection is done, a file <code class="file docutils literal notranslate"><span class="pre">*.inspxe</span></code> should be created. Open it under the Intel Inspector GUI, preferably in an interactive session with X11 forwarding or with Remote Desktop session as follow:</p>
<p>Launch the gui:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$inspxe-gui
</pre></div>
</div>
<p>Select Open Result</p>
<div class="figure align-default" id="id8">
<a class="reference internal image-reference" href="_images/inspxe-5.png"><img alt="command line" src="_images/inspxe-5.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">command line</span><a class="headerlink" href="#id8" title="Permalink to this image">¶</a></p>
</div>
<p>Open the collected Data.</p>
<div class="figure align-default" id="id9">
<a class="reference internal image-reference" href="_images/inspxe-6.png"><img alt="collected data" src="_images/inspxe-6.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">collected data</span><a class="headerlink" href="#id9" title="Permalink to this image">¶</a></p>
</div>
<p>Then fix your code.</p>
<p><strong>Tips:</strong></p>
<p>To simply get the appropriate command line to launch, please proceed as follow.</p>
<p>First, launch inspector gui (<code class="xref std std-option docutils literal notranslate"><span class="pre">-XY</span></code> is needed).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ inspxe-gui
</pre></div>
</div>
<p>Create a new project:</p>
<div class="figure align-default" id="id10">
<a class="reference internal image-reference" href="_images/inspxe-1.png"><img alt="New project" src="_images/inspxe-1.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">New project</span><a class="headerlink" href="#id10" title="Permalink to this image">¶</a></p>
</div>
<p>Create a new analyse:</p>
<div class="figure align-default" id="id11">
<a class="reference internal image-reference" href="_images/inspxe-2.png"><img alt="New analysis" src="_images/inspxe-2.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">New analysis</span><a class="headerlink" href="#id11" title="Permalink to this image">¶</a></p>
</div>
<p>Select the analyse type</p>
<div class="figure align-default" id="id12">
<a class="reference internal image-reference" href="_images/inspxe-3.png"><img alt="analysis type" src="_images/inspxe-3.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">analysis type</span><a class="headerlink" href="#id12" title="Permalink to this image">¶</a></p>
</div>
<p>Get the comand line:</p>
<div class="figure align-default" id="id13">
<a class="reference internal image-reference" href="_images/inspxe-4.png"><img alt="command line" src="_images/inspxe-4.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">command line</span><a class="headerlink" href="#id13" title="Permalink to this image">¶</a></p>
</div>
<p>For more information, see the full <a class="reference external" href="https://software.intel.com/en-us/node/595380">Intel Inspector Documentation</a>.</p>
</div>
</div>
</div>
<span id="document-toc/fulldoc/Profiling"></span><div class="section" id="profiling">
<span id="id1"></span><h2>Profiling<a class="headerlink" href="#profiling" title="Permalink to this headline">¶</a></h2>
<div class="section" id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils" id="id7">
<caption><span class="caption-text">Supported programming model</span><a class="headerlink" href="#id7" title="Permalink to this table">¶</a></caption>
<colgroup>
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head stub">Name</th>
<th class="head">MPI</th>
<th class="head">OpenMP</th>
<th class="head">Cuda</th>
<th class="head">SIMD</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><th class="stub">Advisor</th>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
</tr>
<tr class="row-odd"><th class="stub">Allinea MAP</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="row-even"><th class="stub">Cube</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="row-odd"><th class="stub">Darshan</th>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Gprof</th>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">HPCToolkit</th>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Igprof</th>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">IPM</th>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Paraver</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">PAPI</th>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
</tr>
<tr class="row-even"><th class="stub">Perf</th>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
</tr>
<tr class="row-odd"><th class="stub">ScoreP</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Tau</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">Valgrind (cachegrind)</th>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Valgrind (callgrind)</th>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">Valgrind (massif)</th>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Vampir</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">Vtune</th>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
</tr>
</tbody>
</table>
<table border="1" class="docutils" id="id8">
<caption><span class="caption-text">Collectible events</span><a class="headerlink" href="#id8" title="Permalink to this table">¶</a></caption>
<colgroup>
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head stub">Name</th>
<th class="head">Comm</th>
<th class="head">I/O</th>
<th class="head">Call graph</th>
<th class="head">Hardware counters</th>
<th class="head">Memory usage</th>
<th class="head">Cache usage</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><th class="stub">Advisor</th>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">Allinea MAP</th>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Cube</th>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">Darshan</th>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Gprof</th>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">HPCToolkit</th>
<td>&#160;</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Igprof</th>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">IPM</th>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Paraver</th>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">PAPI</th>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="row-even"><th class="stub">Perf</th>
<td>&#160;</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="row-odd"><th class="stub">ScoreP</th>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="row-even"><th class="stub">Tau</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">Valgrind (cachegrind)</th>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
</tr>
<tr class="row-even"><th class="stub">Valgrind (callgrind)</th>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">Valgrind (massif)</th>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Vampir</th>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">Vtune</th>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
</tr>
</tbody>
</table>
<table border="1" class="docutils" id="id9">
<caption><span class="caption-text">Tool support and type of profiling</span><a class="headerlink" href="#id9" title="Permalink to this table">¶</a></caption>
<colgroup>
<col width="17%" />
<col width="17%" />
<col width="17%" />
<col width="17%" />
<col width="17%" />
<col width="17%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head stub">Name</th>
<th class="head">Collection</th>
<th class="head">GUI</th>
<th class="head">Sampling</th>
<th class="head">Tracing</th>
<th class="head">Instrumentation necessary</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><th class="stub">Advisor</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">Allinea MAP</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Cube</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">Darshan</th>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Gprof</th>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="row-odd"><th class="stub">HPCToolkit</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Igprof</th>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">IPM</th>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Paraver</th>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="row-odd"><th class="stub">PAPI</th>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
</tr>
<tr class="row-even"><th class="stub">Perf</th>
<td>&#160;</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">ScoreP</th>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="row-even"><th class="stub">Tau</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">Valgrind (cachegrind)</th>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Valgrind (callgrind)</th>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><th class="stub">Valgrind (massif)</th>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><th class="stub">Vampir</th>
<td>&#160;</td>
<td>✓</td>
<td>&#160;</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="row-odd"><th class="stub">Vtune</th>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<p>To display a list of all available profilers use the <code class="xref std std-option docutils literal notranslate"><span class="pre">search</span></code> option of the <strong class="command">module</strong> command :</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module search profiler
</pre></div>
</div>
</div>
<div class="section" id="ipm">
<h3>IPM<a class="headerlink" href="#ipm" title="Permalink to this headline">¶</a></h3>
<p>IPM is a light-weight profiling tool that profiles the mpi calls and memory usage in a parallel program.</p>
<p>To run a program with IPM profiling, just load the <strong>ipm module</strong> (no need to instrument or recompile anything) and run it with :</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -r MyJob_Para                # Request name
#MSUB -n 32                        # Number of tasks to use
#MSUB -T 1800                      # Elapsed time limit in seconds
#MSUB -o example_%I.o              # Standard output. %I is the job id
#MSUB -e example_%I.e              # Error output. %I is the job id
#MSUB -q partition                 # Queue

set -x
cd ${BRIDGE_MSUB_PWD}

module load ipm

#The ipm module tells ccc_mprun to use IPM library
ccc_mprun ./prog.exe
</pre></div>
</div>
<p>It will generate a report at the end of the standard output of the job and an <strong>xml file</strong>. It is possible to generate a graphical and complete html page with the command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ipm_parse -html XML_File
</pre></div>
</div>
<p>Example of IPM output</p>
<a class="reference internal image-reference" href="_images/IPM_pdf2.png"><img alt="Example of IPM output" src="_images/IPM_pdf2.png" style="width: 400px;" /></a>
<p>Example of IPM output</p>
<a class="reference internal image-reference" href="_images/IPM_pdf.png"><img alt="image1" src="_images/IPM_pdf.png" style="width: 600px;" /></a>
</div>
<div class="section" id="darshan">
<h3>Darshan<a class="headerlink" href="#darshan" title="Permalink to this headline">¶</a></h3>
<p>Darshan is a scalable HPC I/O characterization tool. It is designed to profile I/O behavior with minimum overhead.</p>
<p>To run a program with Darshan profiling, there is no need to instrument or recompile the code.</p>
<ul class="simple">
<li>Load the <strong>darshan module</strong> : it tells <strong class="command">ccc_mprun</strong> to wrap the I/O calls with the Darshan library.</li>
<li>Specify where you want the darshan trace to be created by exporting the variable <span class="target" id="index-0"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">DARSHAN_LOG_PATH</span></code>.</li>
</ul>
<p>Here is an example of a submission script to enable darshan profiling:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -r MyJob_Para                # Request name
#MSUB -n 32                        # Number of tasks to use
#MSUB -T 1800                      # Elapsed time limit in seconds
#MSUB -o example_%I.o              # Standard output. %I is the job id
#MSUB -e example_%I.e              # Error output. %I is the job id
#MSUB -q partition                 # Queue

set -x
cd ${BRIDGE_MSUB_PWD}

module load darshan
export DARSHAN_LOG_PATH=$PWD

#The darshan module tells ccc_mprun to use the Darshan library.
ccc_mprun ./prog.exe
</pre></div>
</div>
<p>This will generate a trace in the specified directory. Here is the format of the output file: <code class="file docutils literal notranslate"><span class="pre">&lt;USERNAME&gt;_&lt;BINARY_NAME&gt;_&lt;JOB_ID&gt;_&lt;DATE&gt;_&lt;UNIQUE_ID&gt;_&lt;TIMING&gt;.darshan.gz</span></code>.</p>
<p>Some scripts are available to post-process the output. For instance, <strong class="command">darshan-parser</strong>, <strong class="command">darshan-job-summary.pl</strong> and <strong class="command">darshan-summary-per-file.sh</strong>.</p>
<ul class="simple">
<li><strong class="command">darshan-job-summary.pl</strong> will generate a graphical summary of the I/O activity for a job.</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ darshan-job-summary.pl *.darshan.gz
</pre></div>
</div>
<ul class="simple">
<li><strong class="command">darshan-summary-per-file.sh</strong> is similar except that it produces a separate pdf summary for every file accessed by the application. The summaries will be written in the directory specified as argument.</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ darshan-summary-per-file.sh *.darshan.gz output_dir
</pre></div>
</div>
<ul class="simple">
<li><strong class="command">darshan-parser</strong> gives a full, human readable dump of all information contained in a log file.</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ darshan-parser *.darshan.gz &gt; example_output.txt
</pre></div>
</div>
<div class="figure align-default" id="id10">
<a class="reference internal image-reference" href="_images/Darshan_pdf.png"><img alt="Example of Darshan output" src="_images/Darshan_pdf.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Example of Darshan output</span><a class="headerlink" href="#id10" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="arm-forge-map">
<h3>Arm-forge MAP<a class="headerlink" href="#arm-forge-map" title="Permalink to this headline">¶</a></h3>
<p>Arm-forge MAP is the profiler for parallel, multithreaded or single threaded C, C++ and F90 codes. MAP gives information on memory usage, MPI and OpenMP usage, percentage of vectorized SIMD instructions, etc.</p>
<div class="figure align-default" id="id11">
<a class="reference internal image-reference" href="_images/AllineaMAP.png"><img alt="Example of MAP profile" src="_images/AllineaMAP.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Example of MAP profile</span><a class="headerlink" href="#id11" title="Permalink to this image">¶</a></p>
</div>
<p>The code just has to be compiled with -g for debugging information. No instrumentation is needed.</p>
<p>You can profile your code with map by loading the appropriate module:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load arm-forge
</pre></div>
</div>
<p>Then use the command <strong class="command">map -profile</strong>. For parallel codes, edit your submission script and just replace <strong class="command">ccc_mprun</strong> with <strong class="command">map -profile</strong>.</p>
<p>Example of submission script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -r MyJob_Para                # Request name
#MSUB -q partition                 # Queue
#MSUB -n 32                        # Number of tasks to use
#MSUB -T 1800                      # Elapsed time limit in seconds
#MSUB -o example_%I.o              # Standard output. %I is the job id
#MSUB -e example_%I.e              # Error output. %I is the job id
set -x
cd ${BRIDGE_MSUB_PWD}

module load arm-forge
map -n 32 ./a.out
</pre></div>
</div>
<p>Once the job has finished, a <code class="file docutils literal notranslate"><span class="pre">.map</span></code> file should have been created. It can be opened from a remote desktop session or from an interactive session with the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ map &lt;output_name&gt;.map
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Arm-forge MAP is a licenced product.</p>
</div>
<p>Check the output of <strong class="command">module show arm-forge</strong> or <strong class="command">module help arm-forge</strong> to get more information on the amount of licences available.</p>
<p>A full documentation is available in the installation path on the cluster. To open it:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ evince ${MAP_ROOT}/doc/userguide-forge.pdf
</pre></div>
</div>
</div>
<div class="section" id="gprof">
<h3>Gprof<a class="headerlink" href="#gprof" title="Permalink to this headline">¶</a></h3>
<p>Gprof produces an execution profile of C/C++ and Fortran programs. The effect of called routines is incorporated in the profile of each caller. The profile data is taken from the call graph profile file (gmon.out default) which is created by programs that are compiled with the -pg option. Gprof reads the given object file (the default is “a.out”) and establishes the relation between its symbol table and the call graph profile from gmon.out.</p>
<ul class="simple">
<li>To load gprof</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load gprof
</pre></div>
</div>
<ul class="simple">
<li>To compile with <code class="xref std std-option docutils literal notranslate"><span class="pre">-pg</span></code> option</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ icc -pg hello.c
</pre></div>
</div>
<ul class="simple">
<li>If your application is MPI, set environment variable to rename gmon files and enable one file per process</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ export GMON_OUT_PREFIX=&#39;gmon.out-&#39;`/bin/uname -n`
</pre></div>
</div>
<p>Files generated will be named <code class="file docutils literal notranslate"><span class="pre">gmon.out-&lt;hostname&gt;.&lt;pid&gt;</span></code> (ie: <code class="file docutils literal notranslate"><span class="pre">gmon.out-node1192.56893</span></code>).</p>
<ul class="simple">
<li>To generate call graph profile <code class="file docutils literal notranslate"><span class="pre">gmon.out</span></code></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ./a.out
</pre></div>
</div>
<ul class="simple">
<li>To display flat profile and call graph</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ gprof a.out gmon.out
</pre></div>
</div>
<ul class="simple">
<li>To display only the flat profile</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ gprof -p -b ./a.out gmon.out

Flat profile:
Each sample counts as 0.01 seconds.
 %   cumulative   self              self     total
time   seconds   seconds    calls   s/call   s/call  name
67.72     10.24    10.24        1    10.24    10.24  bar
33.06     15.24     5.00                             main
 0.00     15.24     0.00        1     0.00    10.24  foo
</pre></div>
</div>
<ul class="simple">
<li>To display the flat profile of one specific routine</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ gprof -p&lt;routine&gt; -b ./a.out gmon.out
</pre></div>
</div>
<ul class="simple">
<li>To display only the call graph</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ gprof -q -b ./a.out gmon.out

Call graph (explanation follows)
index % time    self  children    called     name
                                                &lt;spontaneous&gt;
[1]    100.0    5.00   10.24                 main [1]
                0.00   10.24       1/1           foo [3]
-----------------------------------------------
               10.24    0.00       1/1           foo [3]
[2]     67.2   10.24    0.00       1         bar [2]
-----------------------------------------------
               0.00   10.24       1/1           main [1]
[3]     67.2   0.00   10.24        1         foo [3]
               10.24    0.00       1/1           bar [2]
-----------------------------------------------
</pre></div>
</div>
<ul class="simple">
<li>To display the call graph of one specific routine</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ gprof -q&lt;routine&gt; -b ./a.out gmon.out
</pre></div>
</div>
<ul class="simple">
<li>To generate a graph from data, see <a class="reference internal" href="#use-with-gprof"><span class="std std-ref">gprof2dot and gprof</span></a></li>
</ul>
</div>
<div class="section" id="igprof">
<h3>igprof<a class="headerlink" href="#igprof" title="Permalink to this headline">¶</a></h3>
<p>IgProf is a tool for measuring and analysing application memory and performance characteristics. To run a program with IgProf profiling, there is no need to instrument or recompile the code.</p>
<ul class="simple">
<li>To load igprof</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">igprof</span>
</pre></div>
</div>
<ul class="simple">
<li>To generate the memory trace</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">igprof</span> <span class="o">-</span><span class="n">d</span> <span class="o">-</span><span class="n">mp</span> <span class="o">-</span><span class="n">z</span> <span class="o">-</span><span class="n">o</span> <span class="n">igprof</span><span class="o">.</span><span class="n">mp</span><span class="o">.</span><span class="n">gz</span> <span class="n">myApp</span> <span class="p">[</span><span class="n">arg1</span> <span class="n">arg2</span> <span class="o">...</span><span class="p">]</span> <span class="o">&gt;&amp;</span> <span class="n">igtest</span><span class="o">.</span><span class="n">mp</span><span class="o">.</span><span class="n">log</span>
</pre></div>
</div>
<ul class="simple">
<li>To see unfreed memory, extract the <strong>MEM_LIVE</strong> report from the <strong>memory trace</strong> with:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">igprof</span><span class="o">-</span><span class="n">analyse</span> <span class="o">-</span><span class="n">d</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">g</span> <span class="o">-</span><span class="n">r</span> <span class="n">MEM_LIVE</span> <span class="n">igprof</span><span class="o">.</span><span class="n">mp</span><span class="o">.</span><span class="n">gz</span> <span class="o">&gt;</span> <span class="n">igreport_live</span><span class="o">.</span><span class="n">res</span>
</pre></div>
</div>
<ul class="simple">
<li>To see which routines have the most memory usage, extract the <strong>MEM_TOTAL</strong> report from the <strong>memory trace</strong> with:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">igprof</span><span class="o">-</span><span class="n">analyse</span> <span class="o">-</span><span class="n">d</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">g</span> <span class="o">-</span><span class="n">r</span> <span class="n">MEM_TOTAL</span> <span class="n">igprof</span><span class="o">.</span><span class="n">mp</span><span class="o">.</span><span class="n">gz</span> <span class="o">&gt;</span> <span class="n">igreport_total</span><span class="o">.</span><span class="n">res</span>
</pre></div>
</div>
<ul class="simple">
<li>See <a class="reference external" href="http://igprof.org/analysis.html">the manual</a> for full details</li>
<li>Example of output:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Counter</span><span class="p">:</span> <span class="n">MEM_TOTAL</span>

<span class="o">----------------------------------------------------------------------</span>
<span class="n">Flat</span> <span class="n">profile</span> <span class="p">(</span><span class="n">cumulative</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="o">%</span><span class="p">)</span>

<span class="o">%</span> <span class="n">total</span>     <span class="n">Total</span>     <span class="n">Calls</span>  <span class="n">Function</span>
  <span class="mf">100.0</span>     <span class="mi">2</span><span class="s1">&#39;416         3  &lt;spontaneous&gt; [1]</span>
  <span class="mf">100.0</span>     <span class="mi">2</span><span class="s1">&#39;416         3  _start [2]</span>
  <span class="mf">100.0</span>     <span class="mi">2</span><span class="s1">&#39;416         3  __libc_start_main [3]</span>
  <span class="mf">100.0</span>     <span class="mi">2</span><span class="s1">&#39;416         3  main [4]</span>
   <span class="mf">99.3</span>     <span class="mi">2</span><span class="s1">&#39;400         2  MAIN__ [5]</span>
   <span class="mf">99.3</span>     <span class="mi">2</span><span class="s1">&#39;400         2  for_alloc_allocatable [6]</span>
   <span class="mf">82.8</span>     <span class="mi">2</span><span class="s1">&#39;000         1  main_IP_b_ [7]</span>
    <span class="mf">0.7</span>        <span class="mi">16</span>         <span class="mi">1</span>  <span class="n">for_rtl_init_</span> <span class="p">[</span><span class="mi">8</span><span class="p">]</span>


<span class="o">----------------------------------------------------------------------</span>
<span class="n">Flat</span> <span class="n">profile</span> <span class="p">(</span><span class="bp">self</span> <span class="o">&gt;=</span> <span class="mf">0.01</span><span class="o">%</span><span class="p">)</span>

<span class="o">%</span> <span class="n">total</span>      <span class="n">Self</span>     <span class="n">Calls</span>  <span class="n">Function</span>
  <span class="mf">99.34</span>     <span class="mi">2</span><span class="s1">&#39;400         2  for_alloc_allocatable [6]</span>
   <span class="mf">0.66</span>        <span class="mi">16</span>         <span class="mi">1</span>  <span class="n">for__get_vm</span> <span class="p">[</span><span class="mi">9</span><span class="p">]</span>
   <span class="mf">0.00</span>         <span class="mi">0</span>         <span class="mi">0</span>  <span class="o">&lt;</span><span class="n">spontaneous</span><span class="o">&gt;</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>


<span class="o">----------------------------------------------------------------------</span>
<span class="n">Call</span> <span class="n">tree</span> <span class="n">profile</span> <span class="p">(</span><span class="n">cumulative</span><span class="p">)</span>

<span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span> <span class="o">-</span>
<span class="n">Rank</span>    <span class="o">%</span> <span class="n">total</span>      <span class="n">Self</span>      <span class="n">Self</span> <span class="o">/</span> <span class="n">Children</span>     <span class="n">Calls</span> <span class="o">/</span> <span class="n">Total</span>     <span class="n">Function</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span>       <span class="mf">100.0</span>     <span class="mi">2</span><span class="s1">&#39;416         0 / 2&#39;</span><span class="mi">416</span>            <span class="mi">3</span>             <span class="o">&lt;</span><span class="n">spontaneous</span><span class="o">&gt;</span>
          <span class="mf">100.0</span>  <span class="o">........</span>     <span class="mi">2</span><span class="s1">&#39;416 / 2&#39;</span><span class="mi">416</span>            <span class="mi">3</span> <span class="o">/</span> <span class="mi">3</span>           <span class="n">_start</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="o">...</span><span class="n">TRUNCATED</span><span class="o">...</span>
</pre></div>
</div>
</div>
<div class="section" id="papi">
<h3>PAPI<a class="headerlink" href="#papi" title="Permalink to this headline">¶</a></h3>
<p>PAPI is an API which allows you to retrieve hardware counters from the CPU. Here an example in Fortran to get the number of floating point operations of a matrix DAXPY:</p>
<div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="k">program </span><span class="n">main</span>
 <span class="k">implicit none</span>
<span class="k"> include</span> <span class="s1">&#39;f90papi.h&#39;</span>
 <span class="c">!</span>
 <span class="kt">integer</span><span class="p">,</span> <span class="k">parameter</span> <span class="kd">::</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">1000</span>
 <span class="kt">integer</span><span class="p">,</span> <span class="k">parameter</span> <span class="kd">::</span> <span class="n">ntimes</span> <span class="o">=</span> <span class="mi">10</span>
 <span class="kt">double precision</span><span class="p">,</span> <span class="k">dimension</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="n">size</span><span class="p">)</span> <span class="kd">::</span> <span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">C</span>
 <span class="kt">integer</span> <span class="kd">::</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">n</span>
 <span class="c">! Variable PAPI</span>
 <span class="kt">integer</span><span class="p">,</span> <span class="k">parameter</span> <span class="kd">::</span> <span class="n">max_event</span> <span class="o">=</span> <span class="mi">1</span>
 <span class="kt">integer</span><span class="p">,</span> <span class="k">dimension</span><span class="p">(</span><span class="n">max_event</span><span class="p">)</span> <span class="kd">::</span> <span class="n">event</span>
 <span class="kt">integer</span> <span class="kd">::</span> <span class="n">num_events</span><span class="p">,</span> <span class="n">retval</span>
 <span class="kt">integer</span><span class="p">(</span><span class="nb">kind</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span> <span class="k">dimension</span><span class="p">(</span><span class="n">max_event</span><span class="p">)</span> <span class="kd">::</span> <span class="n">values</span>
 <span class="c">! Init PAPI</span>
 <span class="k">call </span><span class="n">PAPIf_num_counters</span><span class="p">(</span> <span class="n">num_events</span> <span class="p">)</span>
 <span class="k">print</span> <span class="o">*</span><span class="p">,</span> <span class="s1">&#39;Number of hardware counters supported: &#39;</span><span class="p">,</span> <span class="n">num_events</span>
 <span class="k">call </span><span class="n">PAPIf_query_event</span><span class="p">(</span><span class="n">PAPI_FP_INS</span><span class="p">,</span> <span class="n">retval</span><span class="p">)</span>
 <span class="k">if</span> <span class="p">(</span><span class="n">retval</span> <span class="p">.</span><span class="n">NE</span><span class="p">.</span> <span class="n">PAPI_OK</span><span class="p">)</span> <span class="k">then</span>
<span class="k">    </span><span class="n">event</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">PAPI_TOT_INS</span>
 <span class="k">else</span>
    <span class="c">! Total floating point operations</span>
    <span class="n">event</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">PAPI_FP_INS</span>
 <span class="k">end if</span>
 <span class="c">! Init Matrix</span>
 <span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span>
    <span class="k">do </span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span>
       <span class="n">C</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span> <span class="o">=</span> <span class="kt">real</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="n">j</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
       <span class="n">B</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span> <span class="o">=</span> <span class="o">-</span><span class="n">i</span><span class="o">+</span><span class="mf">0.1</span><span class="o">*</span><span class="n">j</span>
    <span class="k">end do</span>
<span class="k"> end do</span>
 <span class="c">! Set up counters</span>
 <span class="n">num_events</span> <span class="o">=</span> <span class="mi">1</span>
 <span class="k">call </span><span class="n">PAPIf_start_counters</span><span class="p">(</span> <span class="n">event</span><span class="p">,</span> <span class="n">num_events</span><span class="p">,</span> <span class="n">retval</span><span class="p">)</span>
 <span class="c">! Clear the counter values</span>
 <span class="k">call </span><span class="n">PAPIf_read_counters</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">num_events</span><span class="p">,</span><span class="n">retval</span><span class="p">)</span>
 <span class="c">! DAXPY</span>
 <span class="k">do </span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ntimes</span>
    <span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span>
       <span class="k">do </span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span>
          <span class="n">A</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span> <span class="o">=</span> <span class="mf">2.0</span><span class="o">*</span><span class="n">B</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span> <span class="o">+</span> <span class="n">C</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
       <span class="k">end do</span>
<span class="k">    end do</span>
<span class="k"> end do</span>
 <span class="c">! Stop the counters and put the results in the array values</span>
 <span class="k">call </span><span class="n">PAPIf_stop_counters</span><span class="p">(</span><span class="n">values</span><span class="p">,</span><span class="n">num_events</span><span class="p">,</span><span class="n">retval</span><span class="p">)</span>
 <span class="c">! Print results</span>
 <span class="k">if</span> <span class="p">(</span><span class="n">event</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">.</span><span class="n">EQ</span><span class="p">.</span> <span class="n">PAPI_TOT_INS</span><span class="p">)</span> <span class="k">then</span>
<span class="k">    print</span> <span class="o">*</span><span class="p">,</span> <span class="s1">&#39;TOT Instructions:  &#39;</span><span class="p">,</span><span class="n">values</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
 <span class="k">else</span>
<span class="k">    print</span> <span class="o">*</span><span class="p">,</span> <span class="s1">&#39;FP Instructions:  &#39;</span><span class="p">,</span><span class="n">values</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
 <span class="k">end if</span>
<span class="k">end program </span><span class="n">main</span>
</pre></div>
</div>
<p>To compile, you have to load the PAPI module:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>bash-4.00 $ module load papi/4.2.1
bash-4.00 $ ifort ${PAPI_CFLAGS} papi.f90 ${PAPI_LDFLAGS}
bash-4.00 $ ./a.out
 Number of hardware counters supported:            7
 FP Instructions:                10046163
</pre></div>
</div>
<p>To get the available hardware counters, you can type <strong class="command">papi_avail</strong> command.</p>
<p>This library can retrieve the MFLOPS of a certain region of your code:</p>
<div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="k">program </span><span class="n">main</span>
 <span class="k">implicit none</span>
<span class="k"> include</span> <span class="s1">&#39;f90papi.h&#39;</span>
 <span class="c">!</span>
 <span class="kt">integer</span><span class="p">,</span> <span class="k">parameter</span> <span class="kd">::</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">1000</span>
 <span class="kt">integer</span><span class="p">,</span> <span class="k">parameter</span> <span class="kd">::</span> <span class="n">ntimes</span> <span class="o">=</span> <span class="mi">100</span>
 <span class="kt">double precision</span><span class="p">,</span> <span class="k">dimension</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="n">size</span><span class="p">)</span> <span class="kd">::</span> <span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">C</span>
 <span class="kt">integer</span> <span class="kd">::</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">n</span>
 <span class="c">! Variable PAPI</span>
 <span class="kt">integer</span> <span class="kd">::</span> <span class="n">retval</span>
 <span class="kt">real</span><span class="p">(</span><span class="nb">kind</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="kd">::</span> <span class="n">proc_time</span><span class="p">,</span> <span class="n">mflops</span><span class="p">,</span> <span class="n">real_time</span>
 <span class="kt">integer</span><span class="p">(</span><span class="nb">kind</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> <span class="kd">::</span>  <span class="n">flpins</span>
 <span class="c">! Init PAPI</span>
 <span class="n">retval</span> <span class="o">=</span> <span class="n">PAPI_VER_CURRENT</span>
 <span class="k">call </span><span class="n">PAPIf_library_init</span><span class="p">(</span><span class="n">retval</span><span class="p">)</span>
 <span class="k">if</span> <span class="p">(</span> <span class="n">retval</span><span class="p">.</span><span class="n">NE</span><span class="p">.</span><span class="n">PAPI_VER_CURRENT</span><span class="p">)</span> <span class="k">then</span>
<span class="k">    print</span><span class="o">*</span><span class="p">,</span> <span class="s1">&#39;PAPI_library_init&#39;</span><span class="p">,</span> <span class="n">retval</span>
 <span class="k">end if</span>
<span class="k"> call </span><span class="n">PAPIf_query_event</span><span class="p">(</span><span class="n">PAPI_FP_INS</span><span class="p">,</span> <span class="n">retval</span><span class="p">)</span>
 <span class="c">! Init Matrix</span>
 <span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span>
    <span class="k">do </span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span>
       <span class="n">C</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span> <span class="o">=</span> <span class="kt">real</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="n">j</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
       <span class="n">B</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span> <span class="o">=</span> <span class="o">-</span><span class="n">i</span><span class="o">+</span><span class="mf">0.1</span><span class="o">*</span><span class="n">j</span>
    <span class="k">end do</span>
<span class="k"> end do</span>
 <span class="c">! Setup Counter</span>
 <span class="k">call </span><span class="n">PAPIf_flips</span><span class="p">(</span> <span class="n">real_time</span><span class="p">,</span> <span class="n">proc_time</span><span class="p">,</span> <span class="n">flpins</span><span class="p">,</span> <span class="n">mflops</span><span class="p">,</span> <span class="n">retval</span> <span class="p">)</span>
 <span class="c">! DAXPY</span>
 <span class="k">do </span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ntimes</span>
    <span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span>
       <span class="k">do </span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span>
          <span class="n">A</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span> <span class="o">=</span> <span class="mf">2.0</span><span class="o">*</span><span class="n">B</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span> <span class="o">+</span> <span class="n">C</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
       <span class="k">end do</span>
<span class="k">    end do</span>
<span class="k"> end do</span>
 <span class="c">! Collect the data into the Variables passed in</span>
 <span class="k">call </span><span class="n">PAPIf_flips</span><span class="p">(</span> <span class="n">real_time</span><span class="p">,</span> <span class="n">proc_time</span><span class="p">,</span> <span class="n">flpins</span><span class="p">,</span> <span class="n">mflops</span><span class="p">,</span> <span class="n">retval</span><span class="p">)</span>
 <span class="c">! Print results</span>
 <span class="k">print</span> <span class="o">*</span><span class="p">,</span> <span class="s1">&#39;Real_time: &#39;</span><span class="p">,</span> <span class="n">real_time</span>
 <span class="k">print</span> <span class="o">*</span><span class="p">,</span> <span class="s1">&#39; Proc_time: &#39;</span><span class="p">,</span> <span class="n">proc_time</span>
 <span class="k">print</span> <span class="o">*</span><span class="p">,</span> <span class="s1">&#39; Total flpins: &#39;</span><span class="p">,</span> <span class="n">flpins</span>
 <span class="k">print</span> <span class="o">*</span><span class="p">,</span> <span class="s1">&#39; MFLOPS: &#39;</span><span class="p">,</span> <span class="n">mflops</span>
 <span class="c">!</span>
<span class="k">end program </span><span class="n">main</span>
</pre></div>
</div>
<p>and the output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>bash-4.00 $ module load papi/4.2.1
bash-4.00 $ ifort ${PAPI_CFLAGS} papi_flops.f90 ${PAPI_LDFLAGS}
bash-4.00 $ ./a.out
 Real_time:   6.1250001E-02
  Proc_time:   5.1447589E-02
  Total flpins:              100056592
  MFLOPS:    1944.826
</pre></div>
</div>
<p>If you want more precisions, you can contact us or visit PAPI website.</p>
</div>
<div class="section" id="scalasca">
<h3>Scalasca<a class="headerlink" href="#scalasca" title="Permalink to this headline">¶</a></h3>
<p><strong class="program">Scalasca</strong> is a set of software which let you profile your parallel code by taking traces during the execution of the program. It is actually a wrapper that launches <strong class="program">Score-P</strong> and <strong class="program">Cube</strong>. This software is a kind of parallel <strong class="program">gprof</strong> with more information. We present here an introduction of <strong class="program">Scalasca</strong>. The generated output can then be opened with several analysis tools like <strong class="program">Periscope</strong>, <strong class="program">Cube</strong>, <strong class="program">Vampir</strong>, or <strong class="program">Tau</strong>.</p>
<p>Scalasca profiling requires 3 different steps:</p>
<ul class="simple">
<li>Instrumenting the code with <strong class="command">skin</strong></li>
<li>Collecting profiling data with <strong class="command">scan</strong></li>
<li>Examine collected information with <strong class="command">square</strong></li>
</ul>
<div class="section" id="code-instrumentation-with-scalasca">
<h4>Code instrumentation with Scalasca<a class="headerlink" href="#code-instrumentation-with-scalasca" title="Permalink to this headline">¶</a></h4>
<p>First step for profiling a code with is instrumentation. You must compile your code by adding the wrapper before the call to the compiler. You need to load the <strong class="command">scalasca</strong> module beforehand :</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load scalasca
$ skin mpicc -g -c prog.c
$ skin mpicc -o prog.exe prog.o
</pre></div>
</div>
<p>or for Fortran :</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load scalasca
$ skin mpif90 -g -c prog.f90
$ skin mpif90 -o prog.exe prog.o
</pre></div>
</div>
<p>You can compile for OpenMP programs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ skin ifort -openmp -g -c prog.f90
$ skin ifort -openmp -o prog.exe prog.o
</pre></div>
</div>
<p>You can profile hybrid MPI-OpenMP programs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ skin mpif90 -openmp -g -O3 -c prog.f90
$ skin mpif90 -openmp -g -O3 -o prog.exe prog.o
</pre></div>
</div>
</div>
<div class="section" id="simple-profiling-with-scalasca">
<h4>Simple profiling with Scalasca<a class="headerlink" href="#simple-profiling-with-scalasca" title="Permalink to this headline">¶</a></h4>
<p>Once the code has been instrumented with <strong class="program">Scalasca</strong>, run it with <strong class="command">scan</strong>. By default, a simple summary profile is generated.</p>
<p>Here is a simple example of a submission script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -r MyJob_Para                # Request name
#MSUB -n 32                        # Number of tasks to use
#MSUB -T 1800                      # Elapsed time limit in seconds
#MSUB -o example_%I.o              # Standard output. %I is the job id
#MSUB -e example_%I.e              # Error output. %I is the job id
#MSUB -q partition                 # Queue

set -x
cd ${BRIDGE_MSUB_PWD}

module load scalasca
export SCOREP_EXPERIMENT_DIRECTORY=scorep_profile.${BRIDGE_MSUB_JOBID}
scan ccc_mprun ./prog.exe
</pre></div>
</div>
<p>At the end of execution, the program generates a directory which contains the profiling files (the directory name is chosen with the <span class="target" id="index-1"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SCOREP_EXPERIMENT_DIRECTORY</span></code> environment variable):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ tree scorep_profile.2871901
   |- profile.cubex
   `- scorep.cfg
</pre></div>
</div>
<p>The profile information can then be visualized with <strong class="command">square</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load scalasca
$ square scorep_profile.2871901
</pre></div>
</div>
<div class="figure align-default" id="id12">
<a class="reference internal image-reference" href="_images/Cube.png"><img alt="Cube interface" src="_images/Cube.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Cube interface</span><a class="headerlink" href="#id12" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="scalasca-with-papi">
<h4>Scalasca with PAPI<a class="headerlink" href="#scalasca-with-papi" title="Permalink to this headline">¶</a></h4>
<p><strong class="program">Score-P</strong> can retrieve the hardware counter with <strong class="program">PAPI</strong>. For example, if you want retrieve the number of floating point operations:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -r MyJob_Para                # Request name
#MSUB -n 32                        # Number of tasks to use
#MSUB -T 1800                      # Elapsed time limit in seconds
#MSUB -o example_%I.o              # Standard output. %I is the job id
#MSUB -e example_%I.e              # Error output. %I is the job id
#MSUB -q partition                 # Queue

set -x
cd ${BRIDGE_MSUB_PWD}

module load scalasca
export SCOREP_EXPERIMENT_DIRECTORY=scorep_profile.${BRIDGE_MSUB_JOBID}

export SCOREP_METRIC_PAPI=PAPI_FP_OPS
scan ccc_mprun ./prog.exe
</pre></div>
</div>
<p>Then the number of floating point operations will appear on the profile when you visualize it. The the syntax to use several papi counters is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">SCOREP_METRIC_PAPI</span><span class="o">=</span><span class="s2">&quot;PAPI_FP_OPS,PAPI_TOT_CYC&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="tracing-application-with-scalasca">
<h4>Tracing application with Scalasca<a class="headerlink" href="#tracing-application-with-scalasca" title="Permalink to this headline">¶</a></h4>
<p>To get a full trace there is no need to recompile the code. The same instrumentation is used for summary and trace profiling. To activate the trace collection, use the option <code class="xref std std-option docutils literal notranslate"><span class="pre">-t</span></code> of <strong class="command">scan</strong>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -r MyJob_Para                # Request name
#MSUB -n 32                        # Number of tasks to use
#MSUB -T 1800                      # Elapsed time limit in seconds
#MSUB -o example_%I.o              # Standard output. %I is the job id
#MSUB -e example_%I.e              # Error output. %I is the job id
#MSUB -q partition                 # Queue

set -x
cd ${BRIDGE_MSUB_PWD}

module load scalasca
export SCOREP_EXPERIMENT_DIRECTORY=scorep_profile.${BRIDGE_MSUB_JOBID}
scan -t ccc_mprun ./prog.exe
</pre></div>
</div>
<p>In that case, a file <code class="file docutils literal notranslate"><span class="pre">traces.otf2</span></code> is created in the output directory with the summary. This profile trace can be opened with for example.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ tree -L 1 scorep_profile.2727202
  |-- profile.cubex
  |-- scorep.cfg
  |-- traces/
  |-- traces.def
  `-- traces.otf2
</pre></div>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Generating a full trace may require a huge amount of memory.</p>
</div>
<p>Here is the best practice to follow:</p>
<ul class="simple">
<li>First start with a simple Scalasca analysis (without <code class="xref std std-option docutils literal notranslate"><span class="pre">-t</span></code>)</li>
<li>Thanks to this summary, you can get an estimation of the size a full trace would take with the command:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ square -s scorep_profile.2871901

Estimated aggregate size of event trace:                   58GB
Estimated requirements for largest trace buffer (max_buf): 6GB
....
</pre></div>
</div>
<ul class="simple">
<li>If the <em>estimated aggregated size of event trace</em> seems excessive (it can easily reach several TB), you will need to apply filtering before recording the trace.</li>
</ul>
<p>For more information on filtering and profiling options, check out the full documentation provided in the installation path:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load scalasca
$ evince ${SCALASCA_ROOT}/share/doc/scalasca/manual/UserGuide.pdf
</pre></div>
</div>
</div>
</div>
<div class="section" id="vampir">
<h3>Vampir<a class="headerlink" href="#vampir" title="Permalink to this headline">¶</a></h3>
<p><strong class="program">Vampir</strong> is a visualization software that can be used to analyse <strong>OTF traces</strong>. The traces should have been generated before by one of the available profiling software such as <strong class="program">Score-P</strong>.</p>
<div class="section" id="usage">
<h4>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h4>
<p>To open a <strong class="program">Score-P</strong> trace with <strong class="command">vampir</strong>, just launch the graphical interface with the corresponding <strong>OTF file</strong>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load vampir
$ vampir scorep_profile.2871915/traces.otf2
</pre></div>
</div>
<div class="figure align-default" id="id13">
<a class="reference internal image-reference" href="_images/vampir.png"><img alt="Vampir window" src="_images/vampir.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Vampir window</span><a class="headerlink" href="#id13" title="Permalink to this image">¶</a></p>
</div>
<p>It is not recommended to launch on the login nodes. An interactive session on compute nodes may be necessary. Also, the graphical interface may be slow. Using the Remote Desktop System service can help with that.</p>
<p>See <a class="reference external" href="https://www.vampir.eu/tutorial/manual">the manual</a> for full details and features of the vampir tool.</p>
</div>
<div class="section" id="vampirserver">
<h4>Vampirserver<a class="headerlink" href="#vampirserver" title="Permalink to this headline">¶</a></h4>
<p>Traces generated by <strong class="command">Score-P</strong> can be very large and can be very slow if you want to visualize these traces. <strong class="command">Vampir</strong> provides <strong class="command">vampirserver</strong>: it is a parallel program which uses CPU computing to accelerate Vampir visualization. Firstly, you have to submit a job which will launch on Irene nodes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cat vampirserver.sh
#!/bin/bash
#MSUB -r vampirserver             # Request name
#MSUB -n 32                       # Number of tasks to use
#MSUB -T 1800                     # Elapsed time limit in seconds
#MSUB -o vampirserver_%I.o        # Standard output. %I is the job id
#MSUB -e vampirserver_%I.e        # Error output. %I is the job id
#MSUB -q partition                # Queue

module load vampir
vampirserver start -n $((BRIDGE_MSUB_NPROC-1))

vampir
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_msub vampirserver.sh
</pre></div>
</div>
<p>When the job is running, you will obtain this output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mpp
USER ACCOUNT BATCHID NCPU QUEUE PRIORITY STATE RLIM  RUN/START SUSP OLD  NAME         NODES
toto genXXX  234481  32   large 210332   RUN   30.0m 1.3m      -    1.3m vampirserver node1352

$ ccc_mpeek 234481
Found license file: /usr/local/vampir-7.5/bin/lic.dat
Running 31 analysis processes... (abort with Ctrl-C or vngd-shutdown)
Server listens on: node1352:30000
</pre></div>
</div>
<p>And a Vampir window should open.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The <strong class="command">vampirserver</strong> command runs in the background. So, without the call to <strong class="program">Vampir</strong>, the job would be terminated immediately.</p>
</div>
<p>In our example, the Vampirserver master node is on node1352. The port to connect is 30000. Instead of clicking on “Open”, you will click on “Remote Open”:</p>
<div class="figure align-default" id="id14">
<a class="reference internal image-reference" href="_images/vampirserver.png"><img alt="Connecting to Vampirserver" src="_images/vampirserver.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Connecting to Vampirserver</span><a class="headerlink" href="#id14" title="Permalink to this image">¶</a></p>
</div>
<p>Fill the server and the port. You will be connected to vampirserver. Then you can open an <strong>OTF file</strong> and visualize it.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>You can ask any number of processors you want: it will be faster if your profiling files are big. But be careful, it consumes your computing times.</li>
<li>Don’t forget to delete the Vampirserver job after your analyse.</li>
</ul>
</div>
</div>
</div>
<div class="section" id="extra-p">
<h3>Extra-P<a class="headerlink" href="#extra-p" title="Permalink to this headline">¶</a></h3>
<p><strong class="program">Extra-P</strong> is an automatic performance-modeling tool that can be used to analyse several <span class="target" id="index-2"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SCOREP_EXPERIMENT_DIRECTORY</span></code> generated with <strong class="program">Score-P</strong>. The primary goal of this tool is identify scalability bugs but due to his multiple graphics outputs, it’s also useful to make reports.</p>
<div class="section" id="id2">
<h4>Usage<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<p>To analyse the scalability of an algorithm you need to generate several <span class="target" id="index-3"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">SCOREP_EXPERIMENT_DIRECTORY</span></code>, for example you can launch this submission script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#MSUB -r npb_btmz_scorep
#MSUB -o npb_btmz_scorep_%I.o
#MSUB -e npb_btmz_scorep_%I.e
#MSUB -Q test
#MSUB -T 1800    # max walltime in seconds
#MSUB -q haswell

cd $BRIDGE_MSUB_PWD

# benchmark configuration
export OMP_NUM_THREADS=$BRIDGE_MSUB_NCORE

# Score-P configuration
export SCOREP_EXPERIMENT_DIRECTORY=scorep_profile.p$p.r$r
PROCS=$BRIDGE_MSUB_NPROC
EXE=./exe

ccc_mprun -n $PROCS $EXE
</pre></div>
</div>
<p>from a bash script (4 runs on each scripts with 8, 16, 32 and 64 cores):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p</span><span class="o">=</span><span class="mi">4</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span> <span class="n">c</span><span class="o">=</span><span class="mi">2</span> <span class="n">r</span><span class="o">=</span><span class="mi">1</span> <span class="n">ccc_msub</span> <span class="o">-</span><span class="n">n</span> <span class="mi">2</span> <span class="o">-</span><span class="n">c</span> <span class="mi">2</span> <span class="n">submit_global</span><span class="o">.</span><span class="n">msub</span>
<span class="n">p</span><span class="o">=</span><span class="mi">4</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span> <span class="n">c</span><span class="o">=</span><span class="mi">2</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span> <span class="n">ccc_msub</span> <span class="o">-</span><span class="n">n</span> <span class="mi">2</span> <span class="o">-</span><span class="n">c</span> <span class="mi">2</span> <span class="n">submit_global</span><span class="o">.</span><span class="n">msub</span>
<span class="n">p</span><span class="o">=</span><span class="mi">4</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span> <span class="n">c</span><span class="o">=</span><span class="mi">2</span> <span class="n">r</span><span class="o">=</span><span class="mi">3</span> <span class="n">ccc_msub</span> <span class="o">-</span><span class="n">n</span> <span class="mi">2</span> <span class="o">-</span><span class="n">c</span> <span class="mi">2</span> <span class="n">submit_global</span><span class="o">.</span><span class="n">msub</span>
<span class="n">p</span><span class="o">=</span><span class="mi">4</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span> <span class="n">c</span><span class="o">=</span><span class="mi">2</span> <span class="n">r</span><span class="o">=</span><span class="mi">4</span> <span class="n">ccc_msub</span> <span class="o">-</span><span class="n">n</span> <span class="mi">2</span> <span class="o">-</span><span class="n">c</span> <span class="mi">2</span> <span class="n">submit_global</span><span class="o">.</span><span class="n">msub</span>
<span class="n">p</span><span class="o">=</span><span class="mi">8</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span> <span class="n">c</span><span class="o">=</span><span class="mi">4</span> <span class="n">r</span><span class="o">=</span><span class="mi">1</span> <span class="n">ccc_msub</span> <span class="o">-</span><span class="n">n</span> <span class="mi">2</span> <span class="o">-</span><span class="n">c</span> <span class="mi">4</span> <span class="n">submit_global</span><span class="o">.</span><span class="n">msub</span>
<span class="p">[</span><span class="o">...</span><span class="p">]</span>
<span class="n">p</span><span class="o">=</span><span class="mi">32</span> <span class="n">n</span><span class="o">=</span><span class="mi">8</span> <span class="n">c</span><span class="o">=</span><span class="mi">4</span> <span class="n">r</span><span class="o">=</span><span class="mi">4</span> <span class="n">ccc_msub</span> <span class="o">-</span><span class="n">n</span> <span class="mi">8</span> <span class="o">-</span><span class="n">c</span> <span class="mi">4</span> <span class="n">submit_global</span><span class="o">.</span><span class="n">msub</span>
<span class="n">p</span><span class="o">=</span><span class="mi">64</span> <span class="n">n</span><span class="o">=</span><span class="mi">8</span> <span class="n">c</span><span class="o">=</span><span class="mi">8</span> <span class="n">r</span><span class="o">=</span><span class="mi">1</span> <span class="n">ccc_msub</span> <span class="o">-</span><span class="n">n</span> <span class="mi">8</span> <span class="o">-</span><span class="n">c</span> <span class="mi">8</span> <span class="n">submit_global</span><span class="o">.</span><span class="n">msub</span>
<span class="n">p</span><span class="o">=</span><span class="mi">64</span> <span class="n">n</span><span class="o">=</span><span class="mi">8</span> <span class="n">c</span><span class="o">=</span><span class="mi">8</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span> <span class="n">ccc_msub</span> <span class="o">-</span><span class="n">n</span> <span class="mi">8</span> <span class="o">-</span><span class="n">c</span> <span class="mi">8</span> <span class="n">submit_global</span><span class="o">.</span><span class="n">msub</span>
<span class="n">p</span><span class="o">=</span><span class="mi">64</span> <span class="n">n</span><span class="o">=</span><span class="mi">8</span> <span class="n">c</span><span class="o">=</span><span class="mi">8</span> <span class="n">r</span><span class="o">=</span><span class="mi">3</span> <span class="n">ccc_msub</span> <span class="o">-</span><span class="n">n</span> <span class="mi">8</span> <span class="o">-</span><span class="n">c</span> <span class="mi">8</span> <span class="n">submit_global</span><span class="o">.</span><span class="n">msub</span>
<span class="n">p</span><span class="o">=</span><span class="mi">64</span> <span class="n">n</span><span class="o">=</span><span class="mi">8</span> <span class="n">c</span><span class="o">=</span><span class="mi">8</span> <span class="n">r</span><span class="o">=</span><span class="mi">4</span> <span class="n">ccc_msub</span> <span class="o">-</span><span class="n">n</span> <span class="mi">8</span> <span class="o">-</span><span class="n">c</span> <span class="mi">8</span> <span class="n">submit_global</span><span class="o">.</span><span class="n">msub</span>
</pre></div>
</div>
<p>Once these folders are generated load <strong class="program">Extra-P</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load extrap
</pre></div>
</div>
<p>launch it and open the parent folder. The software detects automatically your files:</p>
<a class="reference internal image-reference" href="_images/Scorep_open.png"><img alt="Extra-p interface" src="_images/Scorep_open.png" style="width: 600px;" /></a>
<p>On Metric section choose “time” and you will get the time of each commands. You can also right clic on the graph and choose “Show all data points”, you will see the time of all your runs:</p>
<a class="reference internal image-reference" href="_images/Graph.png"><img alt="Time for p process" src="_images/Graph.png" style="width: 600px;" /></a>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">These graphics only give the time of your application, not any speedup.</p>
</div>
<p><strong class="program">Extra-P</strong> also list all MPI and OpenMP requests, you can select what you want and check scalability:</p>
<a class="reference internal image-reference" href="_images/Choicefunc.png"><img alt="Command list" src="_images/Choicefunc.png" style="width: 600px;" /></a>
<p>At least, you can choose to use strong scaling and see the efficiency of an algorithm:</p>
<a class="reference internal image-reference" href="_images/Strong2.png"><img alt="Strong scaling" src="_images/Strong2.png" style="width: 600px;" /></a>
</div>
</div>
<div class="section" id="hpctoolkit">
<h3>HPCToolkit<a class="headerlink" href="#hpctoolkit" title="Permalink to this headline">¶</a></h3>
<p>HPCToolkit is an integrated suite of tools for measurement and analysis of program performance. HPCToolkit supports measurement and analysis of serial codes, threaded codes (e.g. pthreads, OpenMP), MPI, hybrid (MPI+threads e.g MPI/OpenMP) parallel codes and CUDA codes, statically or dynamically linked. It has a low overhead (1-5%) due to the use of statistical sampling of timers and hardware performance counters.</p>
<p>To sum-up how HPCToolkit works, hereafter an overview of HPCToolkit’s workflow (derived from the official website):</p>
<a class="reference internal image-reference" href="_images/hpctoolkit-workflow.png"><img alt="HPCToolkit's workflow" src="_images/hpctoolkit-workflow.png" style="width: 600px;" /></a>
<p>HPCToolkit’s workflow</p>
<p>Module hpctoolkit has to be loaded:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">hpctoolkit</span>
</pre></div>
</div>
<p>You have to compile your code sources normally (full optimizations) and if possible with the debugging symbols (<code class="xref std std-option docutils literal notranslate"><span class="pre">-g</span></code> option).</p>
<p>You can find below the steps to profile your executable.</p>
<ul class="simple">
<li><strong class="command">hpcsctruct</strong></li>
</ul>
<p>Analyze the structure of your executable.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hpcstruct</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">binary</span><span class="o">/&lt;</span><span class="n">executable</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>It will create a file named <code class="file docutils literal notranslate"><span class="pre">&lt;executable&gt;.hpcstruct</span></code> on the current directory. Its size is similar to the one of the binary. It’s rather quick (few seconds), there is no need to run it into a job.</p>
<ul class="simple">
<li><strong class="command">hpcrun</strong></li>
</ul>
<p><strong class="command">hpcrun</strong> defines some events for profiling the code. Moreover, <strong class="command">hpcrun</strong> is linked against <strong class="program">Papi</strong>, so hardware counters can be used.</p>
<blockquote>
<div><ul class="simple">
<li>To show default metrics provided by <strong class="command">hpcrun</strong>:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hpcrun</span> <span class="o">-</span><span class="n">L</span>
</pre></div>
</div>
<ul class="simple">
<li>To activate the wanted events (for dynamic linked application):</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hpcrun</span> <span class="o">--</span><span class="n">event</span> <span class="o">&lt;</span><span class="n">name</span><span class="o">-</span><span class="n">event</span><span class="o">&gt;</span><span class="p">[</span><span class="o">@&lt;</span><span class="n">period</span><span class="o">&gt;</span><span class="p">]</span>
<span class="c1"># period in units meaningful to the specified event</span>
</pre></div>
</div>
<ul class="simple">
<li>To launch the profiling (into a job):</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_mprun</span> <span class="n">hpcrun</span> <span class="o">&lt;</span><span class="n">executable</span><span class="o">&gt;</span> <span class="p">[</span><span class="n">option_executable</span><span class="p">]</span>
</pre></div>
</div>
<ul class="simple">
<li>Useful option, to generate trace, use <code class="xref std std-option docutils literal notranslate"><span class="pre">-t</span></code>:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hpcrun</span> <span class="o">-</span><span class="n">t</span> <span class="o">...</span>
</pre></div>
</div>
</div></blockquote>
<p>A directory named <code class="file docutils literal notranslate"><span class="pre">hpctoolkit-&lt;executable&gt;-measurement-&lt;jod_id&gt;</span></code> will be created.</p>
<ul class="simple">
<li><strong class="command">hpcrun-flat</strong></li>
</ul>
<p>Another way to profile an executable is to use <strong class="command">hpcrun-flat</strong>, which profiles the execution using statistical sampling (rather than instrumentation) and generates flat profile files. Only dynamic linked applications can be profiled, due to using preloaded shared libraries to initiate profiling.</p>
<blockquote>
<div><ul class="simple">
<li>To show default metrics provided by <strong class="command">hpcrun-flat</strong>:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hpcrun</span><span class="o">-</span><span class="n">flat</span> <span class="o">-</span><span class="n">l</span>
<span class="n">hpcrun</span><span class="o">-</span><span class="n">flat</span> <span class="o">-</span><span class="n">L</span> <span class="c1">#more verbose</span>
</pre></div>
</div>
<ul class="simple">
<li>To activate the wanted events (for dynamic linked applications):</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hpcrun</span><span class="o">-</span><span class="n">flat</span> <span class="o">--</span><span class="n">event</span> <span class="o">&lt;</span><span class="n">event</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span><span class="p">[:</span><span class="o">&lt;</span><span class="n">period</span><span class="o">&gt;</span><span class="p">]</span>
<span class="c1">#period in units meaningful to the specified event</span>
</pre></div>
</div>
<ul class="simple">
<li>To launch the profiling (into a job):</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_mprun</span> <span class="n">hpcrun</span><span class="o">-</span><span class="n">flat</span> <span class="p">[</span><span class="n">options</span><span class="p">][</span><span class="n">events</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="p">]</span> <span class="o">&lt;</span><span class="n">executable</span><span class="o">&gt;</span>  <span class="p">[</span><span class="n">option_executable</span><span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<p>If there are at least one option following your executable has, put the option <code class="xref std std-option docutils literal notranslate"><span class="pre">--</span></code> to <strong class="command">hpcrun-flat</strong>.</p>
<p>Many files named <code class="file docutils literal notranslate"><span class="pre">&lt;executable&gt;.hpcrun-flat.&lt;hostname&gt;.&lt;pid&gt;.&lt;flavor&gt;</span></code> will be created. Some options of are available to sort them.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Only POSIX threads are supported.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The WALLCLOCK event cannot be used in a multithreaded process.</p>
</div>
<ul class="simple">
<li><strong class="command">hpcprof</strong> / <strong class="command">hpcprof-mpi</strong></li>
</ul>
<p><strong class="command">hpcprof</strong> analyses call path profile performance measurements according to the source code structure and generates an experiment database for use with <strong class="command">hpcviewer</strong>. The mpi-version accelerates correlation time.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ hpcprof -S &lt;executable&gt;.hpcstruct -I /path/to/source/1/&#39;*&#39; -I /path/to/source/
2/+ hpctoolkit-&lt;executable&gt;-measurement-&lt;job_id&gt;

$ ccc_mprun hpcprof-mpi -S &lt;executable&gt;.hpcstruct -I /path/to/source/1/* -I
/path/to/source/2/+ hpctoolkit-&lt;executable&gt;-measurement-&lt;job_id&gt;
</pre></div>
</div>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">*</span></code> search for file in the specified directory only</li>
<li><code class="docutils literal notranslate"><span class="pre">+</span></code> search for file recursively</li>
</ul>
<p>A directory named <code class="file docutils literal notranslate"><span class="pre">hpctoolkit-&lt;executable&gt;-database-&lt;number&gt;-[&lt;number&gt;-...]</span></code> will be created.</p>
<ul class="simple">
<li><strong class="command">hpcproftt</strong></li>
</ul>
<p><strong class="command">hpcproftt</strong> correlates ‘flat’ profile metrics provided by <strong class="command">hpcrun-flat</strong> with either source code structure or object code and generates textual output.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hpcproftt</span> <span class="p">[</span><span class="n">options</span><span class="p">][</span><span class="o">--</span><span class="n">sources</span><span class="p">][</span><span class="o">--</span><span class="nb">object</span><span class="p">]</span> <span class="o">&lt;</span><span class="n">executable</span><span class="o">&gt;.</span><span class="n">hpcrun</span><span class="o">-</span><span class="n">flat</span><span class="o">.&lt;</span><span class="n">hostname</span><span class="o">&gt;.&lt;</span><span class="n">pid</span><span class="o">&gt;.&lt;</span><span class="n">flavor</span><span class="o">&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><strong class="command">hpcviewer</strong> / <strong class="command">hpctraceviewer</strong></li>
</ul>
<p>Aimed to result visualization, through X11 forwarding or remote desktop service:</p>
<blockquote>
<div><ul class="simple">
<li>To display metrics about counters:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hpcviewer</span> <span class="n">hpctoolkit</span><span class="o">-&lt;</span><span class="n">executable</span><span class="o">&gt;-</span><span class="n">database</span><span class="o">-&lt;</span><span class="n">number</span><span class="o">&gt;-</span><span class="p">[</span><span class="o">&lt;</span><span class="n">number</span><span class="o">&gt;-...</span><span class="p">]</span>
</pre></div>
</div>
<ul class="simple">
<li>To display trace (only with <strong class="command">hpcrun -t</strong>):</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hpctraceviewer</span> <span class="n">hpctoolkit</span><span class="o">-&lt;</span><span class="n">executable</span><span class="o">&gt;-</span><span class="n">database</span><span class="o">-&lt;</span><span class="n">number</span><span class="o">&gt;-</span><span class="p">[</span><span class="o">&lt;</span><span class="n">number</span><span class="o">&gt;-...</span><span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<div class="figure align-default">
<a class="reference internal image-reference" href="_images/screen_hpcviewer.png"><img alt="hpcviewer overview" src="_images/screen_hpcviewer.png" style="width: 600px;" /></a>
</div>
<div class="figure align-default">
<a class="reference internal image-reference" href="_images/screen_hpctraceviewer.png"><img alt="hpctraceviewer overview" src="_images/screen_hpctraceviewer.png" style="width: 600px;" /></a>
</div>
</div>
<div class="section" id="intel-vtune">
<h3>Intel Vtune<a class="headerlink" href="#intel-vtune" title="Permalink to this headline">¶</a></h3>
<p><strong class="program">Vtune</strong> is a profiling software with hardware profiling counters support. It has two modes:</p>
<blockquote>
<div><ul class="simple">
<li>program stack analysis</li>
<li>hardware counters analysis</li>
</ul>
</div></blockquote>
<p>This program is based on sampling in either mode, which allows to have a low overhead on the analysed program.</p>
<div class="section" id="analysis-with-default-or-extended-hardware-counters">
<h4>Analysis with default or extended hardware counters<a class="headerlink" href="#analysis-with-default-or-extended-hardware-counters" title="Permalink to this headline">¶</a></h4>
<div class="section" id="analysis-with-default-hardware-counters">
<h5>Analysis with default hardware counters<a class="headerlink" href="#analysis-with-default-hardware-counters" title="Permalink to this headline">¶</a></h5>
<p>By default some hardware counters aren’t accessible so VTune will not use them.</p>
<blockquote>
<div><ul class="simple">
<li>Call graph -&gt; hotspots</li>
</ul>
</div></blockquote>
<p>Based on call stack sampling, it gives an approximation of the time spent in each function.</p>
<blockquote>
<div><ul class="simple">
<li>Concurrency</li>
</ul>
</div></blockquote>
<p>Analysis of multi-thread efficiency: based on call stack sampling and threads states in the program.</p>
<blockquote>
<div><ul class="simple">
<li>Locks and waits</li>
</ul>
</div></blockquote>
<p>Analysis of multi-thread locks: based on on call stack sampling and the threads states in the program.</p>
</div>
<div class="section" id="analysis-with-extended-hardware-counters">
<h5>Analysis with extended hardware counters<a class="headerlink" href="#analysis-with-extended-hardware-counters" title="Permalink to this headline">¶</a></h5>
<p>To enable more hardware counters you can use VTune with <a class="reference internal" href="#perf"><span class="std std-ref">linux perf tool</span></a> by passing <code class="xref std std-option docutils literal notranslate"><span class="pre">-E</span> <span class="pre">'--enable_perf'</span></code> option to <strong class="command">ccc_msub</strong> or <strong class="command">ccc_mprun</strong>.</p>
<p>These analyses depend on CPU target architecture and are grouped in predefined analyses. They have some constraints:</p>
<blockquote>
<div><ul class="simple">
<li>You cannot do more than one collection at once: on multi-processes analyses you will need to use a full system collection if you want information on more than one process.</li>
<li>A processor isn’t able to take more than a few hardware counters at once, so the collection is done by cycling between the counters in order to measure everything. Numbers provided are an extrapolation based on the values measured. Some operations can be missed.</li>
<li>The <code class="docutils literal notranslate"><span class="pre">memory-access</span></code> collection does <strong>not</strong> work and should not be used.</li>
</ul>
</div></blockquote>
<p>For more information on these analyses, type:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ amplxe-cl -help collect
</pre></div>
</div>
<p>The lightweight hotspots analysis is a special case of hotspots analysis which use the collecting driver. It has a lower overhead than the hotspots analysis but has the same constraints than the hardware counters mode.</p>
<p>Never do a collection on a non exclusive reservation of the node (the results may strongly be influenced by potential other running jobs).</p>
<p>The best practice is to do a collection in batch mode and then open the result file in the GUI. The visualisation GUI can use a lot of resource, so it is best to avoid using it directly on the login nodes.</p>
</div>
</div>
<div class="section" id="collection-in-batch-mode">
<h4>Collection in batch mode<a class="headerlink" href="#collection-in-batch-mode" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><code class="file docutils literal notranslate"><span class="pre">hotspots_vtune.msub</span></code></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -n 1</span>
<span class="c1">#MSUB -c 28</span>
<span class="c1">#MSUB -T 1800</span>
<span class="c1">#MSUB -q {Partition}</span>
<span class="c1">#MSUB -x</span>
<span class="c1">##</span>
<span class="c1"># Do a hotspots collection on a node using a test case on 28 OMP threads</span>
<span class="c1">##</span>

module load vtune

<span class="nb">export</span> <span class="nv">OMP_NUM_THREADS</span><span class="o">=</span><span class="si">${</span><span class="nv">BRIDGE_MSUB_NCORE</span><span class="si">}</span>

ccc_mprun -E <span class="s1">&#39;--enable_perf&#39;</span> amplxe-cl -collect hotspots -r <span class="si">${</span><span class="nv">PWD</span><span class="si">}</span>/vtune_results ./test
</pre></div>
</div>
<p>Always set the <strong>analysis_type</strong> and be sure to use a collection type compatible with the processors of the partition you are running on. Also, make sure your working directory is either on SCRATCH or WORK filesystem so no files will be generated on your home filesystem (NFS) as it would show slow performance.</p>
</div>
<div class="section" id="open-visualization-gui">
<h4>Open Visualization GUI<a class="headerlink" href="#open-visualization-gui" title="Permalink to this headline">¶</a></h4>
<p>On a remote X display do:</p>
<ul class="simple">
<li><code class="file docutils literal notranslate"><span class="pre">interactive_vtune.msub</span></code></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -n 1</span>
<span class="c1">#MSUB -T 1800</span>
<span class="c1">#MSUB -q {Partition}</span>
<span class="c1">#MSUB -X</span>
<span class="c1">#MSUB -x</span>
<span class="c1">##</span>
<span class="c1"># launch the vtune GUI on a standard node for visualisation of a collection</span>
<span class="c1">##</span>
module load vtune
ccc_mprun amplxe-gui
</pre></div>
</div>
<p>To speed up performance, you can move your profiling files into <code class="file docutils literal notranslate"><span class="pre">/tmp</span></code> or <code class="file docutils literal notranslate"><span class="pre">/dev/shm</span></code> folder before opening them with vtune.</p>
<p>Once the GUI appears you can visualize results from the analyses.</p>
<div class="figure align-default" id="id15">
<a class="reference internal image-reference" href="_images/vtune_gui.png"><img alt="vtune_gui.png" src="_images/vtune_gui.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-text">vtune_gui.png</span><a class="headerlink" href="#id15" title="Permalink to this image">¶</a></p>
</div>
<p>to open a collection open the file finishing (in the corresponding collection directory) .amplxe</p>
<div class="figure align-default" id="id16">
<a class="reference internal image-reference" href="_images/open_results.png"><img alt="open_results.png" src="_images/open_results.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-text">open_results.png</span><a class="headerlink" href="#id16" title="Permalink to this image">¶</a></p>
</div>
<p>it will open the summary of the collection.</p>
<div class="figure align-default" id="id17">
<a class="reference internal image-reference" href="_images/collection_sample.png"><img alt="collection_sample.png" src="_images/collection_sample.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-text">collection_sample.png</span><a class="headerlink" href="#id17" title="Permalink to this image">¶</a></p>
</div>
<p>For more documentation and tutorial on the use of from the GUI you can look at the <a class="reference external" href="http://software.intel.com/en-us/articles/intel-vtune-amplifier-xe-2011-documentation">intel documentation</a>.</p>
</div>
<div class="section" id="known-issues">
<h4>Known issues<a class="headerlink" href="#known-issues" title="Permalink to this headline">¶</a></h4>
<p>At the end of a collection, a finalization of the results is done and stored in a folder named <code class="file docutils literal notranslate"><span class="pre">dicer-db</span></code>. In some cases, when writing on a Lustre filesystem, a non readable <code class="file docutils literal notranslate"><span class="pre">dicer-db</span></code> can be generated, which results in an error message when loading it in the GUI. In this case you can redo the finalization step simply by removing the <code class="file docutils literal notranslate"><span class="pre">dicer-db</span></code> folder in the results folder and open the collection again in the GUI.</p>
</div>
<div class="section" id="view-collection-results-from-command-line">
<h4>View collection results from command line<a class="headerlink" href="#view-collection-results-from-command-line" title="Permalink to this headline">¶</a></h4>
<p>It is possible:</p>
<ul class="simple">
<li>to view result of a collection from the command line, for instance:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ amplxe-cl -report summary -r collection_dir
amplxe: Using result path ...
amplxe: Executing actions 75 % Generating a report
Collection and Platform Info
...
Summary
-------
Elapsed Time:       199.777
Paused Time:        0.0
CPU Time:           5578.254
Average CPU Usage:  27.900
amplxe: Executing actions 100 % done
</pre></div>
</div>
<ul class="simple">
<li>to display the summary of the collection (as the one in GUI) without the need of opening the GUI. In the same way:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ amplxe-cl -report hotspots -r collection_dir
amplxe: Using result path ...
amplxe: Executing actions 75 % Generating a report
Function                 CPU Time       ...
main$omp$parallel@18     4872.548s      ...
...
amplxe: Executing actions 100 % done
</pre></div>
</div>
<ul class="simple">
<li>to list the hotspots in a top down display.</li>
</ul>
<p>For a detailed help on this, see:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ amplxe-cl -help report
</pre></div>
</div>
</div>
<div class="section" id="generate-a-dot-graph-with-gprof2dot">
<h4>Generate a dot graph with gprof2dot<a class="headerlink" href="#generate-a-dot-graph-with-gprof2dot" title="Permalink to this headline">¶</a></h4>
<p>To generate a graph with gprof2dot, see <a class="reference internal" href="#use-with-vtune-in-command-line"><span class="std std-ref">gprof2dot and VTune</span></a>.</p>
</div>
</div>
<div class="section" id="valgrind">
<h3>Valgrind<a class="headerlink" href="#valgrind" title="Permalink to this headline">¶</a></h3>
<p>Valgrind is an instrumentation framework for dynamic analysis tools. It comes with a set of tools for profiling and debugging codes.</p>
<p>To run a program with <strong class="command">valgrind</strong>, there is no need to instrument, recompile, or otherwise modify the code.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>A tool in the Valgrind distribution can be invoked with the <code class="xref std std-option docutils literal notranslate"><span class="pre">--tool</span></code> option:</p>
<div class="last highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">valgrind</span>
<span class="n">valgrind</span> <span class="o">--</span><span class="n">tool</span><span class="o">=&lt;</span><span class="n">toolname</span><span class="o">&gt;</span> <span class="c1">#default is memcheck</span>
</pre></div>
</div>
</div>
<div class="section" id="callgrind">
<h4>Callgrind<a class="headerlink" href="#callgrind" title="Permalink to this headline">¶</a></h4>
<p>Callgrind is a profiling tool that records the call history among functions in a program’s run as a call-graph. By default, the collected data consists of the number of instructions executed, their relationship to source lines, the caller/callee relationship between functions, and the numbers of such calls.</p>
<p>To start a profile run for a program, execute:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">valgrind</span>
<span class="n">valgrind</span> <span class="o">--</span><span class="n">tool</span><span class="o">=</span><span class="n">callgrind</span> <span class="p">[</span><span class="n">callgrind</span> <span class="n">options</span><span class="p">]</span> <span class="n">your</span><span class="o">-</span><span class="n">program</span> <span class="p">[</span><span class="n">program</span> <span class="n">options</span><span class="p">]</span>
</pre></div>
</div>
<p>While the simulation is running, you can observe the execution with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">callgrind_control</span> <span class="o">-</span><span class="n">b</span>
</pre></div>
</div>
<p>This will print out the current backtrace. To annotate the backtrace with event counts, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">callgrind_control</span> <span class="o">-</span><span class="n">e</span> <span class="o">-</span><span class="n">b</span>
</pre></div>
</div>
<p>After program termination, a profile data file named <code class="file docutils literal notranslate"><span class="pre">callgrind.out.&lt;pid&gt;</span></code> is generated, where pid is the process ID of the program being profiled. The data file contains information about the calls made in the program among the functions executed, together with Instruction Read (Ir) event counts.</p>
<p>To generate a function-by-function summary from the profile data file, use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">callgrind_annotate</span> <span class="p">[</span><span class="n">options</span><span class="p">]</span> <span class="n">callgrind</span><span class="o">.</span><span class="n">out</span><span class="o">.&lt;</span><span class="n">pid</span><span class="o">&gt;</span>
</pre></div>
</div>
</div>
<div class="section" id="cachegrind">
<h4>Cachegrind<a class="headerlink" href="#cachegrind" title="Permalink to this headline">¶</a></h4>
<p>Cachegrind simulates how your program interacts with a machine’s cache hierarchy and (optionally) branch predictor. To run <strong class="program">cachegrind</strong> on a program <em>prog</em>, you must specify <code class="xref std std-option docutils literal notranslate"><span class="pre">--tool=cachegrind</span></code> on the <strong class="command">valgrind</strong> command line:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">valgrind</span>
<span class="n">valgrind</span> <span class="o">--</span><span class="n">tool</span><span class="o">=</span><span class="n">cachegrind</span> <span class="n">prog</span>
</pre></div>
</div>
<p>Branch prediction statistics are not collected by default. To do so, add the option <code class="xref std std-option docutils literal notranslate"><span class="pre">--branch-sim=yes</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">valgrind</span> <span class="o">-</span><span class="n">tool</span><span class="o">=</span><span class="n">cachegrind</span> <span class="o">--</span><span class="n">branch</span><span class="o">-</span><span class="n">sim</span><span class="o">=</span><span class="n">yes</span> <span class="n">prog</span>
</pre></div>
</div>
<p>One output file will be created for each process launched with <strong class="program">cachegrind</strong>. To analyse the output, use the command <strong class="command">cg_annotate</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cg_annotate &lt;output_file&gt;
</pre></div>
</div>
<p><strong class="command">cg_annotate</strong> can show the source codes annotated with the sampled values. Therefore, either use the option <code class="xref std std-option docutils literal notranslate"><span class="pre">--auto=yes</span></code> to apply to all the available source files or specify one file by passing it as an argument.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cg_annotate &lt;output_file&gt; sourcecode.c
</pre></div>
</div>
<p>For more information on Cachegrind, check out the official <a class="reference external" href="http://valgrind.org/docs/manual/cg-manual.html">Cachegrind User Manual</a>.</p>
</div>
<div class="section" id="massif">
<h4>Massif<a class="headerlink" href="#massif" title="Permalink to this headline">¶</a></h4>
<p>Massif measures how much heap memory a program uses. This includes both the useful space, and the extra bytes allocated for book-keeping and alignment purposes. Massif can optionally measure the stack memory.</p>
<p>As for the other Valgrind tools, the program should be compiled with debugging info (the <code class="xref std std-option docutils literal notranslate"><span class="pre">-g</span></code> option). To run <strong class="program">massif</strong> on a program <em>prog</em>, the <strong class="command">valgrind</strong> command line is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">valgrind</span>
<span class="n">valgrind</span> <span class="o">--</span><span class="n">tool</span><span class="o">=</span><span class="n">massif</span> <span class="n">prog</span>
</pre></div>
</div>
<p>The Massif option <code class="xref std std-option docutils literal notranslate"><span class="pre">--pages-as-heap=yes</span></code> allows to measure all the memory used by the program.</p>
<p>By default, the output file is called <code class="file docutils literal notranslate"><span class="pre">massif.out.&lt;pid&gt;</span></code> (pid is the process ID), although this file name can be changed with the <code class="xref std std-option docutils literal notranslate"><span class="pre">--massif-out-file</span></code> option. To present the heap profiling information about the program in a readable way, run <strong class="command">ms_print</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ms_print massif.out.&lt;pid&gt;
</pre></div>
</div>
</div>
</div>
<div class="section" id="intel-advisor">
<h3>Intel Advisor<a class="headerlink" href="#intel-advisor" title="Permalink to this headline">¶</a></h3>
<p>Intel Advisor is a threading design and prototyping tool for software architects. Intel Advisor is a useful tool for:</p>
<ul class="simple">
<li>analysing, designing, tuning and checking your threading design before implementation,</li>
<li>exploring and testing threading options without disrupting normal development,</li>
<li>predicting thread errors &amp; performance scaling on systems with more cores.</li>
</ul>
<p>Intel Advisor is available through the <strong class="command">module</strong> command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load advisor
</pre></div>
</div>
<p>The tool can be called either via the command line interface (command <strong class="command">advixe-cl</strong>) or the GUI (command <strong class="command">advixe-gui</strong>). Launching the code needs to be done in a submission script or an interactive session. Never on the login nodes.</p>
<div class="section" id="intel-advisor-command-line-interface">
<h4>Intel Advisor Command Line Interface<a class="headerlink" href="#intel-advisor-command-line-interface" title="Permalink to this headline">¶</a></h4>
<p>The Intel Advisor command line interface helps you to:</p>
<ul class="simple">
<li>collect results in three possible modes: survey, suitability, and correctness,</li>
<li>perform regression testing to determine if source code changes introduced new problems,</li>
<li>generate predefined reports in several formats.</li>
</ul>
<p>The <strong class="command">advixe-cl</strong> invokes the Intel Advisor command line interface:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load advisor
$ advixe-cl &lt;-action&gt; [-option] [[--] application [application options]]
</pre></div>
</div>
<p>One action is to be specified per command line, such as: <code class="xref std std-option docutils literal notranslate"><span class="pre">-collect</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-collect-list</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-report</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-report-list</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-format-list</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-help</span></code>, <code class="xref std std-option docutils literal notranslate"><span class="pre">-import-dir</span></code>, or <code class="xref std std-option docutils literal notranslate"><span class="pre">-version</span></code>. Some actions require arguments, such as <code class="xref std std-option docutils literal notranslate"><span class="pre">-collect</span></code> and <code class="xref std std-option docutils literal notranslate"><span class="pre">-report</span></code>.</p>
<p>Results cannot be viewed on the command line. You can use the Intel Advisor GUI, preferably in an interactive session with X11 forwarding or with a Remote Desktop session, to view a result, or use command line tools to generate one or more reports from the result.</p>
<p>To display the built-in documentation, please type:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ advixe-cl -help
</pre></div>
</div>
</div>
<div class="section" id="intel-advisor-gui">
<h4>Intel Advisor GUI<a class="headerlink" href="#intel-advisor-gui" title="Permalink to this headline">¶</a></h4>
<p>Submission script example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#MSUB -r advisor_sub</span>
<span class="c1">#MSUB -q partition</span>
<span class="c1">#MSUB -n 1                   # Number of task</span>
<span class="c1">#MSUB -c 28                  # Number of core per task</span>
<span class="c1">#MSUB -o advisor_sub_%J.e    # Error output</span>
<span class="c1">#MSUB -e advisor_sub_%J.o    # Output</span>
<span class="c1">#MSUB -x</span>
<span class="c1">#MSUB -X first</span>

<span class="n">module</span> <span class="n">load</span> <span class="n">advisor</span>

<span class="n">ccc_mprun</span> <span class="n">advixe</span><span class="o">-</span><span class="n">gui</span>
</pre></div>
</div>
<p>Create a new project:</p>
<div class="figure align-default" id="id18">
<a class="reference internal image-reference" href="_images/advisor_01.png"><img alt="New Project" src="_images/advisor_01.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">New Project</span><a class="headerlink" href="#id18" title="Permalink to this image">¶</a></p>
</div>
<p>Choose binary to profile:</p>
<div class="figure align-default" id="id19">
<a class="reference internal image-reference" href="_images/advisor_03.png"><img alt="Browse Binary" src="_images/advisor_03.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Browse Binary</span><a class="headerlink" href="#id19" title="Permalink to this image">¶</a></p>
</div>
<p>You can modify environment variables (<span class="target" id="index-4"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">OMP_NUM_THREADS</span></code> for example):</p>
<div class="figure align-default" id="id20">
<a class="reference internal image-reference" href="_images/advisor_04.png"><img alt="Modify Variables" src="_images/advisor_04.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Modify Variables</span><a class="headerlink" href="#id20" title="Permalink to this image">¶</a></p>
</div>
<p>Validate properties:</p>
<div class="figure align-default" id="id21">
<a class="reference internal image-reference" href="_images/advisor_06.png"><img alt="Properties: OK" src="_images/advisor_06.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Properties</span><a class="headerlink" href="#id21" title="Permalink to this image">¶</a></p>
</div>
<p>Turn On Batch mode, select what you need and Collect:</p>
<div class="figure align-default" id="id22">
<a class="reference internal image-reference" href="_images/advisor_08.png"><img alt="Collect" src="_images/advisor_08.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Collect</span><a class="headerlink" href="#id22" title="Permalink to this image">¶</a></p>
</div>
<p>Analyse collected data:</p>
<div class="figure align-default" id="id23">
<a class="reference internal image-reference" href="_images/advisor_09.png"><img alt="Collected Data" src="_images/advisor_09.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Collected Data</span><a class="headerlink" href="#id23" title="Permalink to this image">¶</a></p>
</div>
<p>For more information, see the full <a class="reference external" href="https://software.intel.com/en-us/get-started-with-advisor">Intel Advisor Documentation</a>.</p>
</div>
</div>
<div class="section" id="tau-tuning-and-analysis-utilities">
<h3>TAU (Tuning and Analysis Utilities)<a class="headerlink" href="#tau-tuning-and-analysis-utilities" title="Permalink to this headline">¶</a></h3>
<p>TAU Performance System is a portable profiling and tracing toolkit for performance analysis of parallel programs written in Fortran, C, C++, UPC, Java, Python.</p>
<p>TAU (Tuning and Analysis Utilities) is capable of gathering performance information through instrumentation of functions, methods, basic blocks, and statements as well as event-based sampling. The instrumentation can be inserted in the source code using an automatic instrumentor tool based on the Program Database Toolkit (PDT), dynamically using DyninstAPI, at runtime in the Java Virtual Machine, or manually using the instrumentation API.</p>
<p>TAU’s profile visualization tool, paraprof, provides graphical displays of all the performance analysis results, in aggregate and single node/context/thread forms. The user can quickly identify sources of performance bottlenecks in the application using the graphical interface. In addition, TAU can generate event traces that can be displayed with the Vampir, Paraver or JumpShot trace visualization tools.</p>
<div class="section" id="instrumentation">
<h4>Instrumentation<a class="headerlink" href="#instrumentation" title="Permalink to this headline">¶</a></h4>
<p>TAU is available through the <strong class="command">module</strong> command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load tau
</pre></div>
</div>
<p>Specify programming model by setting <span class="target" id="index-5"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">TAU_MAKEFILE</span></code> to one of <code class="file docutils literal notranslate"><span class="pre">$TAU_MAKEFILEDIR/Makefile.tau-*</span></code>:</p>
<ul class="simple">
<li><code class="file docutils literal notranslate"><span class="pre">Makefile.tau-depthlimit-icpc-mpi-pdt-openmp</span></code></li>
<li><code class="file docutils literal notranslate"><span class="pre">Makefile.tau-icpc-mpi-pdt-openmp</span></code></li>
<li><code class="file docutils literal notranslate"><span class="pre">Makefile.tau-icpc-mpi-pthread-pdt-openmp</span></code></li>
<li><code class="file docutils literal notranslate"><span class="pre">Makefile.tau-icpc-papi-mpi-pdt-openmp</span></code></li>
<li><code class="file docutils literal notranslate"><span class="pre">Makefile.tau-icpc-papi-mpi-pthread-pdt-openmp</span></code></li>
<li><code class="file docutils literal notranslate"><span class="pre">Makefile.tau-param-icpc-mpi-pdt-openmp</span></code></li>
<li><code class="file docutils literal notranslate"><span class="pre">Makefile.tau-phase-icpc-papi-mpi-pdt-openmp</span></code></li>
</ul>
<p>Compile and link with:</p>
<ul class="simple">
<li><strong class="command">tau_cc.sh</strong> for C code source files,</li>
<li><strong class="command">tau_cxx.sh</strong> for C++ code source files, and</li>
<li><strong class="command">tau_f90.sh</strong> for Fortran code source files,</li>
</ul>
</div>
<div class="section" id="id3">
<h4>Usage<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h4>
<p>The command to run TAU is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n $NPROCS tau_exec ./a.out
</pre></div>
</div>
<p>Examine results with <strong class="command">paraprof</strong>/<strong class="command">pprof</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pprof [directory_path]
</pre></div>
</div>
<p>or</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ paraprof
</pre></div>
</div>
<div class="figure align-default" id="id24">
<a class="reference internal image-reference" href="_images/Tau_paraprof.jpg"><img alt="Example of ParaProf window" src="_images/Tau_paraprof.jpg" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Example of ParaProf window</span><a class="headerlink" href="#id24" title="Permalink to this image">¶</a></p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">It’s recommended to use the Remote Desktop session to use the graphical tools provided by tau (e.g. paraprof).</p>
</div>
<p>Environment variables control measurement mode <span class="target" id="index-6"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">TAU_PROFILE</span></code>, <span class="target" id="index-7"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">TAU_TRACE</span></code>, <span class="target" id="index-8"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">TAU_CALLPATH</span></code> are available to tune the profiling settings.</p>
<p>For more information, see <a class="reference external" href="https://www.cs.uoregon.edu/research/tau/docs/newguide/bk01.html">TAU User Guide</a>.</p>
</div>
</div>
<div class="section" id="gprof2dot">
<h3>Gprof2dot<a class="headerlink" href="#gprof2dot" title="Permalink to this headline">¶</a></h3>
<p>Gprof2dot is an utility which converts profile data into a dot graph. It is compatible with many profilers.</p>
<a class="reference internal image-reference" href="_images/gprof2dot_Sample.png"><img alt="Example of a graph generated with gprof2dot" src="_images/gprof2dot_Sample.png" style="width: 341px;" /></a>
<div class="section" id="use-with-gprof">
<span id="id4"></span><h4>Use with gprof<a class="headerlink" href="#use-with-gprof" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>Load modules gprof AND gprof2dot</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load gprof gprof2dot
</pre></div>
</div>
<ul class="simple">
<li>Be sure to compile your application with <code class="xref std std-option docutils literal notranslate"><span class="pre">-pg</span></code> option</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ icc -pg hello.c
</pre></div>
</div>
<ul class="simple">
<li>Generate the call graph profile <code class="file docutils literal notranslate"><span class="pre">gmon.out</span></code> (Run the application one time)</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ./a.out
</pre></div>
</div>
<ul class="simple">
<li>Generate the dot graph in a PNG image</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ gprof ./a.out gmon.out | gprof2dot.py | dot -Tpng -o a.png
</pre></div>
</div>
</div>
<div class="section" id="use-with-vtune-in-command-line">
<span id="id5"></span><h4>Use with VTune in command line<a class="headerlink" href="#use-with-vtune-in-command-line" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>Load modules VTune AND gprof2dot</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ module load vtune gprof2dot
</pre></div>
</div>
<ul class="simple">
<li>Use VTune to collect data</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun amplxe-cl -collect hotspots -result-dir output -- ./exe
</pre></div>
</div>
<ul class="simple">
<li>Transform data in a gprof-like file</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ amplxe-cl -report gprof-cc -result-dir output -format text -report-output output.txt
</pre></div>
</div>
<ul class="simple">
<li>Generate the dot graph</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ gprof2dot.py -f axe output.txt | dot -Tpng -o output.png
</pre></div>
</div>
<p>For more information about gprof2dot, see <a class="reference external" href="https://github.com/jrfonseca/gprof2dot">GitHub gprof2dot</a>.</p>
</div>
</div>
<div class="section" id="perf">
<span id="id6"></span><h3>Perf<a class="headerlink" href="#perf" title="Permalink to this headline">¶</a></h3>
<p>Perf is a portable tool included in Linux kernel, it doesn’t need to be loaded, doesn’t need any driver and also works on all Linux platforms.</p>
<p>It is a performance analysis tool which displays performance counters such as the number of cache loads misses or branch loads misses.</p>
<ul class="simple">
<li>Perf cannot be fully launched on login nodes, you will need to execute it on compute node(s).</li>
<li>To run a command and gather performance counter statistics use <strong class="command">perf stat</strong>. Here is a simple job example:</li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#MSUB -n 1</span>
<span class="c1">#MSUB -c 12</span>
<span class="c1">#MSUB -T 400</span>
<span class="c1">#MSUB -q |Partition|</span>
<span class="c1">#MSUB -x</span>
<span class="c1">#MSUB -E &#39;--enable_perf&#39;</span>

<span class="nb">export</span> <span class="nv">OMP_NUM_THREADS</span><span class="o">=</span><span class="si">${</span><span class="nv">BRIDGE_MSUB_NCORE</span><span class="si">}</span>

ccc_mprun perf stat -o perf.log ./exe
</pre></div>
</div>
<ul class="simple">
<li>Informations will be stored in <code class="file docutils literal notranslate"><span class="pre">perf.log</span></code>:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cat perf.log
# started on Wed Oct 11 14:01:14 2017

Performance counter stats for &#39;./exe&#39;:

  50342.076495         task-clock:u (msec)       #    1.000 CPUs utilized
  98,323               page-faults:u             #    0.002 M/sec
  155,516,791,925      cycles:u                  #    3.089 GHz
  197,715,764,466      instructions:u            #    1.27  insn per cycle

    50.348439743 seconds time elapsed
</pre></div>
</div>
<p>Now for more specifics counters:</p>
<ul class="simple">
<li>list of all performance counters with the command <strong class="command">perf list</strong></li>
<li>Use the <code class="xref std std-option docutils literal notranslate"><span class="pre">-e</span></code> option to specify the wanted performance counters. For example, to get how much cache access misses within all cache access:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun perf stat -o perf.log -e cache-references,cache-misses ./exe
$ cat perf.log
# started on Wed Oct 11 14:02:52 2017

Performance counter stats for &#39;./exe&#39;:

  8,654,163,728      cache-references:u
  875,346,349        cache-misses:u            #   10.115 % of all cache refs

    52.710267128 seconds time elapsed
</pre></div>
</div>
<p>Perf can also record few counters from an executable and create a report:</p>
<ul class="simple">
<li>Use a job to create a report with</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -vvv perf record -o data.perf ./exe
...
[ perf record: Woken up 53 times to write data ]
[ perf record: Captured and wrote 13.149 MB data.perf (344150 samples) ]
...
</pre></div>
</div>
<ul class="simple">
<li>Read the report from the login node</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ perf report -i data.perf
Samples: 344K of event &#39;cycles:u&#39;, Event count (approx.): 245940413046
Overhead  Command  Shared Object       Symbol
 99.94%  exe      exe                 [.] mydgemm_
  0.02%  exe      [kernel.vmlinux]    [k] apic_timer_interrupt
  0.02%  exe      [kernel.vmlinux]    [k] page_fault
  0.00%  exe      exe                 [.] MAIN__
  ...
</pre></div>
</div>
<ul class="simple">
<li>You can also using call graphs with</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -vvv perf record --call-graph fp -o data.perf ./exe

$ perf report -i data.perf
Samples: 5K of event &#39;cycles:u&#39;, Event count (approx.): 2184801676
 Children      Self  Command  Shared Object           Symbol
+   66.72%     0.00%  exe      libc-2.17.so            [.] __libc_start_main
+   61.03%     0.03%  exe      libiomp5.so             [.] __kmpc_fork_call
-   60.96%     0.05%  exe      libiomp5.so             [.] __kmp_fork_call
    60.90% __kmp_fork_call
     - __kmp_invoke_microtask
          56.06% nextGen
          3.33% main
          1.35% __intel_avx_rep_memcpy
+   60.90%     0.03%  exe      libiomp5.so             [.] __kmp_invoke_microtask
+   56.06%    56.06%  exe      exe                     [.] nextGen
+    8.98%     5.86%  exe      exe                     [.] main
...
</pre></div>
</div>
</div>
<div class="section" id="memonit">
<h3>Memonit<a class="headerlink" href="#memonit" title="Permalink to this headline">¶</a></h3>
<p>Memonit is a memory profiling tool for HPC jobs. It traces memory usage for each process. To use the memonit tool, insert in your submission script the following instructions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">1.</span> <span class="n">Trace</span> <span class="n">acquisition</span>
<span class="o">--------------------</span>

<span class="c1">#MSUB -q xxxxxxxx</span>
<span class="c1">#MSUB -T xxxxxxxx</span>
<span class="c1">#MSUB -n xxxxxxxx</span>
<span class="c1">#Other MSUB directives</span>
<span class="c1">#Other MSUB directives</span>
<span class="c1">#Other MSUB directives</span>

<span class="n">export</span> <span class="n">OMP_NUM_THREADS</span><span class="o">=</span><span class="n">xxxxxx</span>

<span class="c1">#export MEMONIT_DELAY=0:100 #snapshot every 100us, by default every 2s</span>
<span class="n">ccc_mprun</span> <span class="o">--</span> <span class="n">memonit_collect</span> <span class="o">./</span><span class="n">my_job</span>

<span class="mf">2.</span> <span class="n">Post</span> <span class="n">treatment</span>
<span class="o">-----------------</span>

<span class="c1">#Load dependencies</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">python</span>

<span class="c1">#Aggregate traces into my_job.db</span>
<span class="n">memonit_aggregate</span> <span class="o">-</span><span class="n">f</span> <span class="n">my_job</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">json</span>

<span class="c1">#Analyse by mpi rank</span>
<span class="n">memonit_gui</span> <span class="o">-</span><span class="n">f</span> <span class="n">my_job</span><span class="o">.</span><span class="n">db</span>
<span class="c1">#Or by node</span>
<span class="n">memonit_gui</span> <span class="o">-</span><span class="n">f</span> <span class="n">my_job_bynode</span><span class="o">.</span><span class="n">db</span>
</pre></div>
</div>
</div>
</div>
<span id="document-toc/fulldoc/Post-processing"></span><div class="section" id="post-processing">
<span id="id1"></span><h2>Post-processing<a class="headerlink" href="#post-processing" title="Permalink to this headline">¶</a></h2>
<div class="section" id="gnuplot">
<h3>Gnuplot<a class="headerlink" href="#gnuplot" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference external" href="http://www.gnuplot.info">Gnuplot homepage</a> provides links to all the documentation most users will need.</p>
<p>You can use <strong class="command">gnuplot</strong> from a Remote Desktop System session or from a compute node (please avoid login nodes)</p>
<p>To start <strong class="command">gnuplot</strong> from a Remote Desktop System session:</p>
<ul class="simple">
<li>Start your Remote Desktop System session</li>
<li>Open a terminal</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">gnuplot</span>
<span class="n">gnuplot</span>
</pre></div>
</div>
<p>To start <strong class="command">gnuplot</strong> from a compute node:</p>
<ul class="simple">
<li>Log into the login node, with X redirection (<strong class="command">ssh -X login&#64;login-node</strong>).</li>
<li>Load the appropriate module:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">gnuplot</span>
</pre></div>
</div>
<ul class="simple">
<li>Start an interactive session from a compute node with X11 export and launch <strong class="command">gnuplot</strong>:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">Xfirst</span> <span class="o">-</span><span class="n">T3600</span> <span class="o">-</span><span class="n">p</span> <span class="o">&lt;</span><span class="n">partition</span><span class="o">&gt;</span> <span class="o">-</span><span class="n">s</span>
<span class="n">gnuplot</span>
</pre></div>
</div>
<ul class="simple">
<li>An example of <strong class="command">gnuplot</strong> prompt:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ gnuplot

    G N U P L O T
    Version x.y patchlevel z    last modified 2020-12-01

    Copyright (C) 1986-1993, 1998, 2004, 2007-2020
    Thomas Williams, Colin Kelley and many others

    gnuplot home:     http://www.gnuplot.info
    faq, bugs, etc:   type &quot;help FAQ&quot;
    immediate help:   type &quot;help&quot;  (plot window: hit &#39;h&#39;)

Terminal type is now &#39;unknown&#39;
gnuplot&gt;
</pre></div>
</div>
<div class="figure align-default" id="id3">
<a class="reference internal image-reference" href="_images/postpro_gnuplot_display.png"><img alt="Example of Gnuplot output (display)" src="_images/postpro_gnuplot_display.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Example of Gnuplot output (display)</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
<ul class="simple">
<li>If your <strong class="command">gnuplot</strong> session is ressource intensive, you may add the <code class="xref std std-option docutils literal notranslate"><span class="pre">-x</span></code> option to ensure the node is allocated to you only.</li>
</ul>
</div>
<div class="section" id="xmgrace">
<h3>Xmgrace<a class="headerlink" href="#xmgrace" title="Permalink to this headline">¶</a></h3>
<p>You can use <strong class="command">xmgrace</strong> from a Remote Desktop System session or from a compute node (please avoid login nodes)</p>
<p>To start <strong class="command">xmgrace</strong> from a Remote Desktop System session:</p>
<ul class="simple">
<li>Start your Remote Desktop System session</li>
<li>Open a terminal</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">grace</span>
<span class="n">xmgrace</span>
</pre></div>
</div>
<p>To start <strong class="command">xmgrace</strong> from a compute node:</p>
<ul class="simple">
<li>Log into the login node, with X redirection and thrusted X11 forwarding</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ssh</span> <span class="o">-</span><span class="n">Y</span> <span class="n">login</span><span class="nd">@login</span><span class="o">-</span><span class="n">node</span>
</pre></div>
</div>
<ul class="simple">
<li>Find <strong class="command">xmgrace</strong>:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">grace</span>
</pre></div>
</div>
<ul class="simple">
<li>Start <strong class="command">xmgrace</strong> from an exclusive compute node:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">Xfirst</span> <span class="o">-</span><span class="n">x</span> <span class="o">-</span><span class="n">Q</span> <span class="n">normal</span> <span class="o">-</span><span class="n">p</span> <span class="n">partition</span> <span class="n">xmgrace</span>
</pre></div>
</div>
<div class="figure align-default" id="id4">
<a class="reference internal image-reference" href="_images/postpro_xmgrace.png"><img alt="Example of xmgrace output" src="_images/postpro_xmgrace.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Example of xmgrace output</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
<p>The program <strong class="command">xmgrace</strong> calls firefox to display its help contents that are available as HTML. Since all nodes don’t have browsers, you may see:</p>
<ul class="simple">
<li>Tutorial and manuals may be found on <a class="reference external" href="http://plasma-gate.weizmann.ac.il/Grace/%7Cthe">website of grace</a></li>
</ul>
</div>
<div class="section" id="tecplot">
<h3>Tecplot<a class="headerlink" href="#tecplot" title="Permalink to this headline">¶</a></h3>
<p>You can use Tecplot from a Remote Desktop System session or from a compute node (please avoid login nodes)</p>
<p>To start tecplot from a Remote Desktop System session:</p>
<ul class="simple">
<li>Start your Remote Desktop System session</li>
<li>Open a terminal</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">tecplot</span>
<span class="n">tec360</span>
</pre></div>
</div>
<p>To start Tecplot from a compute node:</p>
<ul class="simple">
<li>Log into the login node, with X redirection (<strong class="command">ssh -X login&#64;login-node</strong>).</li>
<li>Find tecplot:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">tecplot</span>
</pre></div>
</div>
<ul class="simple">
<li>Start Tecplot from an exclusive compute node:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">Xfirst</span> <span class="o">-</span><span class="n">x</span> <span class="o">-</span><span class="n">Q</span> <span class="n">normal</span> <span class="o">-</span><span class="n">p</span> <span class="n">partition</span> <span class="n">tec360</span>
</pre></div>
</div>
<p>Tecplot calls <strong class="command">firefox</strong> to display its help contents that are available as HTML. Since not all node have firefox, you may be interested in the following:</p>
<ul class="simple">
<li><a class="reference external" href="http://www.tecplot.com/support/tutorials/tecplot-360-getting-started/Tecplot">tutorial</a></li>
<li><a class="reference external" href="http://www.tecplottalk.com/tecplot360/Tecplot">forum</a></li>
</ul>
</div>
<div class="section" id="ensight">
<h3>Ensight<a class="headerlink" href="#ensight" title="Permalink to this headline">¶</a></h3>
<p>The tool can be launched from a Remote Desktop System session (highly recommended) or from a compute node. Please avoid login nodes!</p>
<p>From a Remote Desktop System session:</p>
<ul class="simple">
<li>Start your Remote Desktop System session</li>
<li>Open a terminal</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">ensight</span>
<span class="n">ensight101</span>
</pre></div>
</div>
<p>From a compute node:</p>
<ul class="simple">
<li>Connect to the supercomputer with trusted X11 forwarding</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ssh</span> <span class="o">-</span><span class="n">XY</span> <span class="o">&lt;</span><span class="n">login</span><span class="o">&gt;@&lt;</span><span class="n">machine</span><span class="o">&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li>Load ensight</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">ensight</span>
</pre></div>
</div>
<ul class="simple">
<li>Start the tool from a compute node:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">Xfirst</span> <span class="o">-</span><span class="n">p</span> <span class="n">partition</span> <span class="o">-</span><span class="n">T3600</span> <span class="n">ensight101</span>
</pre></div>
</div>
<div class="figure align-default" id="id5">
<a class="reference internal image-reference" href="_images/ensight_gui.png"><img alt="Example of ensight output" src="_images/ensight_gui.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Example of ensight output</span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="visit">
<h3>visit<a class="headerlink" href="#visit" title="Permalink to this headline">¶</a></h3>
<div class="section" id="interactive-mode">
<h4>Interactive mode<a class="headerlink" href="#interactive-mode" title="Permalink to this headline">¶</a></h4>
<p>You can use Visit from a Remote Desktop System session or from a compute node (please avoid login nodes)</p>
<p>To start Visit from a Remote Desktop System session:</p>
<ul class="simple">
<li>Start your Remote Desktop System session</li>
<li>Open a terminal</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">visit</span>
<span class="n">visit</span>
</pre></div>
</div>
<p>To start Visit from a compute node:</p>
<ul class="simple">
<li>Connect to the supercomputer with trusted X11 forwarding</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ssh</span> <span class="o">-</span><span class="n">XY</span> <span class="o">&lt;</span><span class="n">login</span><span class="o">&gt;@&lt;</span><span class="n">machine</span><span class="o">&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li>Load visit</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">visit</span>
</pre></div>
</div>
<ul class="simple">
<li>Start Visit from a compute node:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">Xfirst</span> <span class="o">-</span><span class="n">p</span> <span class="n">partition</span> <span class="o">-</span><span class="n">T3600</span> <span class="n">visit</span> <span class="o">-</span><span class="n">noconfig</span>
</pre></div>
</div>
<div class="figure align-default" id="id6">
<a class="reference internal image-reference" href="_images/visit_client_server2.png"><img alt="Example of visit output" src="_images/visit_client_server2.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Example of visit output</span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="installing-the-tgcc-configuration">
<h4>Installing the TGCC configuration<a class="headerlink" href="#installing-the-tgcc-configuration" title="Permalink to this headline">¶</a></h4>
<p>In order to run Visit in parallel or properly use the Remote Desktop System GPUs (Client-Server mode), you need to copy the TGCC configuration on your account first. Namely:</p>
<ul class="simple">
<li>Connect to the supercomputer with trusted X11 forwarding</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ssh</span> <span class="o">-</span><span class="n">XY</span> <span class="o">&lt;</span><span class="n">login</span><span class="o">&gt;@&lt;</span><span class="n">machine</span><span class="o">&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li>Load and launch visit</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">visit</span>
<span class="n">visit</span>
</pre></div>
</div>
<ul class="simple">
<li>Install the TGCC configuration: in “<span class="menuselection">Options ‣ Host Profiles and Configuration Setup ‣ TGCC Computing Center Network</span>” and click “Install”</li>
<li>Close visit</li>
</ul>
<div class="figure align-default" id="id7">
<a class="reference internal image-reference" href="_images/postpro_visit_cfg.png"><img alt="Configuring visit for TGCC" src="_images/postpro_visit_cfg.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Configuring visit for TGCC</span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="client-server-mode">
<h4>Client-Server mode<a class="headerlink" href="#client-server-mode" title="Permalink to this headline">¶</a></h4>
<p>You can launch visit in a client-server mode, that is to say in a reservation of n cores, 1 client displays the data, and n-1 servers compute the data to be displayed.</p>
<ul class="simple">
<li>Connect to the supercomputer with trusted X11 forwarding</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ssh</span> <span class="o">-</span><span class="n">XY</span> <span class="o">&lt;</span><span class="n">login</span><span class="o">&gt;@&lt;</span><span class="n">machine</span><span class="o">&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li>If not done yet, please install Computation Center configuration as described above.</li>
<li>Setup a job with X export which load and execute visit:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cat job.sh
#!/bin/bash
#MSUB -X
#MSUB -q partition
#MSUB -n 16
module load visit
visit
$ ccc_msub job.sh
</pre></div>
</div>
<ul class="simple">
<li>Once visit started, open the file and in the window entitled “Select options for &lt;node&gt;” that will appear.<ul>
<li>If you are in a Remote Desktop System session, select “current reservation (visuportal - gpu)” and let “Num procs” to its default value.</li>
<li>Otherwise, select “current reservation (other)” and set the “Num Procs” to “n-1” where “n” is the number of cores of your reservation.</li>
</ul>
</li>
<li>Rendering will now be done by the servers/compute engines.</li>
</ul>
<div class="figure align-default" id="id8">
<a class="reference internal image-reference" href="_images/visit_client_server1.png"><img alt="Starting visit's compute engine(s)" src="_images/visit_client_server1.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Starting visit’s compute engine(s)</span><a class="headerlink" href="#id8" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="paraview">
<h3>paraview<a class="headerlink" href="#paraview" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id2">
<h4>Interactive mode<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<p>You can use Paraview from a Remote Desktop System Session or from a compute node (please avoid login nodes)</p>
<p>To start Paraview from a Remote Desktop System session:</p>
<ul class="simple">
<li>Start your Remote Desktop System session</li>
<li>Open a terminal</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">paraview</span>
<span class="n">paraview</span>
</pre></div>
</div>
<p>To start Paraview on a compute node:</p>
<ul class="simple">
<li>Log into the login node, with X redirection and thrusted X11 forwarding</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ssh</span> <span class="o">-</span><span class="n">XY</span> <span class="n">login</span><span class="nd">@login</span><span class="o">-</span><span class="n">node</span>
</pre></div>
</div>
<ul class="simple">
<li>Find Paraview:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">paraview</span>
</pre></div>
</div>
<ul class="simple">
<li>Start Paraview from an exclusive compute node:</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ccc_mprun</span> <span class="o">-</span><span class="n">Xfirst</span> <span class="o">-</span><span class="n">x</span> <span class="o">-</span><span class="n">Q</span> <span class="n">normal</span> <span class="o">-</span><span class="n">p</span> <span class="n">partition</span> <span class="n">paraview</span>
</pre></div>
</div>
</div>
</div>
</div>
<span id="document-toc/fulldoc/Virtualization"></span><div class="section" id="virtualization">
<span id="virtualisation"></span><h2>Virtualization<a class="headerlink" href="#virtualization" title="Permalink to this headline">¶</a></h2>
<div class="section" id="pcocc">
<h3>PCOCC<a class="headerlink" href="#pcocc" title="Permalink to this headline">¶</a></h3>
<p>PCOCC (pronounced peacock) stands for Private Cloud On a Compute Cluster.
It allows users to host their own clusters of VMs (Virtual Machines) on compute nodes alongside regular HPC jobs.
Everything is still handled by the batch scheduler as the clusters of VMs are seen as standard jobs.
Users are in full control of their VM images and may modify them as they like.
This allows to run jobs in custom environments for development, testing or packaging applications in virtual appliances for easy deployment.
Virtual clusters are instanciated on the fly with a single command: <strong class="command">pcocc</strong> allocates the necessary ressources to host the virtual machines, including private Ethernet and/or InfiniBand networks, creates temporary disk images from the selected templates (using CoW) and instantiates as many virtual machines as required.
Facilities are provided to replicate the host environment and access user directories from the VMs or to create new VM templates from scratch.</p>
</div>
<div class="section" id="pre-requisites-for-virtual-machines">
<h3>Pre-requisites for virtual machines<a class="headerlink" href="#pre-requisites-for-virtual-machines" title="Permalink to this headline">¶</a></h3>
<p>To easily access virtual machines through SSH protocol, it is needed to generate a passwordless key and declare it in <code class="file docutils literal notranslate"><span class="pre">.ssh/authorized_keys</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ssh-keygen -t rsa -b 4096
$ cat .ssh/id_rsa.pub &gt;&gt; .ssh/authorized_keys
</pre></div>
</div>
</div>
<div class="section" id="launching-a-cluster-of-vms">
<h3>Launching a cluster of VMs<a class="headerlink" href="#launching-a-cluster-of-vms" title="Permalink to this headline">¶</a></h3>
<p>First, list the available VM templates:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pcocc template list
NAME                 DESCRIPTION                               RESOURCES    IMAGE
----                 -----------                               ---------    -----
machine-compute-ib    Compute node VM with the same software    all          /ccc/scratch/pcocc/images/machine-compute
                     as machine and IB network
machine-compute       Compute node VM with the same software    default      /ccc/scratch/pcocc/images/machine-compute
                    as machine
</pre></div>
</div>
<p>By default, 2 templates are provided, machine-compute is suitable for single VM launch (as communications are done through TCP only) and machine-compute-ib is suitable for cluster of VMs as it can address InfiniBand interface or even a passthrough PCI device such as a GPU.</p>
<p>Then, as an example, to launch a cluster of &lt;num_machines&gt; machine-compute-ib VMs with &lt;num_cores&gt; cores each on “&lt;partition&gt;” partition for a 3 hours duration:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pcocc alloc -A &lt;project&gt;@&lt;partition&gt; -p &lt;partition&gt; -t 3:00:00 -c &lt;num_cores&gt; machine-compute-ib:&lt;num_machines&gt;
</pre></div>
</div>
<p>Note that you must explicitly specify your project.</p>
<p>You are now in a subshell which controls your allocation. If you exit it (Ctrl+D), your virtual cluster will be terminated and the temporary disks of the VMs will be destroyed. Inside this subshell, <strong class="command">pcocc</strong> commands will implicitely refer to the current cluster.</p>
<p>To follow the VM boot sequence, it is possible to display the console (vm0 is the hostname of the first VM of the cluster):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pcocc console vm0
</pre></div>
</div>
<p>To connect to vm0:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pcocc ssh vm0
</pre></div>
</div>
</div>
<div class="section" id="bridge-templates">
<h3>Bridge templates<a class="headerlink" href="#bridge-templates" title="Permalink to this headline">¶</a></h3>
<p>The environment is configured similarily to a compute node with a local SLURM scheduler and your personal spaces (<span class="target" id="index-0"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$HOME</span></code>, <span class="target" id="index-1"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$CCCSCRATCHDIR</span></code>, <span class="target" id="index-2"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$CCCWORKDIR</span></code>, <span class="target" id="index-3"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">$CCCSTOREDIR</span></code>) mounted. Launching and following jobs is done through BRIDGE commands.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mpinfo
                      --------------CPUS------------  -------------NODES------------
PARTITION    STATUS   TOTAL   DOWN    USED    FREE    TOTAL   DOWN    USED    FREE     MpC   CpN SpN CpS TpC
---------    ------   ------  ------  ------  ------  ------  ------  ------  ------   ----- --- --- --- ---
vm           up           56       0       0      56       4       0       0       4    4390  14  14   1   1
</pre></div>
</div>
<p>Computations can be executed interactively, through <strong class="command">ccc_mprun</strong> or a regular submission with <strong class="command">ccc_msub</strong>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -n 4 -N 4 hostname
vm0
vm1
vm3
vm2
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ccc_msub sub.sh
Submitted Batch Session 18
</pre></div>
</div>
</div>
<div class="section" id="customizing-the-vm">
<h3>Customizing the VM<a class="headerlink" href="#customizing-the-vm" title="Permalink to this headline">¶</a></h3>
<p>The default templates also allows you to connect as root:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pcocc ssh root@vm0
</pre></div>
</div>
<p>You may customize the disk image as you like or install new packages. However, remember that if you do not save the disk image (<strong class="command">pcocc save --dest &lt;DIR&gt;</strong>) before terminating the virtual cluster, all changes will be lost.</p>
</div>
<div class="section" id="bridge-plugin">
<span id="id1"></span><h3>Bridge plugin<a class="headerlink" href="#bridge-plugin" title="Permalink to this headline">¶</a></h3>
<p>To easily launch compute tasks on a virtual cluster with bridge, you can activate the dedicated plugin:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">BRIDGE_ADDONS_PREPEND</span><span class="o">=</span>vm.ad
</pre></div>
</div>
<p>You can then use the <strong class="command">ccc_msub -z &lt;pcocc_template&gt; &lt;script&gt;</strong> command to launch a script in a VM cluster and retrieve the standard and error output in the host file system like it’s usually possible for any job submission.</p>
<p>For example, with the following submission script, <strong class="command">ccc_msub -z &lt;pcocc_template&gt; &lt;script&gt;</strong> will execute the script in a cluster of 2 VMs of 28 cores:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#MSUB -N 2</span>
<span class="c1">#MSUB -n 2</span>
<span class="c1">#MSUB -c 28</span>
<span class="c1">#MSUB -r test</span>
</pre></div>
</div>
<p>The <code class="code docutils literal notranslate"><span class="pre">#MSUB</span></code> options are used to configure the virtual cluster. Here, the <code class="xref std std-option docutils literal notranslate"><span class="pre">-N</span></code> option is the number of VMs created.</p>
</div>
<div class="section" id="checkpoint-restart-with-bridge-plugin">
<h3>Checkpoint / restart with Bridge plugin<a class="headerlink" href="#checkpoint-restart-with-bridge-plugin" title="Permalink to this headline">¶</a></h3>
<p>When a job is submitted with the bridge plugin, a checkpoint is automatically created one hour before the job’s time limit, and the job is stopped. You can adjust this with the <span class="target" id="index-4"></span><code class="xref std std-envvar docutils literal notranslate"><span class="pre">PCOCC_CHECKPOINT_TIME</span></code> variable (3600s by default). For example, to interrupt a job 30min before its timelimit, you can export the following variable before doing the submission with <strong class="command">ccc_msub</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">PCOCC_CHECKPOINT_TIME</span><span class="o">=</span><span class="mi">1800</span>
</pre></div>
</div>
<p>You need to set a duration long enough to write the content of the virtual disk and memory to the host file system or your checkpoint will most likely be corrupted.</p>
<p>To automatically resubmit a job from a saved checkpoint after the job has ended, you can export the following variable before doing the submission:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">PCOCC_CHECKPOINT_RESUBMIT</span><span class="o">=</span><span class="mi">1</span>
</pre></div>
</div>
<p>Note that checkpoint / restart is not possible if the VM use passthrough devices such as Infiniband. For example, you can’t use checkpoint with the default <code class="docutils literal notranslate"><span class="pre">machine-compute-ib</span></code> pcocc template.</p>
<p>To restart a job from a previous job, you can use the following command : <strong class="command">ccc_msub -z &lt;pcocc_template&gt;:&lt;jobid&gt; &lt;script&gt;</strong>.</p>
</div>
<div class="section" id="launching-a-cluster-of-containers">
<h3>Launching a cluster of containers<a class="headerlink" href="#launching-a-cluster-of-containers" title="Permalink to this headline">¶</a></h3>
<p>The PCOCC tool allows to run containers on HPC clusters. It supports container images in Docker and OCI formats. In a typical workflow, users first build their container images on their local workstation before importing them to a pcocc image repository on the compute cluster. They can then spawn containers from these images, to run, for example, data analysis tools or parallel computations. Singularity users must translate their recipies to Dockerfile then generate an image as follow.</p>
<p>This can be done with the following steps:</p>
<ol class="arabic simple">
<li>On your local workstation, export a Docker image in tar archive format</li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ docker save my_docker_image -o my_docker_image.tar
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li>Copy the resulting tar file (here: <code class="file docutils literal notranslate"><span class="pre">my_docker_image.tar</span></code>) to the HPC cluster, using, for example, <strong class="command">scp</strong> or <strong class="command">rsync</strong></li>
<li>Import the container image (in the docker-archive tar) to your pcocc image repository on the HPC cluster:</li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pcocc image import docker-archive:my_docker_image.tar my_docker_image
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li>Check that the image is now available in your repository:</li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pcocc image list
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li>Launch containers from your image (this step can be repeated as needed without re-importing the image):</li>
</ol>
<p>When starting a container from a PCOCC image, the behaviour is similar as with Docker: the task that is executed in the container depends on whether an entrypoint or cmd has been defined when building the container image (refer to the Docker documentation for detailed explanations). Host environment variables are also not propagated to the container environment by default, as with Docker. However, in contrast with Docker, your host storage spaces (home, scratch, work, store …) are mounted by default in the containers and your current working directory is propagated if it is not specified in the image. All of this default behaviour can be modified by passing command line options to <strong class="command">pcocc run</strong>.</p>
<p>The following examples show how to invoke <strong class="command">pcocc run</strong> to launch containers in various scenarios:</p>
<ol class="loweralpha simple">
<li>A single container on the login node (only for very lightweight tasks, large tasks will be killed)</li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ pcocc run -s -I my_docker_image <span class="o">[</span>arg1, ...<span class="o">]</span>
</pre></div>
</div>
<ol class="loweralpha simple" start="2">
<li>One or more containers on compute nodes, in interactive mode</li>
</ol>
<p>First, allocate resources for your containers</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_mprun -p broadwell -m scratch,work -n <span class="m">4</span> -c <span class="m">8</span> -T <span class="m">600</span> -K
</pre></div>
</div>
<p>Here we have allocated resources for 4 containers with 8 cores each, for 10 minutes. Note that since your PCOCC image repositories are stored on Lustre, we have to tell the scheduler that we’re going to use these filesystems with the <code class="xref std std-option docutils literal notranslate"><span class="pre">-m</span></code> option. You should add the store filesystem to your request if you’re going to use it as well.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ pcocc run -I my_docker_image <span class="o">[</span>arg1, ...<span class="o">]</span>
</pre></div>
</div>
<p>Four containers are launched according to the earlier resource allocation with ccc_mprun.</p>
<ol class="loweralpha simple" start="3">
<li>One or more containers in a batch job, with a submission script</li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ccc_msub job_pcocc-docker.sh
$ cat joc_pcocc-docker.sh
<span class="c1">#!/bin/bash</span>

<span class="c1">#MSUB -q broadwell</span>
<span class="c1">#MSUB -T 600</span>
<span class="c1">#MSUB -Q test</span>
<span class="c1">#MSUB -n 1</span>
<span class="c1">#MSUB -c 8</span>

pcocc run -I my_docker_image <span class="o">[</span>arg1, ...<span class="o">]</span>
</pre></div>
</div>
<p>In order to make efficient use of HPC hardware, a container has to be built using low-level libraries (such as infiniband verbs), runtimes (such as MPI) and configuration options specifically tuned for the target cluster. The <code class="docutils literal notranslate"><span class="pre">module</span></code> feature of pcocc can be used to facilitate the process of generating optimized container images. Instead of requiring the container image to be built with a finely tuned runtime stack, users only have to select runtimes which are ABI compatible with the recommended runtimes for the target cluster. Using pcocc modules, the optimized runtime libraries and configurations are injected in the container at launch time to make sure it runs as efficiently as possible on the cluster.</p>
<p>Currently, modules are provided for MPI and CUDA. To run a parallel MPI application, the container should be built using a default installation of OpenMPI x.y.z which is the currently supported MPI version on our machines. When running the container, the <code class="xref std std-option docutils literal notranslate"><span class="pre">-M</span> <span class="pre">openmpi-x.y.z</span></code> option can then be added to the command line to load the proper OpenMPI libraries and tunings for the cluster. In the following example, the ubuntu-ompi container was built by simply installing the <code class="docutils literal notranslate"><span class="pre">libopenmpi-dev</span></code> package but it will use the libraries optimized for the compute center at runtime:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ pcocc run -M openmpi-x.y.z -I ubuntu-ompi /bin/hello
</pre></div>
</div>
<p>CUDA libraries compatible with the host driver can be loaded with the ‘nvidia’ module. For instance on v100 nodes, an interactive container with Tensorflow installed can be set up with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ pcocc run -M nvidia --pty -I tensorflow
</pre></div>
</div>
<p>For more information about PCOCC, please refer to the man pages with for example, <strong class="command">man pcocc</strong> or <strong class="command">man pcocc-run</strong>.</p>
</div>
<div class="section" id="whole-set-of-commands">
<h3>Whole set of commands<a class="headerlink" href="#whole-set-of-commands" title="Permalink to this headline">¶</a></h3>
<p>To get information about a command, you can suffix it with <code class="xref std std-option docutils literal notranslate"><span class="pre">--help</span></code> or read the provided manual:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pcocc --help
$ pcocc save --help
$ man pcocc
</pre></div>
</div>
<p>Further possibilities of PCOCC are explained in full documentation on the web: <a class="reference external" href="https://pcocc.readthedocs.io/en/latest">https://pcocc.readthedocs.io/en/latest</a>.</p>
</div>
</div>
<span id="document-toc/fulldoc/Glossary"></span><div class="section" id="glossary-of-ccc-commands">
<span id="id1"></span><h2>Glossary of CCC commands<a class="headerlink" href="#glossary-of-ccc-commands" title="Permalink to this headline">¶</a></h2>
<dl class="docutils">
<dt><strong class="command">ccc_affinity</strong></dt><dd>Alternative to ccc_mpstat. Gives binding infos</dd>
<dt><strong class="command">ccc_authz</strong></dt><dd>Display the limited and authorized networking accesses related to a user</dd>
<dt><strong class="command">ccc_compuse</strong></dt><dd>Display current project(s) scheduling priority based on recent consumption. See also ccc_myproject</dd>
<dt><strong class="command">ccc_container</strong></dt><dd>Helper command to get your current container</dd>
<dt><strong class="command">ccc_crontab</strong></dt><dd>Substitute of cron on the center</dd>
<dt><strong class="command">ccc_echoe</strong></dt><dd>Display a text within a banner</dd>
<dt><strong class="command">ccc_finger</strong></dt><dd>View user full name</dd>
<dt><strong class="command">ccc_getinfo</strong></dt><dd>Helper command for jobs to exchange environment variable. See also ccc_putinfo</dd>
<dt><strong class="command">ccc_home</strong></dt><dd>List the directories associated to a user or a project</dd>
<dt><strong class="command">ccc_hsm</strong></dt><dd>Handle files on HSM filesystems (store)</dd>
<dt><strong class="command">ccc_license</strong></dt><dd>Display token usages for licensed software</dd>
<dt><strong class="command">ccc_macct</strong></dt><dd>View details on a job</dd>
<dt><strong class="command">ccc_mail</strong></dt><dd>Subsitute of mail on the center</dd>
<dt><strong class="command">ccc_malter</strong></dt><dd>Reduce a job timelimit or its token license</dd>
<dt><strong class="command">ccc_mdel</strong></dt><dd>Delete a running job</dd>
<dt><strong class="command">ccc_mpeek</strong></dt><dd>Get the output of a job (LSF bpeek equivalent)</dd>
<dt><strong class="command">ccc_mpinfo</strong></dt><dd>View details on available partitions/queues</dd>
<dt><strong class="command">ccc_mpp</strong></dt><dd>View current running and pending jobs</dd>
<dt><strong class="command">ccc_mpp_curs</strong></dt><dd>Extension of ccc_mpp which allow pending jobs properties edition in a text user interface</dd>
<dt><strong class="command">ccc_mprun</strong></dt><dd>Substitute of mpirun on the center</dd>
<dt><strong class="command">ccc_mpstat</strong></dt><dd>View running jobs parallelism</dd>
<dt><strong class="command">ccc_mqinfo</strong></dt><dd>View details on QoS (Quality Of Service)</dd>
<dt><strong class="command">ccc_mremain</strong></dt><dd>View remaining free memory of a running job</dd>
<dt><strong class="command">ccc_mstat</strong></dt><dd>Alternative to ccc_mpp. Faster but misses some informations (ETD, reservations)</dd>
<dt><strong class="command">ccc_msub</strong></dt><dd>Submit a script as a job</dd>
<dt><strong class="command">ccc_myproject</strong></dt><dd>Display current project(s) usage</dd>
<dt><strong class="command">ccc_os</strong></dt><dd>Substitute of uname -r on center</dd>
<dt><strong class="command">ccc_pack</strong></dt><dd>Archive data (on store). See also ccc_unpack</dd>
<dt><strong class="command">ccc_password_expiration</strong></dt><dd>Display remaining time before password expiration</dd>
<dt><strong class="command">ccc_putinfo</strong></dt><dd>Helper command for jobs to exchange environment variable</dd>
<dt><strong class="command">ccc_quota</strong></dt><dd>View user, group or project quota across filesystem(s). See also ccc_tree</dd>
<dt><strong class="command">ccc_shspace_chmod</strong></dt><dd>Set unix permissions on shared space</dd>
<dt><strong class="command">ccc_shspace_modck</strong></dt><dd>Check unix permissions on shared space</dd>
<dt><strong class="command">ccc_tree</strong></dt><dd>Check if a tree fullfil store recommended usage. See also ccc_quota and ccc_pack</dd>
<dt><strong class="command">ccc_tremain</strong></dt><dd>View the remaining time of a running job</dd>
<dt><strong class="command">ccc_unpack</strong></dt><dd>Decompress archived data (on store). See also ccc_pack</dd>
</dl>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, CEA
      <span class="lastupdated">
        Last updated on 2021-12-01.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>